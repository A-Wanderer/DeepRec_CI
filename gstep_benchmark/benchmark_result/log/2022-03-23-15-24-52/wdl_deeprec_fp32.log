INFO:tensorflow:Parsing ./data/train.csv
INFO:tensorflow:Parsing ./data/eval.csv
2022-03-23 07:41:56.952763: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299995000 Hz
2022-03-23 07:41:56.957732: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f658c238800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-03-23 07:41:56.957768: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-03-23 07:42:04.874373: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
2022-03-23 07:42:37.697588: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
2022-03-23 07:43:07.758559: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
Using TensorFlow version 1.15.5
Checking dataset
Numbers of training dataset is 8000000
Numbers of test dataset is 2000000
Saving model checkpoints to /benchmark_result/checkpoint/2022-03-23-15-24-52/wdl_deeprec_fp32
****Computing statistics of train dataset*****
Save timeline to /benchmark_result/checkpoint/2022-03-23-15-24-52/wdl_deeprec_fp32
global_step/sec: 15.4322
loss = 0.7058462500572205, steps = 0, cost time = 6.48s
global_step/sec: 32.1372
loss = 0.48524758219718933, steps = 100, cost time = 3.11s
global_step/sec: 30.1793
loss = 0.45802950859069824, steps = 200, cost time = 3.31s
global_step/sec: 33.5291
loss = 0.5274972319602966, steps = 300, cost time = 2.98s
global_step/sec: 33.8210
loss = 0.5004918575286865, steps = 400, cost time = 2.96s
global_step/sec: 33.5044
loss = 0.4988265037536621, steps = 500, cost time = 2.98s
global_step/sec: 33.2990
loss = 0.5516389608383179, steps = 600, cost time = 3.00s
global_step/sec: 33.5407
loss = 0.5409463047981262, steps = 700, cost time = 2.98s
global_step/sec: 33.9454
loss = 0.5281187295913696, steps = 800, cost time = 2.95s
global_step/sec: 33.4087
loss = 0.4879882335662842, steps = 900, cost time = 2.99s
Save timeline to /benchmark_result/checkpoint/2022-03-23-15-24-52/wdl_deeprec_fp32
global_step/sec: 30.3158
loss = 0.5197098255157471, steps = 1000, cost time = 3.30s
global_step/sec: 33.8417
loss = 0.5308974981307983, steps = 1100, cost time = 2.95s
global_step/sec: 34.0491
loss = 0.4861944913864136, steps = 1200, cost time = 2.94s
global_step/sec: 33.7478
loss = 0.4804590344429016, steps = 1300, cost time = 2.96s
global_step/sec: 33.4889
loss = 0.5001721382141113, steps = 1400, cost time = 2.99s
global_step/sec: 33.6548
loss = 0.46836596727371216, steps = 1500, cost time = 2.97s
global_step/sec: 33.7894
loss = 0.4724222421646118, steps = 1600, cost time = 2.96s
global_step/sec: 33.4503
loss = 0.5001210570335388, steps = 1700, cost time = 2.99s
global_step/sec: 33.3954
loss = 0.48517411947250366, steps = 1800, cost time = 2.99s
global_step/sec: 33.8586
loss = 0.47248780727386475, steps = 1900, cost time = 2.95s
Save timeline to /benchmark_result/checkpoint/2022-03-23-15-24-52/wdl_deeprec_fp32
global_step/sec: 30.1983
loss = 0.4664624333381653, steps = 2000, cost time = 3.31s
global_step/sec: 33.6326
loss = 0.46224841475486755, steps = 2100, cost time = 2.97s
global_step/sec: 33.2726
loss = 0.5112839937210083, steps = 2200, cost time = 3.01s
global_step/sec: 33.6052
loss = 0.48268723487854004, steps = 2300, cost time = 2.98s
global_step/sec: 33.3209
loss = 0.5054638385772705, steps = 2400, cost time = 3.00s
global_step/sec: 33.7765
loss = 0.4513634443283081, steps = 2500, cost time = 2.96s
global_step/sec: 33.5052
loss = 0.49556902050971985, steps = 2600, cost time = 2.98s
global_step/sec: 32.9450
loss = 0.5266955494880676, steps = 2700, cost time = 3.04s
global_step/sec: 33.4086
loss = 0.5080386400222778, steps = 2800, cost time = 2.99s
global_step/sec: 33.6238
loss = 0.5048843026161194, steps = 2900, cost time = 2.97s
global_step/sec: 1014.1845
loss = 0.5144844055175781, steps = 2999, cost time = 2.96s
