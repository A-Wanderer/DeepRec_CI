INFO:tensorflow:vocabulary_size = 543060 in UID is inferred from the number of elements in the vocabulary_file ./data/uid_voc.txt.
INFO:tensorflow:vocabulary_size = 367983 in ITEM is inferred from the number of elements in the vocabulary_file ./data/mid_voc.txt.
INFO:tensorflow:vocabulary_size = 1601 in CATEGORY is inferred from the number of elements in the vocabulary_file ./data/cat_voc.txt.
INFO:tensorflow:vocabulary_size = 367983 in HISTORY_ITEM is inferred from the number of elements in the vocabulary_file ./data/mid_voc.txt.
INFO:tensorflow:vocabulary_size = 1601 in HISTORY_CATEGORY is inferred from the number of elements in the vocabulary_file ./data/cat_voc.txt.
INFO:tensorflow:Parsing ./data/local_train_splitByUser
INFO:tensorflow:Parsing ./data/local_test_splitByUser
2022-03-23 07:33:41.427758: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299995000 Hz
2022-03-23 07:33:41.433152: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdebaadfc00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-03-23 07:33:41.433190: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-03-23 07:33:43.926896: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
2022-03-23 07:33:53.624996: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
2022-03-23 07:34:02.121915: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
Using TensorFlow version 1.15.5
Checking dataset
Numbers of training dataset is 1086120
Numbers of test dataset is 121216
Saving model checkpoints to /benchmark_result/checkpoint/2022-03-23-15-24-52/din_deeprec_fp32
Save timeline to /benchmark_result/checkpoint/2022-03-23-15-24-52/din_deeprec_fp32
global_step/sec: 39.0103
loss = 0.6882541179656982, steps = 0, cost time = 2.56s
global_step/sec: 112.5950
loss = 0.7003988027572632, steps = 100, cost time = 0.89s
global_step/sec: 98.5147
loss = 0.6883276700973511, steps = 200, cost time = 1.02s
global_step/sec: 118.5220
loss = 0.6625697612762451, steps = 300, cost time = 0.84s
global_step/sec: 118.9888
loss = 0.662574052810669, steps = 400, cost time = 0.84s
global_step/sec: 119.1909
loss = 0.6672572493553162, steps = 500, cost time = 0.84s
global_step/sec: 119.4197
loss = 0.6610075235366821, steps = 600, cost time = 0.84s
global_step/sec: 119.7317
loss = 0.6511795520782471, steps = 700, cost time = 0.84s
global_step/sec: 119.7364
loss = 0.6276439428329468, steps = 800, cost time = 0.84s
global_step/sec: 119.6249
loss = 0.6553593873977661, steps = 900, cost time = 0.84s
Save timeline to /benchmark_result/checkpoint/2022-03-23-15-24-52/din_deeprec_fp32
global_step/sec: 104.7073
loss = 0.6648685336112976, steps = 1000, cost time = 0.96s
global_step/sec: 118.9750
loss = 0.6748803853988647, steps = 1100, cost time = 0.84s
global_step/sec: 119.4172
loss = 0.6425167322158813, steps = 1200, cost time = 0.84s
global_step/sec: 119.2405
loss = 0.596857488155365, steps = 1300, cost time = 0.84s
global_step/sec: 119.0480
loss = 0.655954122543335, steps = 1400, cost time = 0.84s
global_step/sec: 119.1864
loss = 0.6623407602310181, steps = 1500, cost time = 0.84s
global_step/sec: 119.5310
loss = 0.647626519203186, steps = 1600, cost time = 0.84s
global_step/sec: 119.7908
loss = 0.6372426152229309, steps = 1700, cost time = 0.83s
global_step/sec: 119.9676
loss = 0.631839394569397, steps = 1800, cost time = 0.83s
global_step/sec: 119.0707
loss = 0.6496454477310181, steps = 1900, cost time = 0.84s
Save timeline to /benchmark_result/checkpoint/2022-03-23-15-24-52/din_deeprec_fp32
global_step/sec: 106.5397
loss = 0.6997023820877075, steps = 2000, cost time = 0.94s
global_step/sec: 118.4529
loss = 0.6454862356185913, steps = 2100, cost time = 0.84s
global_step/sec: 118.6012
loss = 0.5860944390296936, steps = 2200, cost time = 0.84s
global_step/sec: 119.1038
loss = 0.6266433000564575, steps = 2300, cost time = 0.84s
global_step/sec: 118.9417
loss = 0.6164659857749939, steps = 2400, cost time = 0.84s
global_step/sec: 118.9372
loss = 0.6601099967956543, steps = 2500, cost time = 0.84s
global_step/sec: 118.3655
loss = 0.5788289904594421, steps = 2600, cost time = 0.84s
global_step/sec: 119.4437
loss = 0.6666924953460693, steps = 2700, cost time = 0.84s
global_step/sec: 119.4208
loss = 0.5964869260787964, steps = 2800, cost time = 0.84s
global_step/sec: 118.7866
loss = 0.5842137336730957, steps = 2900, cost time = 0.84s
global_step/sec: 3580.6547
loss = 0.6030360460281372, steps = 2999, cost time = 0.84s
