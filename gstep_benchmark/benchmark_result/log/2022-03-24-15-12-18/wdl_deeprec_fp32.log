INFO:tensorflow:Parsing ./data/train.csv
INFO:tensorflow:Parsing ./data/eval.csv
2022-03-24 07:29:42.751765: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299995000 Hz
2022-03-24 07:29:42.757373: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe691166800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-03-24 07:29:42.757417: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-03-24 07:29:50.693881: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
2022-03-24 07:30:23.346930: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
2022-03-24 07:30:53.706751: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
Using TensorFlow version 1.15.5
Checking dataset
Numbers of training dataset is 8000000
Numbers of test dataset is 2000000
Saving model checkpoints to /benchmark_result/checkpoint/2022-03-24-15-12-18/wdl_deeprec_fp32
****Computing statistics of train dataset*****
Save timeline to /benchmark_result/checkpoint/2022-03-24-15-12-18/wdl_deeprec_fp32
global_step/sec: 15.2695
loss = 0.7058462500572205, steps = 0, cost time = 6.55s
global_step/sec: 33.1552
loss = 0.48524758219718933, steps = 100, cost time = 3.02s
global_step/sec: 30.7980
loss = 0.45802950859069824, steps = 200, cost time = 3.25s
global_step/sec: 33.7867
loss = 0.5274972319602966, steps = 300, cost time = 2.96s
global_step/sec: 33.9326
loss = 0.5004918575286865, steps = 400, cost time = 2.95s
global_step/sec: 33.4945
loss = 0.4988265037536621, steps = 500, cost time = 2.99s
global_step/sec: 33.5173
loss = 0.5516389608383179, steps = 600, cost time = 2.98s
global_step/sec: 33.3975
loss = 0.5409463047981262, steps = 700, cost time = 2.99s
global_step/sec: 33.6605
loss = 0.5281187295913696, steps = 800, cost time = 2.97s
global_step/sec: 33.4324
loss = 0.4879882335662842, steps = 900, cost time = 2.99s
Save timeline to /benchmark_result/checkpoint/2022-03-24-15-12-18/wdl_deeprec_fp32
global_step/sec: 30.2339
loss = 0.5197098255157471, steps = 1000, cost time = 3.31s
global_step/sec: 33.2742
loss = 0.5308974981307983, steps = 1100, cost time = 3.01s
global_step/sec: 33.3428
loss = 0.4861944913864136, steps = 1200, cost time = 3.00s
global_step/sec: 33.1611
loss = 0.4804590344429016, steps = 1300, cost time = 3.02s
global_step/sec: 33.0626
loss = 0.5001721382141113, steps = 1400, cost time = 3.02s
global_step/sec: 33.0793
loss = 0.46836596727371216, steps = 1500, cost time = 3.02s
global_step/sec: 33.4806
loss = 0.4724222421646118, steps = 1600, cost time = 2.99s
global_step/sec: 33.4766
loss = 0.5001210570335388, steps = 1700, cost time = 2.99s
global_step/sec: 33.1680
loss = 0.48517411947250366, steps = 1800, cost time = 3.01s
global_step/sec: 33.7964
loss = 0.47248780727386475, steps = 1900, cost time = 2.96s
Save timeline to /benchmark_result/checkpoint/2022-03-24-15-12-18/wdl_deeprec_fp32
global_step/sec: 30.3042
loss = 0.4664624333381653, steps = 2000, cost time = 3.30s
global_step/sec: 33.5526
loss = 0.46224841475486755, steps = 2100, cost time = 2.98s
global_step/sec: 33.7822
loss = 0.5112839937210083, steps = 2200, cost time = 2.96s
global_step/sec: 33.9301
loss = 0.48268723487854004, steps = 2300, cost time = 2.95s
global_step/sec: 33.2490
loss = 0.5054638385772705, steps = 2400, cost time = 3.01s
global_step/sec: 32.9401
loss = 0.4513634443283081, steps = 2500, cost time = 3.04s
global_step/sec: 33.7785
loss = 0.49556902050971985, steps = 2600, cost time = 2.96s
global_step/sec: 33.5613
loss = 0.5266955494880676, steps = 2700, cost time = 2.98s
global_step/sec: 33.6933
loss = 0.5080386400222778, steps = 2800, cost time = 2.97s
global_step/sec: 33.7213
loss = 0.5048843026161194, steps = 2900, cost time = 2.97s
global_step/sec: 1020.0772
loss = 0.5144844055175781, steps = 2999, cost time = 2.94s
