INFO:tensorflow:Parsing ./data/train.csv
INFO:tensorflow:Parsing ./data/eval.csv
2022-03-24 07:20:10.150758: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299995000 Hz
2022-03-24 07:20:10.156871: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7efbc0e9f800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-03-24 07:20:10.156914: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-03-24 07:20:17.946761: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
2022-03-24 07:20:41.728926: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
2022-03-24 07:21:02.823225: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
Using TensorFlow version 1.15.5
Checking dataset
Numbers of training dataset is 8000000
Numbers of test dataset is 2000000
Saving model checkpoints to /benchmark_result/checkpoint/2022-03-24-15-12-18/wdl_deeprec_bf16
****Computing statistics of train dataset*****
Save timeline to /benchmark_result/checkpoint/2022-03-24-15-12-18/wdl_deeprec_bf16
global_step/sec: 15.2291
loss = 0.6819902658462524, steps = 0, cost time = 6.57s
global_step/sec: 47.0215
loss = 0.48535847663879395, steps = 100, cost time = 2.13s
global_step/sec: 41.8046
loss = 0.4583454430103302, steps = 200, cost time = 2.39s
global_step/sec: 48.5632
loss = 0.527806282043457, steps = 300, cost time = 2.06s
global_step/sec: 47.8192
loss = 0.5019075274467468, steps = 400, cost time = 2.09s
global_step/sec: 48.2800
loss = 0.4977288842201233, steps = 500, cost time = 2.07s
global_step/sec: 48.4577
loss = 0.5512416362762451, steps = 600, cost time = 2.06s
global_step/sec: 48.4123
loss = 0.5427879095077515, steps = 700, cost time = 2.07s
global_step/sec: 48.6403
loss = 0.5291278958320618, steps = 800, cost time = 2.06s
global_step/sec: 48.1589
loss = 0.4874821901321411, steps = 900, cost time = 2.08s
Save timeline to /benchmark_result/checkpoint/2022-03-24-15-12-18/wdl_deeprec_bf16
global_step/sec: 41.2393
loss = 0.5195416212081909, steps = 1000, cost time = 2.42s
global_step/sec: 47.9881
loss = 0.5307120680809021, steps = 1100, cost time = 2.08s
global_step/sec: 48.7383
loss = 0.4850817322731018, steps = 1200, cost time = 2.05s
global_step/sec: 48.4733
loss = 0.47968000173568726, steps = 1300, cost time = 2.06s
global_step/sec: 48.3438
loss = 0.500375509262085, steps = 1400, cost time = 2.07s
global_step/sec: 47.4840
loss = 0.4698074162006378, steps = 1500, cost time = 2.11s
global_step/sec: 48.0743
loss = 0.4727467894554138, steps = 1600, cost time = 2.08s
global_step/sec: 47.5856
loss = 0.49991220235824585, steps = 1700, cost time = 2.10s
global_step/sec: 48.0159
loss = 0.4852409362792969, steps = 1800, cost time = 2.08s
global_step/sec: 48.4358
loss = 0.4727153480052948, steps = 1900, cost time = 2.06s
Save timeline to /benchmark_result/checkpoint/2022-03-24-15-12-18/wdl_deeprec_bf16
global_step/sec: 42.5530
loss = 0.46611326932907104, steps = 2000, cost time = 2.35s
global_step/sec: 47.6887
loss = 0.4623470604419708, steps = 2100, cost time = 2.10s
global_step/sec: 47.8457
loss = 0.5102174282073975, steps = 2200, cost time = 2.09s
global_step/sec: 48.0189
loss = 0.48119375109672546, steps = 2300, cost time = 2.08s
global_step/sec: 48.3014
loss = 0.5077740550041199, steps = 2400, cost time = 2.07s
global_step/sec: 48.0298
loss = 0.4507516026496887, steps = 2500, cost time = 2.08s
global_step/sec: 48.1076
loss = 0.49675169587135315, steps = 2600, cost time = 2.08s
global_step/sec: 47.8600
loss = 0.5268297791481018, steps = 2700, cost time = 2.09s
global_step/sec: 47.9130
loss = 0.5077645778656006, steps = 2800, cost time = 2.09s
global_step/sec: 47.9343
loss = 0.5050902366638184, steps = 2900, cost time = 2.09s
global_step/sec: 1447.5740
loss = 0.514258861541748, steps = 2999, cost time = 2.07s
