INFO:tensorflow:Parsing ./data/train.csv
INFO:tensorflow:Parsing ./data/eval.csv
2022-03-23 10:04:20.517762: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299995000 Hz
2022-03-23 10:04:20.522294: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f5a710ee800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-03-23 10:04:20.522335: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-03-23 10:04:28.394235: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
2022-03-23 10:05:01.201213: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
2022-03-23 10:05:31.648668: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
Using TensorFlow version 1.15.5
Checking dataset
Numbers of training dataset is 8000000
Numbers of test dataset is 2000000
Saving model checkpoints to /benchmark_result/checkpoint/2022-03-23-17-47-08/wdl_deeprec_fp32
****Computing statistics of train dataset*****
Save timeline to /benchmark_result/checkpoint/2022-03-23-17-47-08/wdl_deeprec_fp32
global_step/sec: 15.2429
loss = 0.7058462500572205, steps = 0, cost time = 6.56s
global_step/sec: 33.0711
loss = 0.48524758219718933, steps = 100, cost time = 3.02s
global_step/sec: 30.5294
loss = 0.45802950859069824, steps = 200, cost time = 3.28s
global_step/sec: 33.4148
loss = 0.5274972319602966, steps = 300, cost time = 2.99s
global_step/sec: 33.3884
loss = 0.5004918575286865, steps = 400, cost time = 3.00s
global_step/sec: 33.6942
loss = 0.4988265037536621, steps = 500, cost time = 2.97s
global_step/sec: 33.8204
loss = 0.5516389608383179, steps = 600, cost time = 2.96s
global_step/sec: 33.2853
loss = 0.5409463047981262, steps = 700, cost time = 3.00s
global_step/sec: 33.8135
loss = 0.5281187295913696, steps = 800, cost time = 2.96s
global_step/sec: 33.3450
loss = 0.4879882335662842, steps = 900, cost time = 3.00s
Save timeline to /benchmark_result/checkpoint/2022-03-23-17-47-08/wdl_deeprec_fp32
global_step/sec: 30.0114
loss = 0.5197098255157471, steps = 1000, cost time = 3.33s
global_step/sec: 32.8617
loss = 0.5308974981307983, steps = 1100, cost time = 3.04s
global_step/sec: 33.3662
loss = 0.4861944913864136, steps = 1200, cost time = 3.00s
global_step/sec: 33.3439
loss = 0.4804590344429016, steps = 1300, cost time = 3.00s
global_step/sec: 33.3710
loss = 0.5001721382141113, steps = 1400, cost time = 3.00s
global_step/sec: 32.9801
loss = 0.46836596727371216, steps = 1500, cost time = 3.03s
global_step/sec: 33.4178
loss = 0.4724222421646118, steps = 1600, cost time = 2.99s
global_step/sec: 33.4498
loss = 0.5001210570335388, steps = 1700, cost time = 2.99s
global_step/sec: 33.1015
loss = 0.48517411947250366, steps = 1800, cost time = 3.02s
global_step/sec: 33.2874
loss = 0.47248780727386475, steps = 1900, cost time = 3.00s
Save timeline to /benchmark_result/checkpoint/2022-03-23-17-47-08/wdl_deeprec_fp32
global_step/sec: 30.0877
loss = 0.4664624333381653, steps = 2000, cost time = 3.32s
global_step/sec: 33.3138
loss = 0.46224841475486755, steps = 2100, cost time = 3.00s
global_step/sec: 33.3868
loss = 0.5112839937210083, steps = 2200, cost time = 3.00s
global_step/sec: 33.7561
loss = 0.48268723487854004, steps = 2300, cost time = 2.96s
global_step/sec: 33.5542
loss = 0.5054638385772705, steps = 2400, cost time = 2.98s
global_step/sec: 33.2961
loss = 0.4513634443283081, steps = 2500, cost time = 3.00s
global_step/sec: 32.9848
loss = 0.49556902050971985, steps = 2600, cost time = 3.03s
global_step/sec: 33.0918
loss = 0.5266955494880676, steps = 2700, cost time = 3.02s
global_step/sec: 32.9801
loss = 0.5080386400222778, steps = 2800, cost time = 3.03s
global_step/sec: 33.6556
loss = 0.5048843026161194, steps = 2900, cost time = 2.97s
global_step/sec: 1015.7915
loss = 0.5144844055175781, steps = 2999, cost time = 2.95s
