INFO:tensorflow:Parsing ./data/train.csv
INFO:tensorflow:Parsing ./data/eval.csv
2022-03-23 08:18:55.170762: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299995000 Hz
2022-03-23 08:18:55.176839: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fca11445800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-03-23 08:18:55.176881: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-03-23 08:19:03.254528: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
2022-03-23 08:19:36.135513: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
2022-03-23 08:20:06.420487: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
Using TensorFlow version 1.15.5
Checking dataset
Numbers of training dataset is 8000000
Numbers of test dataset is 2000000
Saving model checkpoints to /benchmark_result/checkpoint/2022-03-23-16-01-51/wdl_deeprec_fp32
****Computing statistics of train dataset*****
Save timeline to /benchmark_result/checkpoint/2022-03-23-16-01-51/wdl_deeprec_fp32
global_step/sec: 14.8155
loss = 0.7058462500572205, steps = 0, cost time = 6.75s
global_step/sec: 32.7452
loss = 0.48524758219718933, steps = 100, cost time = 3.05s
global_step/sec: 30.6410
loss = 0.45802950859069824, steps = 200, cost time = 3.26s
global_step/sec: 33.4425
loss = 0.5274972319602966, steps = 300, cost time = 2.99s
global_step/sec: 33.6274
loss = 0.5004918575286865, steps = 400, cost time = 2.97s
global_step/sec: 33.3162
loss = 0.4988265037536621, steps = 500, cost time = 3.00s
global_step/sec: 33.7442
loss = 0.5516389608383179, steps = 600, cost time = 2.96s
global_step/sec: 33.5248
loss = 0.5409463047981262, steps = 700, cost time = 2.98s
global_step/sec: 33.1511
loss = 0.5281187295913696, steps = 800, cost time = 3.02s
global_step/sec: 33.4513
loss = 0.4879882335662842, steps = 900, cost time = 2.99s
Save timeline to /benchmark_result/checkpoint/2022-03-23-16-01-51/wdl_deeprec_fp32
global_step/sec: 30.1881
loss = 0.5197098255157471, steps = 1000, cost time = 3.31s
global_step/sec: 33.4019
loss = 0.5308974981307983, steps = 1100, cost time = 2.99s
global_step/sec: 33.1675
loss = 0.4861944913864136, steps = 1200, cost time = 3.01s
global_step/sec: 33.5547
loss = 0.4804590344429016, steps = 1300, cost time = 2.98s
global_step/sec: 33.3755
loss = 0.5001721382141113, steps = 1400, cost time = 3.00s
global_step/sec: 33.6513
loss = 0.46836596727371216, steps = 1500, cost time = 2.97s
global_step/sec: 33.3943
loss = 0.4724222421646118, steps = 1600, cost time = 2.99s
global_step/sec: 33.5928
loss = 0.5001210570335388, steps = 1700, cost time = 2.98s
global_step/sec: 33.1546
loss = 0.48517411947250366, steps = 1800, cost time = 3.02s
global_step/sec: 33.2868
loss = 0.47248780727386475, steps = 1900, cost time = 3.00s
Save timeline to /benchmark_result/checkpoint/2022-03-23-16-01-51/wdl_deeprec_fp32
global_step/sec: 30.3873
loss = 0.4664624333381653, steps = 2000, cost time = 3.29s
global_step/sec: 33.2791
loss = 0.46224841475486755, steps = 2100, cost time = 3.00s
global_step/sec: 33.2236
loss = 0.5112839937210083, steps = 2200, cost time = 3.01s
global_step/sec: 33.6869
loss = 0.48268723487854004, steps = 2300, cost time = 2.97s
global_step/sec: 33.4374
loss = 0.5054638385772705, steps = 2400, cost time = 2.99s
global_step/sec: 33.3697
loss = 0.4513634443283081, steps = 2500, cost time = 3.00s
global_step/sec: 33.1878
loss = 0.49556902050971985, steps = 2600, cost time = 3.01s
global_step/sec: 33.2959
loss = 0.5266955494880676, steps = 2700, cost time = 3.00s
global_step/sec: 33.4316
loss = 0.5080386400222778, steps = 2800, cost time = 2.99s
global_step/sec: 33.3339
loss = 0.5048843026161194, steps = 2900, cost time = 3.00s
global_step/sec: 1005.7060
loss = 0.5144844055175781, steps = 2999, cost time = 2.98s
