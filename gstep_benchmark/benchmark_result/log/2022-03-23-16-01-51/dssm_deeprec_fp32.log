INFO:tensorflow:Parsing ./data/taobao_train_data
INFO:tensorflow:Parsing ./data/taobao_test_data
2022-03-23 08:16:54.894771: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299995000 Hz
2022-03-23 08:16:54.899743: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe065875440 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-03-23 08:16:54.899786: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-03-23 08:16:57.982229: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
2022-03-23 08:17:36.699837: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
2022-03-23 08:18:12.629245: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
Using TensorFlow version 1.15.5
Checking dataset
Numbers of training dataset is 50000
Numbers of test dataset is 10000
Saving model checkpoints to /benchmark_result/checkpoint/2022-03-23-16-01-51/dssm_deeprec_fp32
Save timeline to /benchmark_result/checkpoint/2022-03-23-16-01-51/dssm_deeprec_fp32
global_step/sec: 20.9643
loss = 1914.4189453125, steps = 0, cost time = 4.77s
global_step/sec: 27.7987
loss = 1212.729248046875, steps = 100, cost time = 3.60s
global_step/sec: 24.6489
loss = 1091.5966796875, steps = 200, cost time = 4.06s
global_step/sec: 28.4141
loss = 1212.4241943359375, steps = 300, cost time = 3.52s
global_step/sec: 28.2112
loss = 990.2044677734375, steps = 400, cost time = 3.54s
global_step/sec: 28.3647
loss = 1265.4918212890625, steps = 500, cost time = 3.53s
global_step/sec: 28.3926
loss = 1116.581298828125, steps = 600, cost time = 3.52s
global_step/sec: 28.4881
loss = 964.7382202148438, steps = 700, cost time = 3.51s
global_step/sec: 27.9600
loss = 1184.486328125, steps = 800, cost time = 3.58s
global_step/sec: 28.4072
loss = 1190.25, steps = 900, cost time = 3.52s
Save timeline to /benchmark_result/checkpoint/2022-03-23-16-01-51/dssm_deeprec_fp32
global_step/sec: 24.4938
loss = 1100.73291015625, steps = 1000, cost time = 4.08s
global_step/sec: 28.3049
loss = 1195.8173828125, steps = 1100, cost time = 3.53s
global_step/sec: 28.2269
loss = 1259.7239990234375, steps = 1200, cost time = 3.54s
global_step/sec: 28.3308
loss = 1093.51220703125, steps = 1300, cost time = 3.53s
global_step/sec: 28.3595
loss = 986.5665283203125, steps = 1400, cost time = 3.53s
global_step/sec: 28.2204
loss = 1220.5631103515625, steps = 1500, cost time = 3.54s
global_step/sec: 28.1796
loss = 1246.113525390625, steps = 1600, cost time = 3.55s
global_step/sec: 28.3591
loss = 1175.492919921875, steps = 1700, cost time = 3.53s
global_step/sec: 28.2486
loss = 1011.0130004882812, steps = 1800, cost time = 3.54s
global_step/sec: 28.1666
loss = 1278.0159912109375, steps = 1900, cost time = 3.55s
Save timeline to /benchmark_result/checkpoint/2022-03-23-16-01-51/dssm_deeprec_fp32
global_step/sec: 24.3356
loss = 1156.08251953125, steps = 2000, cost time = 4.11s
global_step/sec: 28.1825
loss = 1323.153076171875, steps = 2100, cost time = 3.55s
global_step/sec: 28.2182
loss = 1105.134033203125, steps = 2200, cost time = 3.54s
global_step/sec: 28.2454
loss = 1232.66064453125, steps = 2300, cost time = 3.54s
global_step/sec: 28.2171
loss = 1258.34619140625, steps = 2400, cost time = 3.54s
global_step/sec: 28.1752
loss = 1004.3017578125, steps = 2500, cost time = 3.55s
global_step/sec: 28.2715
loss = 1168.50537109375, steps = 2600, cost time = 3.54s
global_step/sec: 28.0843
loss = 1168.462890625, steps = 2700, cost time = 3.56s
global_step/sec: 28.1592
loss = 1187.589111328125, steps = 2800, cost time = 3.55s
global_step/sec: 28.1734
loss = 1123.8563232421875, steps = 2900, cost time = 3.55s
global_step/sec: 889.7876
loss = 1022.8991088867188, steps = 2999, cost time = 3.37s
