INFO:tensorflow:Parsing ./data/taobao_train_data
INFO:tensorflow:Parsing ./data/taobao_test_data
2022-03-23 09:03:56.279781: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299995000 Hz
2022-03-23 09:03:56.285577: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f86477e9440 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-03-23 09:03:56.285619: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Using TensorFlow version 1.15.5
Checking dataset
Numbers of training dataset is 50000
Numbers of test dataset is 10000
Saving model checkpoints to /benchmark_result/checkpoint/2022-03-23-17-02-12/dssm_deeprec_bf16_
global_step/sec: 48.5178
loss = 1912.870361328125, steps = 0, cost time = 2.06s
loss = 1912.870361328125, steps = 0
global_step/sec: 28.9020
loss = 1294.240966796875, steps = 100, cost time = 3.46s
loss = 1294.240966796875, steps = 100
global_step/sec: 25.1620
loss = 1119.97705078125, steps = 200, cost time = 3.97s
loss = 1119.97705078125, steps = 200
global_step/sec: 30.5928
loss = 1210.759765625, steps = 300, cost time = 3.27s
loss = 1210.759765625, steps = 300
global_step/sec: 30.4369
loss = 987.0014038085938, steps = 400, cost time = 3.29s
loss = 987.0014038085938, steps = 400
global_step/sec: 30.2739
loss = 1267.7950439453125, steps = 500, cost time = 3.30s
loss = 1267.7950439453125, steps = 500
global_step/sec: 30.4491
loss = 1114.9183349609375, steps = 600, cost time = 3.28s
loss = 1114.9183349609375, steps = 600
global_step/sec: 30.5118
loss = 963.37060546875, steps = 700, cost time = 3.28s
loss = 963.37060546875, steps = 700
global_step/sec: 30.4805
loss = 1183.26318359375, steps = 800, cost time = 3.28s
loss = 1183.26318359375, steps = 800
global_step/sec: 30.4426
loss = 1189.2022705078125, steps = 900, cost time = 3.28s
loss = 1189.2022705078125, steps = 900
global_step/sec: 30.5144
loss = 1099.872802734375, steps = 1000, cost time = 3.28s
loss = 1099.872802734375, steps = 1000
global_step/sec: 30.3143
loss = 1194.9954833984375, steps = 1100, cost time = 3.30s
loss = 1194.9954833984375, steps = 1100
global_step/sec: 30.3265
loss = 1259.015380859375, steps = 1200, cost time = 3.30s
loss = 1259.015380859375, steps = 1200
global_step/sec: 30.4634
loss = 1093.29443359375, steps = 1300, cost time = 3.28s
loss = 1093.29443359375, steps = 1300
global_step/sec: 30.3139
loss = 985.9815673828125, steps = 1400, cost time = 3.30s
loss = 985.9815673828125, steps = 1400
global_step/sec: 30.3912
loss = 1220.010009765625, steps = 1500, cost time = 3.29s
loss = 1220.010009765625, steps = 1500
global_step/sec: 30.2522
loss = 1245.60302734375, steps = 1600, cost time = 3.31s
loss = 1245.60302734375, steps = 1600
global_step/sec: 30.4132
loss = 1175.02001953125, steps = 1700, cost time = 3.29s
loss = 1175.02001953125, steps = 1700
global_step/sec: 30.3849
loss = 1010.568603515625, steps = 1800, cost time = 3.29s
loss = 1010.568603515625, steps = 1800
global_step/sec: 30.2998
loss = 1277.58837890625, steps = 1900, cost time = 3.30s
loss = 1277.58837890625, steps = 1900
global_step/sec: 30.2822
loss = 1155.9873046875, steps = 2000, cost time = 3.30s
loss = 1155.9873046875, steps = 2000
global_step/sec: 30.2626
loss = 1322.820068359375, steps = 2100, cost time = 3.30s
loss = 1322.820068359375, steps = 2100
global_step/sec: 30.3005
loss = 1104.80126953125, steps = 2200, cost time = 3.30s
loss = 1104.80126953125, steps = 2200
global_step/sec: 30.3367
loss = 1232.345947265625, steps = 2300, cost time = 3.30s
loss = 1232.345947265625, steps = 2300
global_step/sec: 30.4249
loss = 1258.034912109375, steps = 2400, cost time = 3.29s
loss = 1258.034912109375, steps = 2400
global_step/sec: 30.3688
loss = 1003.9945068359375, steps = 2500, cost time = 3.29s
loss = 1003.9945068359375, steps = 2500
global_step/sec: 30.3337
loss = 1168.216796875, steps = 2600, cost time = 3.30s
loss = 1168.216796875, steps = 2600
global_step/sec: 30.4090
loss = 1168.183837890625, steps = 2700, cost time = 3.29s
loss = 1168.183837890625, steps = 2700
global_step/sec: 30.3253
loss = 1187.31787109375, steps = 2800, cost time = 3.30s
loss = 1187.31787109375, steps = 2800
global_step/sec: 30.3065
loss = 1123.579833984375, steps = 2900, cost time = 3.30s
loss = 1123.579833984375, steps = 2900
global_step/sec: 954.0021
loss = 1022.6368408203125, steps = 2999, cost time = 3.14s
loss = 1022.6368408203125, steps = 2999
