INFO:tensorflow:Parsing ./data/train.csv
INFO:tensorflow:Parsing ./data/eval.csv
2022-03-23 09:07:01.169772: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299995000 Hz
2022-03-23 09:07:01.175541: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f907a2c3800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-03-23 09:07:01.175584: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Using TensorFlow version 1.15.5
Checking dataset
Numbers of training dataset is 8000000
Numbers of test dataset is 2000000
Saving model checkpoints to /benchmark_result/checkpoint/2022-03-23-17-02-12/wdl_deeprec_bf16_
****Computing statistics of train dataset*****
global_step/sec: 24.4851
loss = 1.0105783939361572, steps = 0, cost time = 4.08s
loss = 1.0105783939361572, steps = 0
global_step/sec: 46.5607
loss = 0.48505932092666626, steps = 100, cost time = 2.15s
loss = 0.48505932092666626, steps = 100
global_step/sec: 39.5640
loss = 0.45716217160224915, steps = 200, cost time = 2.53s
loss = 0.45716217160224915, steps = 200
global_step/sec: 48.0090
loss = 0.52674400806427, steps = 300, cost time = 2.08s
loss = 0.52674400806427, steps = 300
global_step/sec: 47.5434
loss = 0.5001230835914612, steps = 400, cost time = 2.10s
loss = 0.5001230835914612, steps = 400
global_step/sec: 48.1829
loss = 0.500493586063385, steps = 500, cost time = 2.08s
loss = 0.500493586063385, steps = 500
global_step/sec: 48.0409
loss = 0.5497720241546631, steps = 600, cost time = 2.08s
loss = 0.5497720241546631, steps = 600
global_step/sec: 48.0298
loss = 0.5404112339019775, steps = 700, cost time = 2.08s
loss = 0.5404112339019775, steps = 700
global_step/sec: 47.9561
loss = 0.5281272530555725, steps = 800, cost time = 2.09s
loss = 0.5281272530555725, steps = 800
global_step/sec: 47.8782
loss = 0.49104833602905273, steps = 900, cost time = 2.09s
loss = 0.49104833602905273, steps = 900
global_step/sec: 47.9199
loss = 0.5191560983657837, steps = 1000, cost time = 2.09s
loss = 0.5191560983657837, steps = 1000
global_step/sec: 47.1346
loss = 0.5265836715698242, steps = 1100, cost time = 2.12s
loss = 0.5265836715698242, steps = 1100
global_step/sec: 47.8090
loss = 0.48568981885910034, steps = 1200, cost time = 2.09s
loss = 0.48568981885910034, steps = 1200
global_step/sec: 47.4897
loss = 0.48285752534866333, steps = 1300, cost time = 2.11s
loss = 0.48285752534866333, steps = 1300
global_step/sec: 47.4249
loss = 0.5025824308395386, steps = 1400, cost time = 2.11s
loss = 0.5025824308395386, steps = 1400
global_step/sec: 47.1709
loss = 0.46724340319633484, steps = 1500, cost time = 2.12s
loss = 0.46724340319633484, steps = 1500
global_step/sec: 47.6768
loss = 0.47423744201660156, steps = 1600, cost time = 2.10s
loss = 0.47423744201660156, steps = 1600
global_step/sec: 47.0774
loss = 0.501213550567627, steps = 1700, cost time = 2.12s
loss = 0.501213550567627, steps = 1700
global_step/sec: 48.0650
loss = 0.4846568703651428, steps = 1800, cost time = 2.08s
loss = 0.4846568703651428, steps = 1800
global_step/sec: 47.4918
loss = 0.47465386986732483, steps = 1900, cost time = 2.11s
loss = 0.47465386986732483, steps = 1900
global_step/sec: 48.0738
loss = 0.4670311212539673, steps = 2000, cost time = 2.08s
loss = 0.4670311212539673, steps = 2000
global_step/sec: 47.5251
loss = 0.4638475179672241, steps = 2100, cost time = 2.10s
loss = 0.4638475179672241, steps = 2100
global_step/sec: 47.1256
loss = 0.5116925835609436, steps = 2200, cost time = 2.12s
loss = 0.5116925835609436, steps = 2200
global_step/sec: 46.7711
loss = 0.48785555362701416, steps = 2300, cost time = 2.14s
loss = 0.48785555362701416, steps = 2300
global_step/sec: 46.9315
loss = 0.5053932666778564, steps = 2400, cost time = 2.13s
loss = 0.5053932666778564, steps = 2400
global_step/sec: 47.1121
loss = 0.44848182797431946, steps = 2500, cost time = 2.12s
loss = 0.44848182797431946, steps = 2500
global_step/sec: 47.7913
loss = 0.49663859605789185, steps = 2600, cost time = 2.09s
loss = 0.49663859605789185, steps = 2600
global_step/sec: 47.7383
loss = 0.5258277654647827, steps = 2700, cost time = 2.09s
loss = 0.5258277654647827, steps = 2700
global_step/sec: 47.5411
loss = 0.5061455965042114, steps = 2800, cost time = 2.10s
loss = 0.5061455965042114, steps = 2800
global_step/sec: 47.3602
loss = 0.499116450548172, steps = 2900, cost time = 2.11s
loss = 0.499116450548172, steps = 2900
global_step/sec: 1412.7384
loss = 0.5125374794006348, steps = 2999, cost time = 2.12s
loss = 0.5125374794006348, steps = 2999
