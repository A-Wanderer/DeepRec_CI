INFO:tensorflow:Parsing ./data/taobao_train_data
INFO:tensorflow:Parsing ./data/taobao_test_data
INFO:tensorflow:Is using fused embedding lookup for this scope age_level_embedding_weights
INFO:tensorflow:Is using fused embedding lookup for this scope cms_group_id_embedding_weights
INFO:tensorflow:Is using fused embedding lookup for this scope cms_segid_embedding_weights
INFO:tensorflow:Is using fused embedding lookup for this scope new_user_class_level_embedding_weights
INFO:tensorflow:Is using fused embedding lookup for this scope occupation_embedding_weights
INFO:tensorflow:Is using fused embedding lookup for this scope pvalue_level_embedding_weights
INFO:tensorflow:Is using fused embedding lookup for this scope shopping_level_embedding_weights
INFO:tensorflow:Is using fused embedding lookup for this scope tag_brand_list_embedding_weights
INFO:tensorflow:Is using fused embedding lookup for this scope tag_category_list_embedding_weights
INFO:tensorflow:Is using fused embedding lookup for this scope user_id_embedding_weights
INFO:tensorflow:Is using fused embedding lookup for this scope adgroup_id_embedding_weights
INFO:tensorflow:Is using fused embedding lookup for this scope brand_embedding_weights
INFO:tensorflow:Is using fused embedding lookup for this scope campaign_id_embedding_weights
INFO:tensorflow:Is using fused embedding lookup for this scope cate_id_embedding_weights
INFO:tensorflow:Is using fused embedding lookup for this scope customer_embedding_weights
INFO:tensorflow:Is using fused embedding lookup for this scope pid_embedding_weights
INFO:tensorflow:Is using fused embedding lookup for this scope price_embedding_weights
2022-03-23 09:02:17.262777: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299995000 Hz
2022-03-23 09:02:17.268571: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0e51e95440 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-03-23 09:02:17.268612: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Using TensorFlow version 1.15.5
Checking dataset
Numbers of training dataset is 50000
Numbers of test dataset is 10000
Saving model checkpoints to /benchmark_result/checkpoint/2022-03-23-17-02-12/dssm_deeprec_bf16_--fusion
global_step/sec: 63.3018
loss = 1912.870361328125, steps = 0, cost time = 1.58s
loss = 1912.870361328125, steps = 0
global_step/sec: 30.7655
loss = 1300.3963623046875, steps = 100, cost time = 3.25s
loss = 1300.3963623046875, steps = 100
global_step/sec: 28.8130
loss = 1120.57958984375, steps = 200, cost time = 3.47s
loss = 1120.57958984375, steps = 200
global_step/sec: 32.6342
loss = 1211.0025634765625, steps = 300, cost time = 3.06s
loss = 1211.0025634765625, steps = 300
global_step/sec: 32.6259
loss = 987.3304443359375, steps = 400, cost time = 3.07s
loss = 987.3304443359375, steps = 400
global_step/sec: 32.6546
loss = 1263.213134765625, steps = 500, cost time = 3.06s
loss = 1263.213134765625, steps = 500
global_step/sec: 32.6007
loss = 1114.8316650390625, steps = 600, cost time = 3.07s
loss = 1114.8316650390625, steps = 600
global_step/sec: 32.5274
loss = 963.3909912109375, steps = 700, cost time = 3.07s
loss = 963.3909912109375, steps = 700
global_step/sec: 32.5980
loss = 1183.7305908203125, steps = 800, cost time = 3.07s
loss = 1183.7305908203125, steps = 800
global_step/sec: 32.5167
loss = 1189.260986328125, steps = 900, cost time = 3.08s
loss = 1189.260986328125, steps = 900
global_step/sec: 32.7893
loss = 1099.888916015625, steps = 1000, cost time = 3.05s
loss = 1099.888916015625, steps = 1000
global_step/sec: 32.5828
loss = 1195.02734375, steps = 1100, cost time = 3.07s
loss = 1195.02734375, steps = 1100
global_step/sec: 32.5173
loss = 1259.00634765625, steps = 1200, cost time = 3.08s
loss = 1259.00634765625, steps = 1200
global_step/sec: 32.3771
loss = 1092.8570556640625, steps = 1300, cost time = 3.09s
loss = 1092.8570556640625, steps = 1300
global_step/sec: 32.5637
loss = 990.3857421875, steps = 1400, cost time = 3.07s
loss = 990.3857421875, steps = 1400
global_step/sec: 32.4184
loss = 1220.2706298828125, steps = 1500, cost time = 3.08s
loss = 1220.2706298828125, steps = 1500
global_step/sec: 32.4154
loss = 1245.731201171875, steps = 1600, cost time = 3.08s
loss = 1245.731201171875, steps = 1600
global_step/sec: 32.4161
loss = 1175.1072998046875, steps = 1700, cost time = 3.08s
loss = 1175.1072998046875, steps = 1700
global_step/sec: 32.4060
loss = 1010.6114501953125, steps = 1800, cost time = 3.09s
loss = 1010.6114501953125, steps = 1800
global_step/sec: 32.5346
loss = 1277.64013671875, steps = 1900, cost time = 3.07s
loss = 1277.64013671875, steps = 1900
global_step/sec: 32.3754
loss = 1155.7142333984375, steps = 2000, cost time = 3.09s
loss = 1155.7142333984375, steps = 2000
global_step/sec: 32.4117
loss = 1322.803466796875, steps = 2100, cost time = 3.09s
loss = 1322.803466796875, steps = 2100
global_step/sec: 32.5037
loss = 1104.798583984375, steps = 2200, cost time = 3.08s
loss = 1104.798583984375, steps = 2200
global_step/sec: 32.4306
loss = 1232.3504638671875, steps = 2300, cost time = 3.08s
loss = 1232.3504638671875, steps = 2300
global_step/sec: 32.4332
loss = 1258.0362548828125, steps = 2400, cost time = 3.08s
loss = 1258.0362548828125, steps = 2400
global_step/sec: 32.4833
loss = 1004.0112915039062, steps = 2500, cost time = 3.08s
loss = 1004.0112915039062, steps = 2500
global_step/sec: 32.4114
loss = 1168.218994140625, steps = 2600, cost time = 3.09s
loss = 1168.218994140625, steps = 2600
global_step/sec: 32.5273
loss = 1168.1865234375, steps = 2700, cost time = 3.07s
loss = 1168.1865234375, steps = 2700
global_step/sec: 32.2559
loss = 1187.31982421875, steps = 2800, cost time = 3.10s
loss = 1187.31982421875, steps = 2800
global_step/sec: 32.3296
loss = 1123.5869140625, steps = 2900, cost time = 3.09s
loss = 1123.5869140625, steps = 2900
global_step/sec: 1025.1165
loss = 1022.64501953125, steps = 2999, cost time = 2.93s
loss = 1022.64501953125, steps = 2999
