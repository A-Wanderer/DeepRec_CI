WARNING:tensorflow:From train.py:14: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

WARNING:tensorflow:From train.py:14: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

WARNING:tensorflow:From train.py:367: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

INFO:tensorflow:Parsing ./data/train.csv
INFO:tensorflow:Parsing ./data/eval.csv
WARNING:tensorflow:From train.py:380: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.

WARNING:tensorflow:From train.py:380: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_types(dataset)`.
WARNING:tensorflow:From train.py:381: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(dataset)`.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:347: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_types(iterator)`.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:348: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(iterator)`.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:350: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_classes(iterator)`.
WARNING:tensorflow:From train.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From train.py:178: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.

WARNING:tensorflow:From train.py:181: The name tf.feature_column.input_layer is deprecated. Please use tf.compat.v1.feature_column.input_layer instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column.py:206: EmbeddingColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:3182: HashedCategoricalColumn._get_sparse_tensors (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column.py:2158: HashedCategoricalColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:3122: HashedCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column.py:207: EmbeddingColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column.py:206: NumericColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column.py:2158: NumericColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column.py:207: NumericColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From train.py:166: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.Dense instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From train.py:169: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).
WARNING:tensorflow:From train.py:53: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From train.py:55: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

WARNING:tensorflow:From train.py:225: The name tf.losses.mean_squared_error is deprecated. Please use tf.compat.v1.losses.mean_squared_error instead.

WARNING:tensorflow:From train.py:230: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.

WARNING:tensorflow:From train.py:232: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From train.py:250: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

WARNING:tensorflow:From train.py:250: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

WARNING:tensorflow:From train.py:149: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.

WARNING:tensorflow:From train.py:152: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From train.py:409: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From train.py:443: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2022-03-31 08:24:52.711130: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2022-03-31 08:24:52.753781: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3400000000 Hz
2022-03-31 08:24:52.785380: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x72bcaf0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-03-31 08:24:52.785452: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From train.py:444: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From train.py:445: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.

WARNING:tensorflow:From train.py:446: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

WARNING:tensorflow:From train.py:447: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From train.py:448: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From train.py:448: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From train.py:450: The name tf.RunOptions is deprecated. Please use tf.compat.v1.RunOptions instead.

WARNING:tensorflow:From train.py:451: The name tf.RunMetadata is deprecated. Please use tf.compat.v1.RunMetadata instead.

Using TensorFlow version 1.15.5
Checking dataset
Numbers of training dataset is 8000000
Numbers of test dataset is 2000000
Saving model checkpoints to /benchmark_result/checkpoint/2022-03-31-14-47-37/deepfm_tf_fp32
global_step/sec: 24.9592
loss = 0.27569693326950073, steps = 0, cost time = 4.01s
global_step/sec: 30.8921
loss = 0.17493751645088196, steps = 100, cost time = 3.24s
global_step/sec: 33.5432
loss = 0.14787457883358002, steps = 200, cost time = 2.98s
global_step/sec: 32.5534
loss = 0.1811363250017166, steps = 300, cost time = 3.07s
global_step/sec: 33.9054
loss = 0.1927308440208435, steps = 400, cost time = 2.95s
global_step/sec: 33.9835
loss = 0.17348526418209076, steps = 500, cost time = 2.94s
global_step/sec: 31.8349
loss = 0.1899583488702774, steps = 600, cost time = 3.14s
global_step/sec: 31.3950
loss = 0.1979748010635376, steps = 700, cost time = 3.19s
global_step/sec: 34.3774
loss = 0.18462365865707397, steps = 800, cost time = 2.91s
global_step/sec: 33.5682
loss = 0.17542770504951477, steps = 900, cost time = 2.98s
global_step/sec: 33.2309
loss = 0.19186526536941528, steps = 1000, cost time = 3.01s
global_step/sec: 33.3439
loss = 0.19256094098091125, steps = 1100, cost time = 3.00s
global_step/sec: 31.4988
loss = 0.1778920441865921, steps = 1200, cost time = 3.17s
global_step/sec: 32.8900
loss = 0.16566956043243408, steps = 1300, cost time = 3.04s
global_step/sec: 35.2246
loss = 0.1605229377746582, steps = 1400, cost time = 2.84s
global_step/sec: 35.0721
loss = 0.15731500089168549, steps = 1500, cost time = 2.85s
global_step/sec: 33.9421
loss = 0.16265523433685303, steps = 1600, cost time = 2.95s
global_step/sec: 32.5723
loss = 0.16700057685375214, steps = 1700, cost time = 3.07s
global_step/sec: 32.6816
loss = 0.15324121713638306, steps = 1800, cost time = 3.06s
global_step/sec: 35.0684
loss = 0.15193751454353333, steps = 1900, cost time = 2.85s
global_step/sec: 33.7574
loss = 0.14846940338611603, steps = 2000, cost time = 2.96s
global_step/sec: 34.2822
loss = 0.14924518764019012, steps = 2100, cost time = 2.92s
global_step/sec: 35.9158
loss = 0.1756083369255066, steps = 2200, cost time = 2.78s
global_step/sec: 33.9591
loss = 0.15453453361988068, steps = 2300, cost time = 2.94s
global_step/sec: 33.6513
loss = 0.16443872451782227, steps = 2400, cost time = 2.97s
global_step/sec: 34.4380
loss = 0.14376232028007507, steps = 2500, cost time = 2.90s
global_step/sec: 34.7639
loss = 0.16398704051971436, steps = 2600, cost time = 2.88s
global_step/sec: 34.7447
loss = 0.17231640219688416, steps = 2700, cost time = 2.88s
global_step/sec: 35.8823
loss = 0.15153957903385162, steps = 2800, cost time = 2.79s
global_step/sec: 34.6277
loss = 0.15678159892559052, steps = 2900, cost time = 2.89s
global_step/sec: 34.6899
loss = 0.16193662583827972, steps = 3000, cost time = 2.88s
global_step/sec: 33.3805
loss = 0.16978445649147034, steps = 3100, cost time = 3.00s
global_step/sec: 34.5979
loss = 0.15750914812088013, steps = 3200, cost time = 2.89s
global_step/sec: 34.7660
loss = 0.14785915613174438, steps = 3300, cost time = 2.88s
global_step/sec: 34.4259
loss = 0.15731123089790344, steps = 3400, cost time = 2.90s
global_step/sec: 34.0704
loss = 0.1584409475326538, steps = 3500, cost time = 2.94s
global_step/sec: 33.3440
loss = 0.14326965808868408, steps = 3600, cost time = 3.00s
global_step/sec: 33.6367
loss = 0.1532147228717804, steps = 3700, cost time = 2.97s
global_step/sec: 34.4479
loss = 0.1584303081035614, steps = 3800, cost time = 2.90s
global_step/sec: 33.4105
loss = 0.153211310505867, steps = 3900, cost time = 2.99s
global_step/sec: 34.6308
loss = 0.16935360431671143, steps = 4000, cost time = 2.89s
global_step/sec: 33.5380
loss = 0.15348638594150543, steps = 4100, cost time = 2.98s
global_step/sec: 34.1821
loss = 0.143014058470726, steps = 4200, cost time = 2.93s
global_step/sec: 32.5530
loss = 0.1599840223789215, steps = 4300, cost time = 3.07s
global_step/sec: 33.8812
loss = 0.1494937539100647, steps = 4400, cost time = 2.95s
global_step/sec: 33.8697
loss = 0.15316498279571533, steps = 4500, cost time = 2.95s
global_step/sec: 33.9357
loss = 0.15167507529258728, steps = 4600, cost time = 2.95s
global_step/sec: 34.8014
loss = 0.14103099703788757, steps = 4700, cost time = 2.87s
global_step/sec: 33.6342
loss = 0.15153180062770844, steps = 4800, cost time = 2.97s
global_step/sec: 33.8287
loss = 0.1431628167629242, steps = 4900, cost time = 2.96s
global_step/sec: 34.1189
loss = 0.15035171806812286, steps = 5000, cost time = 2.93s
global_step/sec: 33.9969
loss = 0.14844706654548645, steps = 5100, cost time = 2.94s
global_step/sec: 34.3338
loss = 0.15456625819206238, steps = 5200, cost time = 2.91s
global_step/sec: 33.5911
loss = 0.143344447016716, steps = 5300, cost time = 2.98s
global_step/sec: 33.8915
loss = 0.15922552347183228, steps = 5400, cost time = 2.95s
global_step/sec: 35.2143
loss = 0.15708297491073608, steps = 5500, cost time = 2.84s
global_step/sec: 32.0546
loss = 0.13948793709278107, steps = 5600, cost time = 3.12s
global_step/sec: 31.8761
loss = 0.1589151918888092, steps = 5700, cost time = 3.14s
global_step/sec: 34.9818
loss = 0.153467059135437, steps = 5800, cost time = 2.86s
global_step/sec: 36.1765
loss = 0.16001395881175995, steps = 5900, cost time = 2.76s
global_step/sec: 36.3327
loss = 0.15658047795295715, steps = 6000, cost time = 2.75s
global_step/sec: 33.9745
loss = 0.16733983159065247, steps = 6100, cost time = 2.94s
global_step/sec: 34.2368
loss = 0.15082331001758575, steps = 6200, cost time = 2.92s
global_step/sec: 34.1753
loss = 0.16187074780464172, steps = 6300, cost time = 2.93s
global_step/sec: 35.1339
loss = 0.16780491173267365, steps = 6400, cost time = 2.85s
global_step/sec: 34.6866
loss = 0.1450444608926773, steps = 6500, cost time = 2.88s
global_step/sec: 34.9957
loss = 0.14789247512817383, steps = 6600, cost time = 2.86s
global_step/sec: 34.7785
loss = 0.1494380235671997, steps = 6700, cost time = 2.88s
global_step/sec: 35.8374
loss = 0.1491304337978363, steps = 6800, cost time = 2.79s
global_step/sec: 34.1423
loss = 0.13536611199378967, steps = 6900, cost time = 2.93s
global_step/sec: 33.8702
loss = 0.1567295789718628, steps = 7000, cost time = 2.95s
global_step/sec: 33.0672
loss = 0.1653534173965454, steps = 7100, cost time = 3.02s
global_step/sec: 33.9001
loss = 0.14076167345046997, steps = 7200, cost time = 2.95s
global_step/sec: 32.5954
loss = 0.15188394486904144, steps = 7300, cost time = 3.07s
global_step/sec: 33.7529
loss = 0.15920370817184448, steps = 7400, cost time = 2.96s
global_step/sec: 33.0643
loss = 0.149452805519104, steps = 7500, cost time = 3.02s
global_step/sec: 34.1365
loss = 0.14930877089500427, steps = 7600, cost time = 2.93s
global_step/sec: 33.6233
loss = 0.1272866427898407, steps = 7700, cost time = 2.97s
global_step/sec: 31.8518
loss = 0.12770533561706543, steps = 7800, cost time = 3.14s
global_step/sec: 33.8447
loss = 0.14502477645874023, steps = 7900, cost time = 2.95s
global_step/sec: 36.0269
loss = 0.13370844721794128, steps = 8000, cost time = 2.78s
global_step/sec: 33.5660
loss = 0.14821293950080872, steps = 8100, cost time = 2.98s
global_step/sec: 35.2101
loss = 0.15031932294368744, steps = 8200, cost time = 2.84s
global_step/sec: 33.9151
loss = 0.133570596575737, steps = 8300, cost time = 2.95s
global_step/sec: 35.4124
loss = 0.1485576629638672, steps = 8400, cost time = 2.82s
global_step/sec: 34.5165
loss = 0.1473168134689331, steps = 8500, cost time = 2.90s
global_step/sec: 34.5388
loss = 0.14817959070205688, steps = 8600, cost time = 2.90s
global_step/sec: 34.9867
loss = 0.14809554815292358, steps = 8700, cost time = 2.86s
global_step/sec: 34.2509
loss = 0.14646869897842407, steps = 8800, cost time = 2.92s
global_step/sec: 34.7705
loss = 0.14638429880142212, steps = 8900, cost time = 2.88s
global_step/sec: 34.1649
loss = 0.1499808430671692, steps = 9000, cost time = 2.93s
global_step/sec: 34.3539
loss = 0.15901340544223785, steps = 9100, cost time = 2.91s
global_step/sec: 35.1050
loss = 0.15292617678642273, steps = 9200, cost time = 2.85s
global_step/sec: 34.5547
loss = 0.14916254580020905, steps = 9300, cost time = 2.89s
global_step/sec: 32.8227
loss = 0.15729454159736633, steps = 9400, cost time = 3.05s
global_step/sec: 32.7388
loss = 0.13847604393959045, steps = 9500, cost time = 3.05s
global_step/sec: 33.5391
loss = 0.15220332145690918, steps = 9600, cost time = 2.98s
global_step/sec: 33.8674
loss = 0.14676901698112488, steps = 9700, cost time = 2.95s
global_step/sec: 33.0914
loss = 0.1573321521282196, steps = 9800, cost time = 3.02s
global_step/sec: 32.9930
loss = 0.13740967214107513, steps = 9900, cost time = 3.03s
global_step/sec: 32.3822
loss = 0.13924987614154816, steps = 10000, cost time = 3.09s
global_step/sec: 32.2757
loss = 0.1514025777578354, steps = 10100, cost time = 3.10s
global_step/sec: 33.4745
loss = 0.14660492539405823, steps = 10200, cost time = 2.99s
global_step/sec: 33.3609
loss = 0.13701677322387695, steps = 10300, cost time = 3.00s
global_step/sec: 32.5234
loss = 0.1442088782787323, steps = 10400, cost time = 3.07s
global_step/sec: 33.8164
loss = 0.1597544252872467, steps = 10500, cost time = 2.96s
global_step/sec: 33.5220
loss = 0.14725805819034576, steps = 10600, cost time = 2.98s
global_step/sec: 33.0898
loss = 0.160881906747818, steps = 10700, cost time = 3.02s
global_step/sec: 34.2555
loss = 0.1454080045223236, steps = 10800, cost time = 2.92s
global_step/sec: 32.4439
loss = 0.13904976844787598, steps = 10900, cost time = 3.08s
global_step/sec: 34.0848
loss = 0.13963571190834045, steps = 11000, cost time = 2.93s
global_step/sec: 31.9522
loss = 0.14750948548316956, steps = 11100, cost time = 3.13s
global_step/sec: 30.9819
loss = 0.13551029562950134, steps = 11200, cost time = 3.23s
global_step/sec: 31.8188
loss = 0.14422333240509033, steps = 11300, cost time = 3.14s
global_step/sec: 31.7256
loss = 0.14500561356544495, steps = 11400, cost time = 3.15s
global_step/sec: 32.7321
loss = 0.14277905225753784, steps = 11500, cost time = 3.06s
global_step/sec: 32.1343
loss = 0.14052671194076538, steps = 11600, cost time = 3.11s
global_step/sec: 33.2126
loss = 0.1442701518535614, steps = 11700, cost time = 3.01s
global_step/sec: 32.3903
loss = 0.14850029349327087, steps = 11800, cost time = 3.09s
global_step/sec: 32.3923
loss = 0.16276907920837402, steps = 11900, cost time = 3.09s
global_step/sec: 31.3445
loss = 0.1502579003572464, steps = 12000, cost time = 3.19s
global_step/sec: 31.0553
loss = 0.1514594703912735, steps = 12100, cost time = 3.22s
global_step/sec: 31.1189
loss = 0.13319475948810577, steps = 12200, cost time = 3.21s
global_step/sec: 32.2588
loss = 0.1520785540342331, steps = 12300, cost time = 3.10s
global_step/sec: 31.5948
loss = 0.1537199169397354, steps = 12400, cost time = 3.17s
global_step/sec: 30.9412
loss = 0.13502077758312225, steps = 12500, cost time = 3.23s
global_step/sec: 32.0634
loss = 0.1313086599111557, steps = 12600, cost time = 3.12s
global_step/sec: 33.3789
loss = 0.12824758887290955, steps = 12700, cost time = 3.00s
global_step/sec: 32.2426
loss = 0.16023294627666473, steps = 12800, cost time = 3.10s
global_step/sec: 32.5118
loss = 0.1603621393442154, steps = 12900, cost time = 3.08s
global_step/sec: 31.6491
loss = 0.15982848405838013, steps = 13000, cost time = 3.16s
global_step/sec: 31.7663
loss = 0.16447287797927856, steps = 13100, cost time = 3.15s
global_step/sec: 31.2380
loss = 0.16077008843421936, steps = 13200, cost time = 3.20s
global_step/sec: 31.0760
loss = 0.1519053876399994, steps = 13300, cost time = 3.22s
global_step/sec: 31.5357
loss = 0.15285265445709229, steps = 13400, cost time = 3.17s
global_step/sec: 32.3449
loss = 0.1569669246673584, steps = 13500, cost time = 3.09s
global_step/sec: 31.3427
loss = 0.15795257687568665, steps = 13600, cost time = 3.19s
global_step/sec: 31.2917
loss = 0.15492655336856842, steps = 13700, cost time = 3.20s
global_step/sec: 31.9918
loss = 0.1509721577167511, steps = 13800, cost time = 3.13s
global_step/sec: 31.1497
loss = 0.15028774738311768, steps = 13900, cost time = 3.21s
global_step/sec: 32.5229
loss = 0.1596834510564804, steps = 14000, cost time = 3.07s
global_step/sec: 32.2124
loss = 0.16251760721206665, steps = 14100, cost time = 3.10s
global_step/sec: 31.7091
loss = 0.15056559443473816, steps = 14200, cost time = 3.15s
global_step/sec: 31.5337
loss = 0.139993816614151, steps = 14300, cost time = 3.17s
global_step/sec: 30.9811
loss = 0.14443540573120117, steps = 14400, cost time = 3.23s
global_step/sec: 30.7887
loss = 0.1451593041419983, steps = 14500, cost time = 3.25s
global_step/sec: 32.4659
loss = 0.15761317312717438, steps = 14600, cost time = 3.08s
global_step/sec: 31.4070
loss = 0.14624693989753723, steps = 14700, cost time = 3.18s
global_step/sec: 31.6761
loss = 0.15261831879615784, steps = 14800, cost time = 3.16s
global_step/sec: 31.7250
loss = 0.14283594489097595, steps = 14900, cost time = 3.15s
global_step/sec: 31.4389
loss = 0.1539471447467804, steps = 15000, cost time = 3.18s
global_step/sec: 31.2561
loss = 0.13598066568374634, steps = 15100, cost time = 3.20s
global_step/sec: 31.6926
loss = 0.15814782679080963, steps = 15200, cost time = 3.16s
global_step/sec: 31.6097
loss = 0.15964540839195251, steps = 15300, cost time = 3.16s
global_step/sec: 31.3989
loss = 0.1413799673318863, steps = 15400, cost time = 3.18s
global_step/sec: 32.1516
loss = 0.1675327718257904, steps = 15500, cost time = 3.11s
global_step/sec: 32.0160
loss = 0.13238532841205597, steps = 15600, cost time = 3.12s
global_step/sec: 32.1907
loss = 0.11695507913827896, steps = 15700, cost time = 3.11s
global_step/sec: 32.0519
loss = 0.13378646969795227, steps = 15800, cost time = 3.12s
global_step/sec: 32.6527
loss = 0.1558738350868225, steps = 15900, cost time = 3.06s
global_step/sec: 31.9997
loss = 0.15474486351013184, steps = 16000, cost time = 3.13s
global_step/sec: 31.2999
loss = 0.16320860385894775, steps = 16100, cost time = 3.19s
global_step/sec: 31.9451
loss = 0.15620124340057373, steps = 16200, cost time = 3.13s
global_step/sec: 32.2508
loss = 0.1441405862569809, steps = 16300, cost time = 3.10s
global_step/sec: 32.8610
loss = 0.15969890356063843, steps = 16400, cost time = 3.04s
global_step/sec: 31.6295
loss = 0.1605815589427948, steps = 16500, cost time = 3.16s
global_step/sec: 31.7709
loss = 0.14070850610733032, steps = 16600, cost time = 3.15s
global_step/sec: 32.2471
loss = 0.1606501042842865, steps = 16700, cost time = 3.10s
global_step/sec: 31.0452
loss = 0.15501250326633453, steps = 16800, cost time = 3.22s
global_step/sec: 30.7930
loss = 0.13662786781787872, steps = 16900, cost time = 3.25s
global_step/sec: 31.0286
loss = 0.14844337105751038, steps = 17000, cost time = 3.22s
global_step/sec: 31.6269
loss = 0.1426268219947815, steps = 17100, cost time = 3.16s
global_step/sec: 32.4076
loss = 0.13463768362998962, steps = 17200, cost time = 3.09s
global_step/sec: 32.1273
loss = 0.15014079213142395, steps = 17300, cost time = 3.11s
global_step/sec: 33.4726
loss = 0.1456422209739685, steps = 17400, cost time = 2.99s
global_step/sec: 32.7757
loss = 0.13737688958644867, steps = 17500, cost time = 3.05s
global_step/sec: 33.2843
loss = 0.1495347023010254, steps = 17600, cost time = 3.00s
global_step/sec: 31.1670
loss = 0.1541392207145691, steps = 17700, cost time = 3.21s
global_step/sec: 31.5329
loss = 0.14609363675117493, steps = 17800, cost time = 3.17s
global_step/sec: 32.2238
loss = 0.15090429782867432, steps = 17900, cost time = 3.10s
global_step/sec: 33.2815
loss = 0.1303274929523468, steps = 18000, cost time = 3.00s
global_step/sec: 31.4892
loss = 0.13919906318187714, steps = 18100, cost time = 3.18s
global_step/sec: 31.5623
loss = 0.15574726462364197, steps = 18200, cost time = 3.17s
global_step/sec: 32.2332
loss = 0.14516261219978333, steps = 18300, cost time = 3.10s
global_step/sec: 31.6830
loss = 0.1380290687084198, steps = 18400, cost time = 3.16s
global_step/sec: 31.3324
loss = 0.14481647312641144, steps = 18500, cost time = 3.19s
global_step/sec: 31.4505
loss = 0.16679202020168304, steps = 18600, cost time = 3.18s
global_step/sec: 32.7947
loss = 0.1577550172805786, steps = 18700, cost time = 3.05s
global_step/sec: 32.2761
loss = 0.15075728297233582, steps = 18800, cost time = 3.10s
global_step/sec: 31.7661
loss = 0.15231995284557343, steps = 18900, cost time = 3.15s
global_step/sec: 31.3292
loss = 0.14420998096466064, steps = 19000, cost time = 3.19s
global_step/sec: 31.4567
loss = 0.13778063654899597, steps = 19100, cost time = 3.18s
global_step/sec: 32.5647
loss = 0.13510408997535706, steps = 19200, cost time = 3.07s
global_step/sec: 31.6438
loss = 0.15171648561954498, steps = 19300, cost time = 3.16s
global_step/sec: 32.7038
loss = 0.13222622871398926, steps = 19400, cost time = 3.06s
global_step/sec: 30.9236
loss = 0.14721034467220306, steps = 19500, cost time = 3.23s
global_step/sec: 30.8622
loss = 0.1525638997554779, steps = 19600, cost time = 3.24s
global_step/sec: 33.1438
loss = 0.14142560958862305, steps = 19700, cost time = 3.02s
global_step/sec: 32.5002
loss = 0.1309656798839569, steps = 19800, cost time = 3.08s
global_step/sec: 32.3955
loss = 0.13021567463874817, steps = 19900, cost time = 3.09s
global_step/sec: 31.7810
loss = 0.1429516077041626, steps = 20000, cost time = 3.15s
global_step/sec: 31.6820
loss = 0.1420111209154129, steps = 20100, cost time = 3.16s
global_step/sec: 31.9037
loss = 0.16029095649719238, steps = 20200, cost time = 3.13s
global_step/sec: 31.7765
loss = 0.13269101083278656, steps = 20300, cost time = 3.15s
global_step/sec: 31.0129
loss = 0.15088555216789246, steps = 20400, cost time = 3.22s
global_step/sec: 31.1274
loss = 0.14984530210494995, steps = 20500, cost time = 3.21s
global_step/sec: 30.8078
loss = 0.14265115559101105, steps = 20600, cost time = 3.25s
global_step/sec: 30.7837
loss = 0.14637638628482819, steps = 20700, cost time = 3.25s
global_step/sec: 30.9486
loss = 0.1532481610774994, steps = 20800, cost time = 3.23s
global_step/sec: 31.9009
loss = 0.15534263849258423, steps = 20900, cost time = 3.13s
global_step/sec: 31.7246
loss = 0.14772561192512512, steps = 21000, cost time = 3.15s
global_step/sec: 31.4929
loss = 0.12833930552005768, steps = 21100, cost time = 3.18s
global_step/sec: 33.0696
loss = 0.15346479415893555, steps = 21200, cost time = 3.02s
global_step/sec: 32.0022
loss = 0.1350950449705124, steps = 21300, cost time = 3.12s
global_step/sec: 32.7592
loss = 0.12519454956054688, steps = 21400, cost time = 3.05s
global_step/sec: 33.0022
loss = 0.1378994733095169, steps = 21500, cost time = 3.03s
global_step/sec: 33.2659
loss = 0.14440864324569702, steps = 21600, cost time = 3.01s
global_step/sec: 32.7560
loss = 0.1538916379213333, steps = 21700, cost time = 3.05s
global_step/sec: 29.7961
loss = 0.14545631408691406, steps = 21800, cost time = 3.36s
global_step/sec: 31.9300
loss = 0.14222168922424316, steps = 21900, cost time = 3.13s
global_step/sec: 31.0574
loss = 0.1557142734527588, steps = 22000, cost time = 3.22s
global_step/sec: 30.9699
loss = 0.14836660027503967, steps = 22100, cost time = 3.23s
global_step/sec: 31.0610
loss = 0.15235260128974915, steps = 22200, cost time = 3.22s
global_step/sec: 32.5119
loss = 0.13039752840995789, steps = 22300, cost time = 3.08s
global_step/sec: 32.3307
loss = 0.1592385619878769, steps = 22400, cost time = 3.09s
global_step/sec: 31.9900
loss = 0.1281028389930725, steps = 22500, cost time = 3.13s
global_step/sec: 32.4000
loss = 0.15158390998840332, steps = 22600, cost time = 3.09s
global_step/sec: 31.1205
loss = 0.12976010143756866, steps = 22700, cost time = 3.21s
global_step/sec: 31.0960
loss = 0.12627603113651276, steps = 22800, cost time = 3.22s
global_step/sec: 31.9997
loss = 0.14485357701778412, steps = 22900, cost time = 3.13s
global_step/sec: 32.3188
loss = 0.15012413263320923, steps = 23000, cost time = 3.09s
global_step/sec: 31.5898
loss = 0.15518081188201904, steps = 23100, cost time = 3.17s
global_step/sec: 31.7884
loss = 0.14613428711891174, steps = 23200, cost time = 3.15s
global_step/sec: 32.0059
loss = 0.15027397871017456, steps = 23300, cost time = 3.12s
global_step/sec: 31.3581
loss = 0.147233247756958, steps = 23400, cost time = 3.19s
global_step/sec: 32.4575
loss = 0.14135850965976715, steps = 23500, cost time = 3.08s
global_step/sec: 32.7385
loss = 0.14926740527153015, steps = 23600, cost time = 3.05s
global_step/sec: 31.8180
loss = 0.1361660659313202, steps = 23700, cost time = 3.14s
global_step/sec: 32.6731
loss = 0.13572727143764496, steps = 23800, cost time = 3.06s
global_step/sec: 32.4670
loss = 0.12985682487487793, steps = 23900, cost time = 3.08s
global_step/sec: 32.1558
loss = 0.14070303738117218, steps = 24000, cost time = 3.11s
global_step/sec: 31.3043
loss = 0.1278390884399414, steps = 24100, cost time = 3.19s
global_step/sec: 31.7531
loss = 0.13023222982883453, steps = 24200, cost time = 3.15s
global_step/sec: 32.4546
loss = 0.15336161851882935, steps = 24300, cost time = 3.08s
global_step/sec: 30.7269
loss = 0.14110207557678223, steps = 24400, cost time = 3.25s
global_step/sec: 31.7810
loss = 0.1446845531463623, steps = 24500, cost time = 3.15s
global_step/sec: 31.3369
loss = 0.1496843695640564, steps = 24600, cost time = 3.19s
global_step/sec: 31.2664
loss = 0.12434868514537811, steps = 24700, cost time = 3.20s
global_step/sec: 32.3711
loss = 0.15094727277755737, steps = 24800, cost time = 3.09s
global_step/sec: 31.3978
loss = 0.13611170649528503, steps = 24900, cost time = 3.18s
global_step/sec: 31.1743
loss = 0.1529425084590912, steps = 25000, cost time = 3.21s
global_step/sec: 31.9760
loss = 0.14427530765533447, steps = 25100, cost time = 3.13s
global_step/sec: 31.8865
loss = 0.14413730800151825, steps = 25200, cost time = 3.14s
global_step/sec: 31.8678
loss = 0.1308734118938446, steps = 25300, cost time = 3.14s
global_step/sec: 31.0892
loss = 0.12949763238430023, steps = 25400, cost time = 3.22s
global_step/sec: 32.0247
loss = 0.14807502925395966, steps = 25500, cost time = 3.12s
global_step/sec: 32.4812
loss = 0.1374351680278778, steps = 25600, cost time = 3.08s
global_step/sec: 32.5179
loss = 0.13054504990577698, steps = 25700, cost time = 3.08s
global_step/sec: 30.6170
loss = 0.1400117427110672, steps = 25800, cost time = 3.27s
global_step/sec: 32.2989
loss = 0.15117502212524414, steps = 25900, cost time = 3.10s
global_step/sec: 31.3876
loss = 0.14952774345874786, steps = 26000, cost time = 3.19s
global_step/sec: 32.2324
loss = 0.13663843274116516, steps = 26100, cost time = 3.10s
global_step/sec: 31.8315
loss = 0.12610599398612976, steps = 26200, cost time = 3.14s
global_step/sec: 31.9792
loss = 0.13768739998340607, steps = 26300, cost time = 3.13s
global_step/sec: 31.8774
loss = 0.14431530237197876, steps = 26400, cost time = 3.14s
global_step/sec: 32.4117
loss = 0.15033629536628723, steps = 26500, cost time = 3.09s
global_step/sec: 33.1348
loss = 0.1415543407201767, steps = 26600, cost time = 3.02s
global_step/sec: 32.4102
loss = 0.13588730990886688, steps = 26700, cost time = 3.09s
global_step/sec: 31.8482
loss = 0.14593926072120667, steps = 26800, cost time = 3.14s
global_step/sec: 32.7699
loss = 0.13536006212234497, steps = 26900, cost time = 3.05s
global_step/sec: 32.3348
loss = 0.14834696054458618, steps = 27000, cost time = 3.09s
global_step/sec: 31.1812
loss = 0.14337828755378723, steps = 27100, cost time = 3.21s
global_step/sec: 31.2178
loss = 0.14050282537937164, steps = 27200, cost time = 3.20s
global_step/sec: 32.1085
loss = 0.14647115767002106, steps = 27300, cost time = 3.11s
global_step/sec: 31.4402
loss = 0.13065464794635773, steps = 27400, cost time = 3.18s
global_step/sec: 32.4733
loss = 0.13777655363082886, steps = 27500, cost time = 3.08s
global_step/sec: 31.9246
loss = 0.12939512729644775, steps = 27600, cost time = 3.13s
global_step/sec: 31.4686
loss = 0.15769550204277039, steps = 27700, cost time = 3.18s
global_step/sec: 30.9887
loss = 0.13393110036849976, steps = 27800, cost time = 3.23s
global_step/sec: 31.4599
loss = 0.14343026280403137, steps = 27900, cost time = 3.18s
global_step/sec: 31.8723
loss = 0.1642138659954071, steps = 28000, cost time = 3.14s
global_step/sec: 30.9029
loss = 0.13401401042938232, steps = 28100, cost time = 3.24s
global_step/sec: 32.1060
loss = 0.12778085470199585, steps = 28200, cost time = 3.11s
global_step/sec: 32.9439
loss = 0.12472446262836456, steps = 28300, cost time = 3.04s
global_step/sec: 30.8595
loss = 0.1268528699874878, steps = 28400, cost time = 3.24s
global_step/sec: 30.8208
loss = 0.1501941978931427, steps = 28500, cost time = 3.24s
global_step/sec: 32.0303
loss = 0.15666598081588745, steps = 28600, cost time = 3.12s
global_step/sec: 32.1868
loss = 0.17138835787773132, steps = 28700, cost time = 3.11s
global_step/sec: 31.3897
loss = 0.14701172709465027, steps = 28800, cost time = 3.19s
global_step/sec: 31.9936
loss = 0.1697140485048294, steps = 28900, cost time = 3.13s
global_step/sec: 31.6539
loss = 0.15283997356891632, steps = 29000, cost time = 3.16s
global_step/sec: 31.9091
loss = 0.15753866732120514, steps = 29100, cost time = 3.13s
global_step/sec: 31.4161
loss = 0.15631011128425598, steps = 29200, cost time = 3.18s
global_step/sec: 31.3081
loss = 0.1460934579372406, steps = 29300, cost time = 3.19s
global_step/sec: 31.3026
loss = 0.14337997138500214, steps = 29400, cost time = 3.19s
global_step/sec: 32.4152
loss = 0.155253067612648, steps = 29500, cost time = 3.08s
global_step/sec: 30.9083
loss = 0.1633923202753067, steps = 29600, cost time = 3.24s
global_step/sec: 30.9759
loss = 0.14996999502182007, steps = 29700, cost time = 3.23s
global_step/sec: 32.5287
loss = 0.13444401323795319, steps = 29800, cost time = 3.07s
global_step/sec: 32.8546
loss = 0.1446380466222763, steps = 29900, cost time = 3.04s
global_step/sec: 32.3852
loss = 0.14379540085792542, steps = 30000, cost time = 3.09s
global_step/sec: 31.5382
loss = 0.14444789290428162, steps = 30100, cost time = 3.17s
global_step/sec: 32.4332
loss = 0.1446409672498703, steps = 30200, cost time = 3.08s
global_step/sec: 31.3563
loss = 0.1537182331085205, steps = 30300, cost time = 3.19s
global_step/sec: 31.4486
loss = 0.15231159329414368, steps = 30400, cost time = 3.18s
global_step/sec: 31.8222
loss = 0.14147479832172394, steps = 30500, cost time = 3.14s
global_step/sec: 31.3510
loss = 0.15590068697929382, steps = 30600, cost time = 3.19s
global_step/sec: 31.6734
loss = 0.1241668313741684, steps = 30700, cost time = 3.16s
global_step/sec: 32.4306
loss = 0.14294682443141937, steps = 30800, cost time = 3.08s
global_step/sec: 31.9582
loss = 0.12958067655563354, steps = 30900, cost time = 3.13s
global_step/sec: 32.1398
loss = 0.13132086396217346, steps = 31000, cost time = 3.11s
global_step/sec: 31.2456
loss = 0.1577928513288498, steps = 31100, cost time = 3.20s
global_step/sec: 32.5709
loss = 0.13948464393615723, steps = 31200, cost time = 3.07s
global_step/sec: 31.1376
loss = 0.1189308613538742, steps = 31300, cost time = 3.21s
global_step/sec: 32.1549
loss = 0.14350971579551697, steps = 31400, cost time = 3.11s
global_step/sec: 31.8484
loss = 0.1421525925397873, steps = 31500, cost time = 3.14s
global_step/sec: 31.4155
loss = 0.1438465565443039, steps = 31600, cost time = 3.18s
global_step/sec: 32.0347
loss = 0.159810408949852, steps = 31700, cost time = 3.12s
global_step/sec: 31.6427
loss = 0.1528334766626358, steps = 31800, cost time = 3.16s
global_step/sec: 31.7325
loss = 0.15120932459831238, steps = 31900, cost time = 3.15s
global_step/sec: 31.6968
loss = 0.12693116068840027, steps = 32000, cost time = 3.15s
global_step/sec: 32.5334
loss = 0.1516932249069214, steps = 32100, cost time = 3.07s
global_step/sec: 31.6216
loss = 0.14492009580135345, steps = 32200, cost time = 3.16s
global_step/sec: 34.1605
loss = 0.13759498298168182, steps = 32300, cost time = 2.93s
global_step/sec: 31.9727
loss = 0.14161105453968048, steps = 32400, cost time = 3.13s
global_step/sec: 32.4615
loss = 0.14400336146354675, steps = 32500, cost time = 3.08s
global_step/sec: 31.5882
loss = 0.1544322371482849, steps = 32600, cost time = 3.17s
global_step/sec: 31.6029
loss = 0.1487019658088684, steps = 32700, cost time = 3.16s
global_step/sec: 30.9899
loss = 0.13181044161319733, steps = 32800, cost time = 3.23s
global_step/sec: 31.7631
loss = 0.1459081918001175, steps = 32900, cost time = 3.15s
global_step/sec: 31.4070
loss = 0.141768217086792, steps = 33000, cost time = 3.18s
global_step/sec: 30.7578
loss = 0.12905451655387878, steps = 33100, cost time = 3.25s
global_step/sec: 32.3757
loss = 0.13165810704231262, steps = 33200, cost time = 3.09s
global_step/sec: 31.3692
loss = 0.13707365095615387, steps = 33300, cost time = 3.19s
global_step/sec: 31.0755
loss = 0.15453921258449554, steps = 33400, cost time = 3.22s
global_step/sec: 32.0781
loss = 0.13260820508003235, steps = 33500, cost time = 3.12s
global_step/sec: 32.1785
loss = 0.14076462388038635, steps = 33600, cost time = 3.11s
global_step/sec: 31.8443
loss = 0.12898807227611542, steps = 33700, cost time = 3.14s
global_step/sec: 30.8097
loss = 0.13163892924785614, steps = 33800, cost time = 3.25s
global_step/sec: 32.5057
loss = 0.13023418188095093, steps = 33900, cost time = 3.08s
global_step/sec: 31.6770
loss = 0.14896395802497864, steps = 34000, cost time = 3.16s
global_step/sec: 31.2830
loss = 0.12143580615520477, steps = 34100, cost time = 3.20s
global_step/sec: 31.0518
loss = 0.14866825938224792, steps = 34200, cost time = 3.22s
global_step/sec: 30.8256
loss = 0.12698189914226532, steps = 34300, cost time = 3.24s
global_step/sec: 32.7908
loss = 0.13731862604618073, steps = 34400, cost time = 3.05s
global_step/sec: 32.5921
loss = 0.13839736580848694, steps = 34500, cost time = 3.07s
global_step/sec: 32.6312
loss = 0.14287130534648895, steps = 34600, cost time = 3.06s
global_step/sec: 32.4230
loss = 0.14030051231384277, steps = 34700, cost time = 3.08s
global_step/sec: 32.1675
loss = 0.15826678276062012, steps = 34800, cost time = 3.11s
global_step/sec: 33.4893
loss = 0.1483933925628662, steps = 34900, cost time = 2.99s
global_step/sec: 32.1293
loss = 0.12927892804145813, steps = 35000, cost time = 3.11s
global_step/sec: 31.7685
loss = 0.14555062353610992, steps = 35100, cost time = 3.15s
global_step/sec: 31.8590
loss = 0.13159500062465668, steps = 35200, cost time = 3.14s
global_step/sec: 30.8735
loss = 0.1285967230796814, steps = 35300, cost time = 3.24s
global_step/sec: 31.1858
loss = 0.14391174912452698, steps = 35400, cost time = 3.21s
global_step/sec: 31.6498
loss = 0.1259552538394928, steps = 35500, cost time = 3.16s
global_step/sec: 32.1031
loss = 0.15380895137786865, steps = 35600, cost time = 3.11s
global_step/sec: 32.6402
loss = 0.1335432529449463, steps = 35700, cost time = 3.06s
global_step/sec: 31.9418
loss = 0.1406601518392563, steps = 35800, cost time = 3.13s
global_step/sec: 31.0012
loss = 0.13997551798820496, steps = 35900, cost time = 3.23s
global_step/sec: 31.2870
loss = 0.13737419247627258, steps = 36000, cost time = 3.20s
global_step/sec: 31.9118
loss = 0.13562694191932678, steps = 36100, cost time = 3.13s
global_step/sec: 31.4046
loss = 0.14633026719093323, steps = 36200, cost time = 3.18s
global_step/sec: 31.3262
loss = 0.14049121737480164, steps = 36300, cost time = 3.19s
global_step/sec: 31.7435
loss = 0.1375635415315628, steps = 36400, cost time = 3.15s
global_step/sec: 31.4933
loss = 0.1490444839000702, steps = 36500, cost time = 3.18s
global_step/sec: 31.8106
loss = 0.13559703528881073, steps = 36600, cost time = 3.14s
global_step/sec: 32.6040
loss = 0.13049232959747314, steps = 36700, cost time = 3.07s
global_step/sec: 32.2013
loss = 0.16005855798721313, steps = 36800, cost time = 3.11s
global_step/sec: 31.3759
loss = 0.13618773221969604, steps = 36900, cost time = 3.19s
global_step/sec: 31.1474
loss = 0.12438514083623886, steps = 37000, cost time = 3.21s
global_step/sec: 31.3650
loss = 0.16293060779571533, steps = 37100, cost time = 3.19s
global_step/sec: 30.4323
loss = 0.1388835906982422, steps = 37200, cost time = 3.29s
global_step/sec: 31.0625
loss = 0.12646380066871643, steps = 37300, cost time = 3.22s
global_step/sec: 31.3263
loss = 0.14469915628433228, steps = 37400, cost time = 3.19s
global_step/sec: 30.7356
loss = 0.1371924728155136, steps = 37500, cost time = 3.25s
global_step/sec: 31.7173
loss = 0.13299402594566345, steps = 37600, cost time = 3.15s
global_step/sec: 30.8755
loss = 0.14603036642074585, steps = 37700, cost time = 3.24s
global_step/sec: 31.4180
loss = 0.12341919541358948, steps = 37800, cost time = 3.18s
global_step/sec: 31.0047
loss = 0.15383391082286835, steps = 37900, cost time = 3.23s
global_step/sec: 31.6180
loss = 0.14336425065994263, steps = 38000, cost time = 3.16s
global_step/sec: 32.1937
loss = 0.15218794345855713, steps = 38100, cost time = 3.11s
global_step/sec: 32.2143
loss = 0.13867661356925964, steps = 38200, cost time = 3.10s
global_step/sec: 31.9159
loss = 0.14662253856658936, steps = 38300, cost time = 3.13s
global_step/sec: 30.9111
loss = 0.15188078582286835, steps = 38400, cost time = 3.24s
global_step/sec: 32.0092
loss = 0.1296248584985733, steps = 38500, cost time = 3.12s
global_step/sec: 32.7886
loss = 0.13522151112556458, steps = 38600, cost time = 3.05s
global_step/sec: 31.6274
loss = 0.13112396001815796, steps = 38700, cost time = 3.16s
global_step/sec: 31.5452
loss = 0.13444063067436218, steps = 38800, cost time = 3.17s
global_step/sec: 31.7537
loss = 0.13652454316616058, steps = 38900, cost time = 3.15s
global_step/sec: 32.0327
loss = 0.12997685372829437, steps = 39000, cost time = 3.12s
global_step/sec: 32.3507
loss = 0.12949120998382568, steps = 39100, cost time = 3.09s
global_step/sec: 32.5390
loss = 0.1474418342113495, steps = 39200, cost time = 3.07s
global_step/sec: 31.9334
loss = 0.13707859814167023, steps = 39300, cost time = 3.13s
global_step/sec: 32.7943
loss = 0.12484728544950485, steps = 39400, cost time = 3.05s
global_step/sec: 31.7594
loss = 0.13515615463256836, steps = 39500, cost time = 3.15s
global_step/sec: 32.1811
loss = 0.14626827836036682, steps = 39600, cost time = 3.11s
global_step/sec: 30.9827
loss = 0.13557642698287964, steps = 39700, cost time = 3.23s
global_step/sec: 30.9100
loss = 0.1367693841457367, steps = 39800, cost time = 3.24s
global_step/sec: 30.5255
loss = 0.1317124217748642, steps = 39900, cost time = 3.28s
global_step/sec: 31.0896
loss = 0.11937782168388367, steps = 40000, cost time = 3.22s
global_step/sec: 31.8495
loss = 0.13896819949150085, steps = 40100, cost time = 3.14s
global_step/sec: 32.9750
loss = 0.14758005738258362, steps = 40200, cost time = 3.03s
global_step/sec: 32.2352
loss = 0.12854543328285217, steps = 40300, cost time = 3.10s
global_step/sec: 32.3473
loss = 0.13516363501548767, steps = 40400, cost time = 3.09s
global_step/sec: 33.4786
loss = 0.13615509867668152, steps = 40500, cost time = 2.99s
global_step/sec: 32.0085
loss = 0.14083150029182434, steps = 40600, cost time = 3.12s
global_step/sec: 32.4781
loss = 0.1388491988182068, steps = 40700, cost time = 3.08s
global_step/sec: 32.4492
loss = 0.15998521447181702, steps = 40800, cost time = 3.08s
global_step/sec: 32.5315
loss = 0.13906386494636536, steps = 40900, cost time = 3.07s
global_step/sec: 31.1296
loss = 0.14247295260429382, steps = 41000, cost time = 3.21s
global_step/sec: 32.1746
loss = 0.13251808285713196, steps = 41100, cost time = 3.11s
global_step/sec: 30.8993
loss = 0.13434459269046783, steps = 41200, cost time = 3.24s
global_step/sec: 33.0093
loss = 0.1467447280883789, steps = 41300, cost time = 3.03s
global_step/sec: 31.7862
loss = 0.14429998397827148, steps = 41400, cost time = 3.15s
global_step/sec: 31.1474
loss = 0.1471082717180252, steps = 41500, cost time = 3.21s
global_step/sec: 32.1258
loss = 0.12647266685962677, steps = 41600, cost time = 3.11s
global_step/sec: 32.4321
loss = 0.1449999213218689, steps = 41700, cost time = 3.08s
global_step/sec: 32.3079
loss = 0.1485961228609085, steps = 41800, cost time = 3.10s
global_step/sec: 32.7580
loss = 0.1294856071472168, steps = 41900, cost time = 3.05s
global_step/sec: 31.9233
loss = 0.14943809807300568, steps = 42000, cost time = 3.13s
global_step/sec: 31.2268
loss = 0.13209417462348938, steps = 42100, cost time = 3.20s
global_step/sec: 31.1431
loss = 0.11722361296415329, steps = 42200, cost time = 3.21s
global_step/sec: 31.5547
loss = 0.1514451503753662, steps = 42300, cost time = 3.17s
global_step/sec: 30.7795
loss = 0.13525037467479706, steps = 42400, cost time = 3.25s
global_step/sec: 30.2142
loss = 0.12579940259456635, steps = 42500, cost time = 3.31s
global_step/sec: 32.0375
loss = 0.12570279836654663, steps = 42600, cost time = 3.12s
global_step/sec: 32.3178
loss = 0.12736845016479492, steps = 42700, cost time = 3.09s
global_step/sec: 31.6877
loss = 0.13924483954906464, steps = 42800, cost time = 3.16s
global_step/sec: 32.5341
loss = 0.139236181974411, steps = 42900, cost time = 3.07s
global_step/sec: 32.0429
loss = 0.14315536618232727, steps = 43000, cost time = 3.12s
global_step/sec: 31.9775
loss = 0.12913835048675537, steps = 43100, cost time = 3.13s
global_step/sec: 31.2465
loss = 0.13361284136772156, steps = 43200, cost time = 3.20s
global_step/sec: 31.6395
loss = 0.1243346780538559, steps = 43300, cost time = 3.16s
global_step/sec: 33.7230
loss = 0.13884323835372925, steps = 43400, cost time = 2.97s
global_step/sec: 33.3802
loss = 0.13327597081661224, steps = 43500, cost time = 3.00s
global_step/sec: 31.3943
loss = 0.12438669055700302, steps = 43600, cost time = 3.19s
global_step/sec: 32.1736
loss = 0.14948579668998718, steps = 43700, cost time = 3.11s
global_step/sec: 32.4554
loss = 0.1320967972278595, steps = 43800, cost time = 3.08s
global_step/sec: 32.0758
loss = 0.13477623462677002, steps = 43900, cost time = 3.12s
global_step/sec: 32.3488
loss = 0.12163595855236053, steps = 44000, cost time = 3.09s
global_step/sec: 32.3386
loss = 0.13017024099826813, steps = 44100, cost time = 3.09s
global_step/sec: 31.9800
loss = 0.14153441786766052, steps = 44200, cost time = 3.13s
global_step/sec: 32.4012
loss = 0.14267784357070923, steps = 44300, cost time = 3.09s
global_step/sec: 31.7120
loss = 0.1417575180530548, steps = 44400, cost time = 3.15s
global_step/sec: 32.7607
loss = 0.14334452152252197, steps = 44500, cost time = 3.05s
global_step/sec: 32.2211
loss = 0.13248586654663086, steps = 44600, cost time = 3.10s
global_step/sec: 32.0936
loss = 0.13691800832748413, steps = 44700, cost time = 3.12s
global_step/sec: 31.6959
loss = 0.13841530680656433, steps = 44800, cost time = 3.15s
global_step/sec: 31.4268
loss = 0.15784887969493866, steps = 44900, cost time = 3.18s
global_step/sec: 31.5163
loss = 0.13927721977233887, steps = 45000, cost time = 3.17s
global_step/sec: 32.9533
loss = 0.13723275065422058, steps = 45100, cost time = 3.03s
global_step/sec: 31.8570
loss = 0.1308629810810089, steps = 45200, cost time = 3.14s
global_step/sec: 31.8142
loss = 0.14943137764930725, steps = 45300, cost time = 3.14s
global_step/sec: 31.9530
loss = 0.12606853246688843, steps = 45400, cost time = 3.13s
global_step/sec: 32.0977
loss = 0.14226463437080383, steps = 45500, cost time = 3.12s
global_step/sec: 31.3100
loss = 0.14097875356674194, steps = 45600, cost time = 3.19s
global_step/sec: 31.0912
loss = 0.12568366527557373, steps = 45700, cost time = 3.22s
global_step/sec: 31.3012
loss = 0.1451222449541092, steps = 45800, cost time = 3.19s
global_step/sec: 32.8658
loss = 0.12322445958852768, steps = 45900, cost time = 3.04s
global_step/sec: 32.9484
loss = 0.15249934792518616, steps = 46000, cost time = 3.04s
global_step/sec: 31.9029
loss = 0.13859693706035614, steps = 46100, cost time = 3.13s
global_step/sec: 30.9522
loss = 0.13406360149383545, steps = 46200, cost time = 3.23s
global_step/sec: 31.2333
loss = 0.14067134261131287, steps = 46300, cost time = 3.20s
global_step/sec: 32.7521
loss = 0.13342715799808502, steps = 46400, cost time = 3.05s
global_step/sec: 31.4902
loss = 0.15373924374580383, steps = 46500, cost time = 3.18s
global_step/sec: 31.1623
loss = 0.13501223921775818, steps = 46600, cost time = 3.21s
global_step/sec: 31.8178
loss = 0.12999966740608215, steps = 46700, cost time = 3.14s
global_step/sec: 30.8208
loss = 0.12905648350715637, steps = 46800, cost time = 3.24s
global_step/sec: 31.5507
loss = 0.12679626047611237, steps = 46900, cost time = 3.17s
global_step/sec: 31.3628
loss = 0.12075870484113693, steps = 47000, cost time = 3.19s
global_step/sec: 32.5377
loss = 0.14190037548542023, steps = 47100, cost time = 3.07s
global_step/sec: 31.8644
loss = 0.13529765605926514, steps = 47200, cost time = 3.14s
global_step/sec: 31.5031
loss = 0.12821000814437866, steps = 47300, cost time = 3.17s
global_step/sec: 32.0329
loss = 0.15774603188037872, steps = 47400, cost time = 3.12s
global_step/sec: 31.9730
loss = 0.1393674910068512, steps = 47500, cost time = 3.13s
global_step/sec: 32.0068
loss = 0.14887461066246033, steps = 47600, cost time = 3.12s
global_step/sec: 32.0230
loss = 0.13430975377559662, steps = 47700, cost time = 3.12s
global_step/sec: 32.1072
loss = 0.13565555214881897, steps = 47800, cost time = 3.11s
global_step/sec: 32.0512
loss = 0.14818339049816132, steps = 47900, cost time = 3.12s
global_step/sec: 31.2509
loss = 0.12850706279277802, steps = 48000, cost time = 3.20s
global_step/sec: 31.4591
loss = 0.14529715478420258, steps = 48100, cost time = 3.18s
global_step/sec: 31.3284
loss = 0.12837721407413483, steps = 48200, cost time = 3.19s
global_step/sec: 32.3403
loss = 0.13751868903636932, steps = 48300, cost time = 3.09s
global_step/sec: 32.0626
loss = 0.11873841285705566, steps = 48400, cost time = 3.12s
global_step/sec: 30.1954
loss = 0.1346719115972519, steps = 48500, cost time = 3.31s
global_step/sec: 31.9847
loss = 0.14016854763031006, steps = 48600, cost time = 3.13s
global_step/sec: 32.1768
loss = 0.13022886216640472, steps = 48700, cost time = 3.11s
global_step/sec: 29.9158
loss = 0.12104490399360657, steps = 48800, cost time = 3.34s
global_step/sec: 30.1736
loss = 0.11920763552188873, steps = 48900, cost time = 3.31s
global_step/sec: 30.3908
loss = 0.13299991190433502, steps = 49000, cost time = 3.29s
global_step/sec: 30.0761
loss = 0.15017566084861755, steps = 49100, cost time = 3.32s
global_step/sec: 30.5038
loss = 0.14131295680999756, steps = 49200, cost time = 3.28s
global_step/sec: 31.6446
loss = 0.14052072167396545, steps = 49300, cost time = 3.16s
global_step/sec: 29.4932
loss = 0.13382558524608612, steps = 49400, cost time = 3.39s
global_step/sec: 31.7370
loss = 0.1370130181312561, steps = 49500, cost time = 3.15s
global_step/sec: 30.9400
loss = 0.1445629596710205, steps = 49600, cost time = 3.23s
global_step/sec: 30.9072
loss = 0.14489859342575073, steps = 49700, cost time = 3.24s
global_step/sec: 29.8609
loss = 0.13267871737480164, steps = 49800, cost time = 3.35s
global_step/sec: 29.4234
loss = 0.121336929500103, steps = 49900, cost time = 3.40s
global_step/sec: 30.5294
loss = 0.12539082765579224, steps = 50000, cost time = 3.28s
global_step/sec: 29.4095
loss = 0.1450633704662323, steps = 50100, cost time = 3.40s
global_step/sec: 30.1074
loss = 0.1296338438987732, steps = 50200, cost time = 3.32s
global_step/sec: 30.2443
loss = 0.1400429606437683, steps = 50300, cost time = 3.31s
global_step/sec: 30.1519
loss = 0.1228918582201004, steps = 50400, cost time = 3.32s
global_step/sec: 29.4430
loss = 0.14537933468818665, steps = 50500, cost time = 3.40s
global_step/sec: 31.8949
loss = 0.1224958673119545, steps = 50600, cost time = 3.14s
global_step/sec: 31.2509
loss = 0.13567295670509338, steps = 50700, cost time = 3.20s
global_step/sec: 31.8937
loss = 0.15048596262931824, steps = 50800, cost time = 3.14s
global_step/sec: 31.2626
loss = 0.1388595551252365, steps = 50900, cost time = 3.20s
global_step/sec: 32.0020
loss = 0.13057996332645416, steps = 51000, cost time = 3.12s
global_step/sec: 32.0451
loss = 0.15418465435504913, steps = 51100, cost time = 3.12s
global_step/sec: 31.6815
loss = 0.12874731421470642, steps = 51200, cost time = 3.16s
global_step/sec: 31.9080
loss = 0.12687605619430542, steps = 51300, cost time = 3.13s
global_step/sec: 31.6940
loss = 0.147504985332489, steps = 51400, cost time = 3.16s
global_step/sec: 31.0524
loss = 0.14438527822494507, steps = 51500, cost time = 3.22s
global_step/sec: 31.1466
loss = 0.12407158315181732, steps = 51600, cost time = 3.21s
global_step/sec: 30.7916
loss = 0.1270056813955307, steps = 51700, cost time = 3.25s
global_step/sec: 30.0559
loss = 0.1158193051815033, steps = 51800, cost time = 3.33s
global_step/sec: 33.4260
loss = 0.11953958868980408, steps = 51900, cost time = 2.99s
global_step/sec: 32.6855
loss = 0.14013323187828064, steps = 52000, cost time = 3.06s
global_step/sec: 32.0612
loss = 0.12035782635211945, steps = 52100, cost time = 3.12s
global_step/sec: 29.1282
loss = 0.1315278559923172, steps = 52200, cost time = 3.43s
global_step/sec: 31.2692
loss = 0.13111738860607147, steps = 52300, cost time = 3.20s
global_step/sec: 31.9279
loss = 0.1269110143184662, steps = 52400, cost time = 3.13s
global_step/sec: 31.4820
loss = 0.13466030359268188, steps = 52500, cost time = 3.18s
global_step/sec: 30.9085
loss = 0.1272006332874298, steps = 52600, cost time = 3.24s
global_step/sec: 31.7906
loss = 0.1336439996957779, steps = 52700, cost time = 3.15s
global_step/sec: 31.7339
loss = 0.13943743705749512, steps = 52800, cost time = 3.15s
global_step/sec: 31.6979
loss = 0.12480379641056061, steps = 52900, cost time = 3.15s
global_step/sec: 31.5055
loss = 0.1540450155735016, steps = 53000, cost time = 3.17s
global_step/sec: 32.2068
loss = 0.1415492445230484, steps = 53100, cost time = 3.10s
global_step/sec: 30.9573
loss = 0.15804703533649445, steps = 53200, cost time = 3.23s
global_step/sec: 32.4651
loss = 0.1578349471092224, steps = 53300, cost time = 3.08s
global_step/sec: 31.9524
loss = 0.13802175223827362, steps = 53400, cost time = 3.13s
global_step/sec: 31.4681
loss = 0.14472046494483948, steps = 53500, cost time = 3.18s
global_step/sec: 32.3175
loss = 0.1263362616300583, steps = 53600, cost time = 3.09s
global_step/sec: 30.9449
loss = 0.12804284691810608, steps = 53700, cost time = 3.23s
global_step/sec: 32.9034
loss = 0.12810708582401276, steps = 53800, cost time = 3.04s
global_step/sec: 31.8325
loss = 0.133640319108963, steps = 53900, cost time = 3.14s
global_step/sec: 31.3810
loss = 0.13887713849544525, steps = 54000, cost time = 3.19s
global_step/sec: 31.0860
loss = 0.14040586352348328, steps = 54100, cost time = 3.22s
global_step/sec: 31.5195
loss = 0.13310104608535767, steps = 54200, cost time = 3.17s
global_step/sec: 32.4885
loss = 0.11753477156162262, steps = 54300, cost time = 3.08s
global_step/sec: 31.3452
loss = 0.12877905368804932, steps = 54400, cost time = 3.19s
global_step/sec: 32.4746
loss = 0.12844884395599365, steps = 54500, cost time = 3.08s
global_step/sec: 31.7586
loss = 0.1440877914428711, steps = 54600, cost time = 3.15s
global_step/sec: 32.8623
loss = 0.1315959244966507, steps = 54700, cost time = 3.04s
global_step/sec: 32.0613
loss = 0.1299949288368225, steps = 54800, cost time = 3.12s
global_step/sec: 31.6597
loss = 0.12056298553943634, steps = 54900, cost time = 3.16s
global_step/sec: 31.1753
loss = 0.1441510021686554, steps = 55000, cost time = 3.21s
global_step/sec: 30.1422
loss = 0.134762242436409, steps = 55100, cost time = 3.32s
global_step/sec: 31.6607
loss = 0.1253090798854828, steps = 55200, cost time = 3.16s
global_step/sec: 31.3852
loss = 0.1268511265516281, steps = 55300, cost time = 3.19s
global_step/sec: 31.1190
loss = 0.12060695886611938, steps = 55400, cost time = 3.21s
global_step/sec: 33.2513
loss = 0.13196860253810883, steps = 55500, cost time = 3.01s
global_step/sec: 31.6613
loss = 0.12001974880695343, steps = 55600, cost time = 3.16s
global_step/sec: 32.1588
loss = 0.12754672765731812, steps = 55700, cost time = 3.11s
global_step/sec: 32.6627
loss = 0.13554935157299042, steps = 55800, cost time = 3.06s
global_step/sec: 31.5430
loss = 0.15001961588859558, steps = 55900, cost time = 3.17s
global_step/sec: 31.2739
loss = 0.12640023231506348, steps = 56000, cost time = 3.20s
global_step/sec: 32.7188
loss = 0.1266298145055771, steps = 56100, cost time = 3.06s
global_step/sec: 31.8628
loss = 0.13121235370635986, steps = 56200, cost time = 3.14s
global_step/sec: 32.2393
loss = 0.14119461178779602, steps = 56300, cost time = 3.10s
global_step/sec: 31.1542
loss = 0.1200222373008728, steps = 56400, cost time = 3.21s
global_step/sec: 32.1845
loss = 0.1487836241722107, steps = 56500, cost time = 3.11s
global_step/sec: 32.1219
loss = 0.13132528960704803, steps = 56600, cost time = 3.11s
global_step/sec: 31.1632
loss = 0.1441793143749237, steps = 56700, cost time = 3.21s
global_step/sec: 32.3186
loss = 0.12325279414653778, steps = 56800, cost time = 3.09s
global_step/sec: 30.9179
loss = 0.11505747586488724, steps = 56900, cost time = 3.23s
global_step/sec: 31.9720
loss = 0.11377610266208649, steps = 57000, cost time = 3.13s
global_step/sec: 31.3643
loss = 0.13526928424835205, steps = 57100, cost time = 3.19s
global_step/sec: 30.5921
loss = 0.127645343542099, steps = 57200, cost time = 3.27s
global_step/sec: 31.6382
loss = 0.12939278781414032, steps = 57300, cost time = 3.16s
global_step/sec: 32.7602
loss = 0.11964303255081177, steps = 57400, cost time = 3.05s
global_step/sec: 31.6839
loss = 0.1322539746761322, steps = 57500, cost time = 3.16s
global_step/sec: 32.3770
loss = 0.1371295154094696, steps = 57600, cost time = 3.09s
global_step/sec: 31.5961
loss = 0.125765860080719, steps = 57700, cost time = 3.16s
global_step/sec: 32.3259
loss = 0.1315702348947525, steps = 57800, cost time = 3.09s
global_step/sec: 31.8052
loss = 0.13854628801345825, steps = 57900, cost time = 3.14s
global_step/sec: 31.0960
loss = 0.12039273232221603, steps = 58000, cost time = 3.22s
global_step/sec: 32.8886
loss = 0.13969281315803528, steps = 58100, cost time = 3.04s
global_step/sec: 32.5176
loss = 0.11209169030189514, steps = 58200, cost time = 3.08s
global_step/sec: 31.8987
loss = 0.11755488067865372, steps = 58300, cost time = 3.13s
global_step/sec: 31.9323
loss = 0.1326383352279663, steps = 58400, cost time = 3.13s
global_step/sec: 31.5693
loss = 0.13489830493927002, steps = 58500, cost time = 3.17s
global_step/sec: 31.3485
loss = 0.11830441653728485, steps = 58600, cost time = 3.19s
global_step/sec: 32.8807
loss = 0.14539124071598053, steps = 58700, cost time = 3.04s
global_step/sec: 32.0315
loss = 0.14312824606895447, steps = 58800, cost time = 3.12s
global_step/sec: 31.2818
loss = 0.14291736483573914, steps = 58900, cost time = 3.20s
global_step/sec: 31.4007
loss = 0.11263039708137512, steps = 59000, cost time = 3.18s
global_step/sec: 31.1833
loss = 0.12802550196647644, steps = 59100, cost time = 3.21s
global_step/sec: 31.3557
loss = 0.12296499311923981, steps = 59200, cost time = 3.19s
global_step/sec: 30.9516
loss = 0.13791075348854065, steps = 59300, cost time = 3.23s
global_step/sec: 30.7758
loss = 0.11913345754146576, steps = 59400, cost time = 3.25s
global_step/sec: 32.1778
loss = 0.1263098418712616, steps = 59500, cost time = 3.11s
global_step/sec: 31.9677
loss = 0.10348494350910187, steps = 59600, cost time = 3.13s
global_step/sec: 30.5929
loss = 0.12139487266540527, steps = 59700, cost time = 3.27s
global_step/sec: 31.1252
loss = 0.1399013251066208, steps = 59800, cost time = 3.21s
global_step/sec: 31.5047
loss = 0.15053442120552063, steps = 59900, cost time = 3.17s
global_step/sec: 31.5103
loss = 0.14076809585094452, steps = 60000, cost time = 3.17s
global_step/sec: 32.2279
loss = 0.13913124799728394, steps = 60100, cost time = 3.10s
global_step/sec: 32.3178
loss = 0.15574222803115845, steps = 60200, cost time = 3.09s
global_step/sec: 33.1821
loss = 0.13536156713962555, steps = 60300, cost time = 3.01s
global_step/sec: 31.2005
loss = 0.15880665183067322, steps = 60400, cost time = 3.21s
global_step/sec: 32.8842
loss = 0.13158860802650452, steps = 60500, cost time = 3.04s
global_step/sec: 31.0599
loss = 0.13901418447494507, steps = 60600, cost time = 3.22s
global_step/sec: 31.4171
loss = 0.14755234122276306, steps = 60700, cost time = 3.18s
global_step/sec: 32.3492
loss = 0.13607057929039001, steps = 60800, cost time = 3.09s
global_step/sec: 33.3067
loss = 0.12893596291542053, steps = 60900, cost time = 3.00s
global_step/sec: 32.7946
loss = 0.15677228569984436, steps = 61000, cost time = 3.05s
global_step/sec: 32.8726
loss = 0.11944028735160828, steps = 61100, cost time = 3.04s
global_step/sec: 31.9687
loss = 0.1454971581697464, steps = 61200, cost time = 3.13s
global_step/sec: 31.1827
loss = 0.11451634764671326, steps = 61300, cost time = 3.21s
global_step/sec: 31.7155
loss = 0.1407424807548523, steps = 61400, cost time = 3.15s
global_step/sec: 32.5318
loss = 0.11947903037071228, steps = 61500, cost time = 3.07s
global_step/sec: 33.5097
loss = 0.13181520998477936, steps = 61600, cost time = 2.98s
global_step/sec: 32.6182
loss = 0.1279604583978653, steps = 61700, cost time = 3.07s
global_step/sec: 32.2612
loss = 0.1471206396818161, steps = 61800, cost time = 3.10s
global_step/sec: 33.0889
loss = 0.14611424505710602, steps = 61900, cost time = 3.02s
global_step/sec: 31.8968
loss = 0.12623240053653717, steps = 62000, cost time = 3.14s
global_step/sec: 32.1722
loss = 0.1429271697998047, steps = 62100, cost time = 3.11s
global_step/sec: 31.3946
loss = 0.1416243016719818, steps = 62200, cost time = 3.19s
global_step/sec: 31.0896
loss = 0.14640960097312927, steps = 62300, cost time = 3.22s
global_step/sec: 32.0674
loss = 0.12416933476924896, steps = 62400, cost time = 3.12s
global_step/sec: 32.2314
loss = 0.12217319011688232, steps = 62500, cost time = 3.10s
global_step/sec: 31.6037
loss = 0.14188839495182037, steps = 62600, cost time = 3.16s
global_step/sec: 30.5320
loss = 0.1287582516670227, steps = 62700, cost time = 3.28s
global_step/sec: 31.6228
loss = 0.12293069064617157, steps = 62800, cost time = 3.16s
global_step/sec: 30.4086
loss = 0.1407547891139984, steps = 62900, cost time = 3.29s
global_step/sec: 30.8170
loss = 0.1223846971988678, steps = 63000, cost time = 3.24s
global_step/sec: 32.3640
loss = 0.13382722437381744, steps = 63100, cost time = 3.09s
global_step/sec: 32.3032
loss = 0.12368176877498627, steps = 63200, cost time = 3.10s
global_step/sec: 32.5217
loss = 0.1535191535949707, steps = 63300, cost time = 3.07s
global_step/sec: 32.3428
loss = 0.13019421696662903, steps = 63400, cost time = 3.09s
global_step/sec: 30.8479
loss = 0.13987770676612854, steps = 63500, cost time = 3.24s
global_step/sec: 32.1520
loss = 0.13688048720359802, steps = 63600, cost time = 3.11s
global_step/sec: 32.8284
loss = 0.13411857187747955, steps = 63700, cost time = 3.05s
global_step/sec: 32.0900
loss = 0.12402156740427017, steps = 63800, cost time = 3.12s
global_step/sec: 32.0333
loss = 0.13284149765968323, steps = 63900, cost time = 3.12s
global_step/sec: 31.5452
loss = 0.1314467489719391, steps = 64000, cost time = 3.17s
global_step/sec: 31.5539
loss = 0.12264317274093628, steps = 64100, cost time = 3.17s
global_step/sec: 31.5632
loss = 0.12863880395889282, steps = 64200, cost time = 3.17s
global_step/sec: 31.3346
loss = 0.1163196861743927, steps = 64300, cost time = 3.19s
global_step/sec: 32.0917
loss = 0.14136719703674316, steps = 64400, cost time = 3.12s
global_step/sec: 31.5985
loss = 0.11970355361700058, steps = 64500, cost time = 3.16s
global_step/sec: 31.5062
loss = 0.12186374515295029, steps = 64600, cost time = 3.17s
global_step/sec: 31.7565
loss = 0.11952335387468338, steps = 64700, cost time = 3.15s
global_step/sec: 32.9957
loss = 0.12384957820177078, steps = 64800, cost time = 3.03s
global_step/sec: 32.3822
loss = 0.11569884419441223, steps = 64900, cost time = 3.09s
global_step/sec: 31.7173
loss = 0.13378609716892242, steps = 65000, cost time = 3.15s
global_step/sec: 32.6175
loss = 0.12815500795841217, steps = 65100, cost time = 3.07s
global_step/sec: 31.2792
loss = 0.1399160623550415, steps = 65200, cost time = 3.20s
global_step/sec: 31.4302
loss = 0.12747806310653687, steps = 65300, cost time = 3.18s
global_step/sec: 30.4767
loss = 0.12381541728973389, steps = 65400, cost time = 3.28s
global_step/sec: 31.9762
loss = 0.12878507375717163, steps = 65500, cost time = 3.13s
global_step/sec: 32.2663
loss = 0.13246355950832367, steps = 65600, cost time = 3.10s
global_step/sec: 32.4242
loss = 0.11796658486127853, steps = 65700, cost time = 3.08s
global_step/sec: 32.7466
loss = 0.13686636090278625, steps = 65800, cost time = 3.05s
global_step/sec: 30.6674
loss = 0.11955587565898895, steps = 65900, cost time = 3.26s
global_step/sec: 30.2167
loss = 0.11232248693704605, steps = 66000, cost time = 3.31s
global_step/sec: 32.0275
loss = 0.1374160796403885, steps = 66100, cost time = 3.12s
global_step/sec: 31.9011
loss = 0.14463333785533905, steps = 66200, cost time = 3.13s
global_step/sec: 31.2076
loss = 0.1251581609249115, steps = 66300, cost time = 3.20s
global_step/sec: 32.2536
loss = 0.142543762922287, steps = 66400, cost time = 3.10s
global_step/sec: 32.7027
loss = 0.12266262620687485, steps = 66500, cost time = 3.06s
global_step/sec: 33.6779
loss = 0.12248965352773666, steps = 66600, cost time = 2.97s
global_step/sec: 31.1715
loss = 0.1262955516576767, steps = 66700, cost time = 3.21s
global_step/sec: 31.8454
loss = 0.12652583420276642, steps = 66800, cost time = 3.14s
global_step/sec: 32.4762
loss = 0.13220351934432983, steps = 66900, cost time = 3.08s
global_step/sec: 32.3634
loss = 0.12391655147075653, steps = 67000, cost time = 3.09s
global_step/sec: 32.2660
loss = 0.13003334403038025, steps = 67100, cost time = 3.10s
global_step/sec: 33.1565
loss = 0.12212049961090088, steps = 67200, cost time = 3.02s
global_step/sec: 31.6359
loss = 0.12607750296592712, steps = 67300, cost time = 3.16s
global_step/sec: 32.1814
loss = 0.12654554843902588, steps = 67400, cost time = 3.11s
global_step/sec: 31.5476
loss = 0.12058237195014954, steps = 67500, cost time = 3.17s
global_step/sec: 31.8283
loss = 0.1198471337556839, steps = 67600, cost time = 3.14s
global_step/sec: 31.3201
loss = 0.12932650744915009, steps = 67700, cost time = 3.19s
global_step/sec: 30.4223
loss = 0.13133923709392548, steps = 67800, cost time = 3.29s
global_step/sec: 31.4835
loss = 0.1433110535144806, steps = 67900, cost time = 3.18s
global_step/sec: 30.9730
loss = 0.11861132085323334, steps = 68000, cost time = 3.23s
global_step/sec: 30.1825
loss = 0.1156766414642334, steps = 68100, cost time = 3.31s
global_step/sec: 31.7954
loss = 0.11789828538894653, steps = 68200, cost time = 3.15s
global_step/sec: 31.8832
loss = 0.12270227074623108, steps = 68300, cost time = 3.14s
global_step/sec: 31.8142
loss = 0.12014175206422806, steps = 68400, cost time = 3.14s
global_step/sec: 31.3185
loss = 0.1273006945848465, steps = 68500, cost time = 3.19s
global_step/sec: 31.5657
loss = 0.13536155223846436, steps = 68600, cost time = 3.17s
global_step/sec: 31.7477
loss = 0.1238304078578949, steps = 68700, cost time = 3.15s
global_step/sec: 31.2124
loss = 0.12893322110176086, steps = 68800, cost time = 3.20s
global_step/sec: 32.1311
loss = 0.13323348760604858, steps = 68900, cost time = 3.11s
global_step/sec: 31.1250
loss = 0.11606739461421967, steps = 69000, cost time = 3.21s
global_step/sec: 32.9836
loss = 0.11020456254482269, steps = 69100, cost time = 3.03s
global_step/sec: 31.5202
loss = 0.1255573332309723, steps = 69200, cost time = 3.17s
global_step/sec: 31.8129
loss = 0.13585466146469116, steps = 69300, cost time = 3.14s
global_step/sec: 31.3037
loss = 0.11980274319648743, steps = 69400, cost time = 3.19s
global_step/sec: 31.9852
loss = 0.12433521449565887, steps = 69500, cost time = 3.13s
global_step/sec: 31.6416
loss = 0.11413778364658356, steps = 69600, cost time = 3.16s
global_step/sec: 31.1772
loss = 0.1157810240983963, steps = 69700, cost time = 3.21s
global_step/sec: 32.4002
loss = 0.13777336478233337, steps = 69800, cost time = 3.09s
global_step/sec: 32.3780
loss = 0.1398504227399826, steps = 69900, cost time = 3.09s
global_step/sec: 32.5350
loss = 0.13328474760055542, steps = 70000, cost time = 3.07s
global_step/sec: 32.0718
loss = 0.1277843713760376, steps = 70100, cost time = 3.12s
global_step/sec: 32.3285
loss = 0.11639126390218735, steps = 70200, cost time = 3.09s
global_step/sec: 32.4171
loss = 0.1444629579782486, steps = 70300, cost time = 3.08s
global_step/sec: 31.3536
loss = 0.12180247902870178, steps = 70400, cost time = 3.19s
global_step/sec: 32.2876
loss = 0.122213214635849, steps = 70500, cost time = 3.10s
global_step/sec: 31.7696
loss = 0.10688935220241547, steps = 70600, cost time = 3.15s
global_step/sec: 31.4136
loss = 0.11258292198181152, steps = 70700, cost time = 3.18s
global_step/sec: 31.7749
loss = 0.11375556886196136, steps = 70800, cost time = 3.15s
global_step/sec: 30.8318
loss = 0.12440355122089386, steps = 70900, cost time = 3.24s
global_step/sec: 31.6322
loss = 0.12548844516277313, steps = 71000, cost time = 3.16s
global_step/sec: 30.7787
loss = 0.13054178655147552, steps = 71100, cost time = 3.25s
global_step/sec: 31.7382
loss = 0.13953587412834167, steps = 71200, cost time = 3.15s
global_step/sec: 31.5618
loss = 0.11816251277923584, steps = 71300, cost time = 3.17s
global_step/sec: 32.1969
loss = 0.12822997570037842, steps = 71400, cost time = 3.11s
global_step/sec: 32.7831
loss = 0.12979412078857422, steps = 71500, cost time = 3.05s
global_step/sec: 30.3644
loss = 0.13214540481567383, steps = 71600, cost time = 3.29s
global_step/sec: 31.3595
loss = 0.12650349736213684, steps = 71700, cost time = 3.19s
global_step/sec: 30.2433
loss = 0.12869277596473694, steps = 71800, cost time = 3.31s
global_step/sec: 32.3861
loss = 0.11815307289361954, steps = 71900, cost time = 3.09s
global_step/sec: 31.1287
loss = 0.14285407960414886, steps = 72000, cost time = 3.21s
global_step/sec: 30.8746
loss = 0.13057151436805725, steps = 72100, cost time = 3.24s
global_step/sec: 32.9197
loss = 0.1112358421087265, steps = 72200, cost time = 3.04s
global_step/sec: 32.7878
loss = 0.12832653522491455, steps = 72300, cost time = 3.05s
global_step/sec: 31.2385
loss = 0.13228318095207214, steps = 72400, cost time = 3.20s
global_step/sec: 31.8934
loss = 0.1299435794353485, steps = 72500, cost time = 3.14s
global_step/sec: 31.4535
loss = 0.11321067810058594, steps = 72600, cost time = 3.18s
global_step/sec: 31.9895
loss = 0.12257927656173706, steps = 72700, cost time = 3.13s
global_step/sec: 31.2621
loss = 0.1180545762181282, steps = 72800, cost time = 3.20s
global_step/sec: 30.9237
loss = 0.12272386997938156, steps = 72900, cost time = 3.23s
global_step/sec: 32.1158
loss = 0.13049191236495972, steps = 73000, cost time = 3.11s
global_step/sec: 32.5557
loss = 0.126356303691864, steps = 73100, cost time = 3.07s
global_step/sec: 31.1024
loss = 0.10747833549976349, steps = 73200, cost time = 3.22s
global_step/sec: 31.7799
loss = 0.11001592874526978, steps = 73300, cost time = 3.15s
global_step/sec: 32.0519
loss = 0.12938976287841797, steps = 73400, cost time = 3.12s
global_step/sec: 31.0410
loss = 0.11902418732643127, steps = 73500, cost time = 3.22s
global_step/sec: 32.6377
loss = 0.14366352558135986, steps = 73600, cost time = 3.06s
global_step/sec: 33.2544
loss = 0.13719087839126587, steps = 73700, cost time = 3.01s
global_step/sec: 31.4927
loss = 0.1226041167974472, steps = 73800, cost time = 3.18s
global_step/sec: 31.4672
loss = 0.13631032407283783, steps = 73900, cost time = 3.18s
global_step/sec: 32.0750
loss = 0.11519753932952881, steps = 74000, cost time = 3.12s
global_step/sec: 32.2938
loss = 0.129518061876297, steps = 74100, cost time = 3.10s
global_step/sec: 31.3031
loss = 0.1251721978187561, steps = 74200, cost time = 3.19s
global_step/sec: 31.5739
loss = 0.13075284659862518, steps = 74300, cost time = 3.17s
global_step/sec: 31.6604
loss = 0.12940652668476105, steps = 74400, cost time = 3.16s
global_step/sec: 32.2829
loss = 0.13278831541538239, steps = 74500, cost time = 3.10s
global_step/sec: 31.5210
loss = 0.13396838307380676, steps = 74600, cost time = 3.17s
global_step/sec: 31.5754
loss = 0.11834782361984253, steps = 74700, cost time = 3.17s
global_step/sec: 32.0030
loss = 0.1300216019153595, steps = 74800, cost time = 3.12s
global_step/sec: 32.0808
loss = 0.11987730860710144, steps = 74900, cost time = 3.12s
global_step/sec: 32.6661
loss = 0.1201426237821579, steps = 75000, cost time = 3.06s
global_step/sec: 31.8561
loss = 0.1116979569196701, steps = 75100, cost time = 3.14s
global_step/sec: 31.6340
loss = 0.1268264353275299, steps = 75200, cost time = 3.16s
global_step/sec: 30.7259
loss = 0.1149464026093483, steps = 75300, cost time = 3.25s
global_step/sec: 31.6632
loss = 0.1292264759540558, steps = 75400, cost time = 3.16s
global_step/sec: 30.8154
loss = 0.1412879228591919, steps = 75500, cost time = 3.25s
global_step/sec: 32.2868
loss = 0.14199893176555634, steps = 75600, cost time = 3.10s
global_step/sec: 32.1675
loss = 0.15250897407531738, steps = 75700, cost time = 3.11s
global_step/sec: 31.4380
loss = 0.13090810179710388, steps = 75800, cost time = 3.18s
global_step/sec: 31.3619
loss = 0.14889881014823914, steps = 75900, cost time = 3.19s
global_step/sec: 32.6570
loss = 0.1256224513053894, steps = 76000, cost time = 3.06s
global_step/sec: 32.0630
loss = 0.12588435411453247, steps = 76100, cost time = 3.12s
global_step/sec: 31.4321
loss = 0.14055052399635315, steps = 76200, cost time = 3.18s
global_step/sec: 31.4094
loss = 0.15668562054634094, steps = 76300, cost time = 3.18s
global_step/sec: 32.2944
loss = 0.1541859209537506, steps = 76400, cost time = 3.10s
global_step/sec: 31.8063
loss = 0.12358444929122925, steps = 76500, cost time = 3.14s
global_step/sec: 31.0655
loss = 0.1321997344493866, steps = 76600, cost time = 3.22s
global_step/sec: 32.6663
loss = 0.13582554459571838, steps = 76700, cost time = 3.06s
global_step/sec: 31.5085
loss = 0.14422479271888733, steps = 76800, cost time = 3.17s
global_step/sec: 31.6157
loss = 0.11747148633003235, steps = 76900, cost time = 3.16s
global_step/sec: 31.6064
loss = 0.1246049776673317, steps = 77000, cost time = 3.16s
global_step/sec: 31.8881
loss = 0.11806292086839676, steps = 77100, cost time = 3.14s
global_step/sec: 32.1276
loss = 0.12189918756484985, steps = 77200, cost time = 3.11s
global_step/sec: 31.8996
loss = 0.13075876235961914, steps = 77300, cost time = 3.13s
global_step/sec: 31.9599
loss = 0.1366969347000122, steps = 77400, cost time = 3.13s
global_step/sec: 31.7033
loss = 0.1195148453116417, steps = 77500, cost time = 3.15s
global_step/sec: 31.7421
loss = 0.12255273759365082, steps = 77600, cost time = 3.15s
global_step/sec: 31.9587
loss = 0.12601208686828613, steps = 77700, cost time = 3.13s
global_step/sec: 31.3511
loss = 0.12564605474472046, steps = 77800, cost time = 3.19s
global_step/sec: 31.6621
loss = 0.12316866219043732, steps = 77900, cost time = 3.16s
global_step/sec: 33.6183
loss = 0.11881282925605774, steps = 78000, cost time = 2.97s
global_step/sec: 31.1781
loss = 0.12460900843143463, steps = 78100, cost time = 3.21s
global_step/sec: 32.4023
loss = 0.11391285806894302, steps = 78200, cost time = 3.09s
global_step/sec: 33.0329
loss = 0.1123853400349617, steps = 78300, cost time = 3.03s
global_step/sec: 32.1745
loss = 0.11562301963567734, steps = 78400, cost time = 3.11s
global_step/sec: 32.5304
loss = 0.1304253786802292, steps = 78500, cost time = 3.07s
global_step/sec: 32.2480
loss = 0.13817404210567474, steps = 78600, cost time = 3.10s
global_step/sec: 31.9327
loss = 0.12781809270381927, steps = 78700, cost time = 3.13s
global_step/sec: 32.8299
loss = 0.13622012734413147, steps = 78800, cost time = 3.05s
global_step/sec: 31.7963
loss = 0.1205313578248024, steps = 78900, cost time = 3.15s
global_step/sec: 32.2166
loss = 0.13748699426651, steps = 79000, cost time = 3.10s
global_step/sec: 30.0864
loss = 0.14093516767024994, steps = 79100, cost time = 3.32s
global_step/sec: 32.2146
loss = 0.14254865050315857, steps = 79200, cost time = 3.10s
global_step/sec: 31.6704
loss = 0.11967052519321442, steps = 79300, cost time = 3.16s
global_step/sec: 32.0888
loss = 0.1160961464047432, steps = 79400, cost time = 3.12s
global_step/sec: 31.6480
loss = 0.1293039470911026, steps = 79500, cost time = 3.16s
global_step/sec: 33.5993
loss = 0.13897012174129486, steps = 79600, cost time = 2.98s
global_step/sec: 31.6249
loss = 0.11565381288528442, steps = 79700, cost time = 3.16s
global_step/sec: 32.4779
loss = 0.11599605530500412, steps = 79800, cost time = 3.08s
global_step/sec: 32.2484
loss = 0.1301346719264984, steps = 79900, cost time = 3.10s
global_step/sec: 29.5502
loss = 0.1476110816001892, steps = 80000, cost time = 3.38s
global_step/sec: 31.0016
loss = 0.12538549304008484, steps = 80100, cost time = 3.23s
global_step/sec: 30.4365
loss = 0.13568229973316193, steps = 80200, cost time = 3.29s
global_step/sec: 30.8127
loss = 0.12821915745735168, steps = 80300, cost time = 3.25s
global_step/sec: 31.6445
loss = 0.11672338098287582, steps = 80400, cost time = 3.16s
global_step/sec: 31.9815
loss = 0.1317780613899231, steps = 80500, cost time = 3.13s
global_step/sec: 32.2076
loss = 0.11100110411643982, steps = 80600, cost time = 3.10s
global_step/sec: 32.8624
loss = 0.11633649468421936, steps = 80700, cost time = 3.04s
global_step/sec: 32.5971
loss = 0.1305989921092987, steps = 80800, cost time = 3.07s
global_step/sec: 33.3901
loss = 0.11402449011802673, steps = 80900, cost time = 2.99s
global_step/sec: 33.5995
loss = 0.13743805885314941, steps = 81000, cost time = 2.98s
global_step/sec: 32.5234
loss = 0.10963980853557587, steps = 81100, cost time = 3.07s
global_step/sec: 32.2960
loss = 0.1214500218629837, steps = 81200, cost time = 3.10s
global_step/sec: 32.6489
loss = 0.11948978900909424, steps = 81300, cost time = 3.06s
global_step/sec: 31.5920
loss = 0.10824523866176605, steps = 81400, cost time = 3.17s
global_step/sec: 32.1670
loss = 0.10899461805820465, steps = 81500, cost time = 3.11s
global_step/sec: 32.8513
loss = 0.10637710988521576, steps = 81600, cost time = 3.04s
global_step/sec: 32.0725
loss = 0.12387820333242416, steps = 81700, cost time = 3.12s
global_step/sec: 31.5398
loss = 0.12525126338005066, steps = 81800, cost time = 3.17s
global_step/sec: 32.2227
loss = 0.11730797588825226, steps = 81900, cost time = 3.10s
global_step/sec: 32.3494
loss = 0.11925160139799118, steps = 82000, cost time = 3.09s
global_step/sec: 32.0153
loss = 0.13659633696079254, steps = 82100, cost time = 3.12s
global_step/sec: 33.0404
loss = 0.12367682158946991, steps = 82200, cost time = 3.03s
global_step/sec: 32.3199
loss = 0.1255992352962494, steps = 82300, cost time = 3.09s
global_step/sec: 31.0015
loss = 0.14116990566253662, steps = 82400, cost time = 3.23s
global_step/sec: 31.8953
loss = 0.13179701566696167, steps = 82500, cost time = 3.14s
global_step/sec: 31.1150
loss = 0.14213493466377258, steps = 82600, cost time = 3.21s
global_step/sec: 31.8959
loss = 0.12318813055753708, steps = 82700, cost time = 3.14s
global_step/sec: 32.6795
loss = 0.14209455251693726, steps = 82800, cost time = 3.06s
global_step/sec: 31.5477
loss = 0.12495744228363037, steps = 82900, cost time = 3.17s
global_step/sec: 31.3816
loss = 0.12047982960939407, steps = 83000, cost time = 3.19s
global_step/sec: 31.9941
loss = 0.13262847065925598, steps = 83100, cost time = 3.13s
global_step/sec: 31.5307
loss = 0.11737814545631409, steps = 83200, cost time = 3.17s
global_step/sec: 32.1586
loss = 0.12027043104171753, steps = 83300, cost time = 3.11s
global_step/sec: 31.0137
loss = 0.11306697130203247, steps = 83400, cost time = 3.22s
global_step/sec: 31.9168
loss = 0.11046269536018372, steps = 83500, cost time = 3.13s
global_step/sec: 31.8222
loss = 0.12649935483932495, steps = 83600, cost time = 3.14s
global_step/sec: 30.8350
loss = 0.13275155425071716, steps = 83700, cost time = 3.24s
global_step/sec: 31.9954
loss = 0.1247527003288269, steps = 83800, cost time = 3.13s
global_step/sec: 31.3161
loss = 0.14661014080047607, steps = 83900, cost time = 3.19s
global_step/sec: 32.5680
loss = 0.12144354730844498, steps = 84000, cost time = 3.07s
global_step/sec: 31.4214
loss = 0.11309047043323517, steps = 84100, cost time = 3.18s
global_step/sec: 31.9215
loss = 0.12018272280693054, steps = 84200, cost time = 3.13s
global_step/sec: 32.4837
loss = 0.11885185539722443, steps = 84300, cost time = 3.08s
global_step/sec: 31.9920
loss = 0.1295226514339447, steps = 84400, cost time = 3.13s
global_step/sec: 32.1998
loss = 0.12810005247592926, steps = 84500, cost time = 3.11s
global_step/sec: 33.2738
loss = 0.11884874850511551, steps = 84600, cost time = 3.01s
global_step/sec: 31.3397
loss = 0.1258135437965393, steps = 84700, cost time = 3.19s
global_step/sec: 32.7385
loss = 0.11508247256278992, steps = 84800, cost time = 3.05s
global_step/sec: 31.4177
loss = 0.13014531135559082, steps = 84900, cost time = 3.18s
global_step/sec: 32.3964
loss = 0.12922827899456024, steps = 85000, cost time = 3.09s
global_step/sec: 31.9099
loss = 0.14398671686649323, steps = 85100, cost time = 3.13s
global_step/sec: 32.1628
loss = 0.13255785405635834, steps = 85200, cost time = 3.11s
global_step/sec: 31.5508
loss = 0.12504619359970093, steps = 85300, cost time = 3.17s
global_step/sec: 32.2679
loss = 0.12992553412914276, steps = 85400, cost time = 3.10s
global_step/sec: 31.5994
loss = 0.12680919468402863, steps = 85500, cost time = 3.16s
global_step/sec: 32.7624
loss = 0.12297269701957703, steps = 85600, cost time = 3.05s
global_step/sec: 31.8448
loss = 0.12276005744934082, steps = 85700, cost time = 3.14s
global_step/sec: 31.6368
loss = 0.1269320547580719, steps = 85800, cost time = 3.16s
global_step/sec: 31.8947
loss = 0.11526087671518326, steps = 85900, cost time = 3.14s
global_step/sec: 32.4675
loss = 0.11200742423534393, steps = 86000, cost time = 3.08s
global_step/sec: 32.1056
loss = 0.13032370805740356, steps = 86100, cost time = 3.11s
global_step/sec: 32.7072
loss = 0.1106623113155365, steps = 86200, cost time = 3.06s
global_step/sec: 33.1326
loss = 0.1212707906961441, steps = 86300, cost time = 3.02s
global_step/sec: 32.3681
loss = 0.11818301677703857, steps = 86400, cost time = 3.09s
global_step/sec: 32.4739
loss = 0.12417517602443695, steps = 86500, cost time = 3.08s
global_step/sec: 31.8331
loss = 0.15272291004657745, steps = 86600, cost time = 3.14s
global_step/sec: 30.5695
loss = 0.129710853099823, steps = 86700, cost time = 3.27s
global_step/sec: 31.3045
loss = 0.13281866908073425, steps = 86800, cost time = 3.19s
global_step/sec: 32.5675
loss = 0.1135336235165596, steps = 86900, cost time = 3.07s
global_step/sec: 31.7338
loss = 0.10208091139793396, steps = 87000, cost time = 3.15s
global_step/sec: 32.1176
loss = 0.12347583472728729, steps = 87100, cost time = 3.11s
global_step/sec: 31.6098
loss = 0.13430754840373993, steps = 87200, cost time = 3.16s
global_step/sec: 32.1463
loss = 0.11842595040798187, steps = 87300, cost time = 3.11s
global_step/sec: 32.2895
loss = 0.10503701120615005, steps = 87400, cost time = 3.10s
global_step/sec: 31.1848
loss = 0.12473303824663162, steps = 87500, cost time = 3.21s
global_step/sec: 32.1694
loss = 0.12044978141784668, steps = 87600, cost time = 3.11s
global_step/sec: 32.3963
loss = 0.11647406220436096, steps = 87700, cost time = 3.09s
global_step/sec: 32.3071
loss = 0.13351672887802124, steps = 87800, cost time = 3.10s
global_step/sec: 32.0708
loss = 0.12654952704906464, steps = 87900, cost time = 3.12s
global_step/sec: 31.9734
loss = 0.13002705574035645, steps = 88000, cost time = 3.13s
global_step/sec: 32.6747
loss = 0.11443440616130829, steps = 88100, cost time = 3.06s
global_step/sec: 32.2328
loss = 0.12158498913049698, steps = 88200, cost time = 3.10s
global_step/sec: 31.2192
loss = 0.13235284388065338, steps = 88300, cost time = 3.20s
global_step/sec: 32.0720
loss = 0.12159373611211777, steps = 88400, cost time = 3.12s
global_step/sec: 32.4484
loss = 0.13291038572788239, steps = 88500, cost time = 3.08s
global_step/sec: 32.5976
loss = 0.1372395157814026, steps = 88600, cost time = 3.07s
global_step/sec: 31.2111
loss = 0.11044228076934814, steps = 88700, cost time = 3.20s
global_step/sec: 31.8449
loss = 0.12561070919036865, steps = 88800, cost time = 3.14s
global_step/sec: 31.3825
loss = 0.11789095401763916, steps = 88900, cost time = 3.19s
global_step/sec: 32.3603
loss = 0.122611865401268, steps = 89000, cost time = 3.09s
global_step/sec: 32.2507
loss = 0.13569357991218567, steps = 89100, cost time = 3.10s
global_step/sec: 31.5503
loss = 0.1377115249633789, steps = 89200, cost time = 3.17s
global_step/sec: 31.1865
loss = 0.11219530552625656, steps = 89300, cost time = 3.21s
global_step/sec: 32.7454
loss = 0.11434660851955414, steps = 89400, cost time = 3.05s
global_step/sec: 30.9025
loss = 0.10997401177883148, steps = 89500, cost time = 3.24s
global_step/sec: 30.3779
loss = 0.12041185796260834, steps = 89600, cost time = 3.29s
global_step/sec: 31.2361
loss = 0.12797966599464417, steps = 89700, cost time = 3.20s
global_step/sec: 31.6507
loss = 0.1236025020480156, steps = 89800, cost time = 3.16s
global_step/sec: 31.2516
loss = 0.11791463941335678, steps = 89900, cost time = 3.20s
global_step/sec: 31.7905
loss = 0.11890000849962234, steps = 90000, cost time = 3.15s
global_step/sec: 32.1287
loss = 0.12132292985916138, steps = 90100, cost time = 3.11s
global_step/sec: 31.9308
loss = 0.13170737028121948, steps = 90200, cost time = 3.13s
global_step/sec: 31.7941
loss = 0.13046476244926453, steps = 90300, cost time = 3.15s
global_step/sec: 31.8861
loss = 0.11173400282859802, steps = 90400, cost time = 3.14s
global_step/sec: 31.9178
loss = 0.12486404925584793, steps = 90500, cost time = 3.13s
global_step/sec: 31.7376
loss = 0.11746840924024582, steps = 90600, cost time = 3.15s
global_step/sec: 31.7531
loss = 0.13380005955696106, steps = 90700, cost time = 3.15s
global_step/sec: 31.9086
loss = 0.1104794517159462, steps = 90800, cost time = 3.13s
global_step/sec: 31.9726
loss = 0.10716290771961212, steps = 90900, cost time = 3.13s
global_step/sec: 31.4979
loss = 0.12605637311935425, steps = 91000, cost time = 3.17s
global_step/sec: 31.8854
loss = 0.13215093314647675, steps = 91100, cost time = 3.14s
global_step/sec: 31.4466
loss = 0.11249454319477081, steps = 91200, cost time = 3.18s
global_step/sec: 30.6049
loss = 0.149980366230011, steps = 91300, cost time = 3.27s
global_step/sec: 30.3749
loss = 0.13532577455043793, steps = 91400, cost time = 3.29s
global_step/sec: 30.7796
loss = 0.13150106370449066, steps = 91500, cost time = 3.25s
global_step/sec: 31.5728
loss = 0.12213234603404999, steps = 91600, cost time = 3.17s
global_step/sec: 32.1592
loss = 0.12317778915166855, steps = 91700, cost time = 3.11s
global_step/sec: 30.9521
loss = 0.11248622089624405, steps = 91800, cost time = 3.23s
global_step/sec: 32.7650
loss = 0.1350041925907135, steps = 91900, cost time = 3.05s
global_step/sec: 32.2065
loss = 0.130538672208786, steps = 92000, cost time = 3.10s
global_step/sec: 31.8690
loss = 0.12267430871725082, steps = 92100, cost time = 3.14s
global_step/sec: 32.6764
loss = 0.11913864314556122, steps = 92200, cost time = 3.06s
global_step/sec: 31.9279
loss = 0.13909608125686646, steps = 92300, cost time = 3.13s
global_step/sec: 32.4483
loss = 0.13375672698020935, steps = 92400, cost time = 3.08s
global_step/sec: 31.9519
loss = 0.12384644150733948, steps = 92500, cost time = 3.13s
global_step/sec: 32.7512
loss = 0.13269376754760742, steps = 92600, cost time = 3.05s
global_step/sec: 31.4261
loss = 0.12072426825761795, steps = 92700, cost time = 3.18s
global_step/sec: 32.0542
loss = 0.1287001520395279, steps = 92800, cost time = 3.12s
global_step/sec: 31.4004
loss = 0.118745356798172, steps = 92900, cost time = 3.18s
global_step/sec: 32.3125
loss = 0.12495215982198715, steps = 93000, cost time = 3.09s
global_step/sec: 31.8761
loss = 0.12156727910041809, steps = 93100, cost time = 3.14s
global_step/sec: 31.8111
loss = 0.13494005799293518, steps = 93200, cost time = 3.14s
global_step/sec: 31.6657
loss = 0.12304174900054932, steps = 93300, cost time = 3.16s
global_step/sec: 30.7955
loss = 0.11181455105543137, steps = 93400, cost time = 3.25s
global_step/sec: 32.7329
loss = 0.12662994861602783, steps = 93500, cost time = 3.06s
global_step/sec: 31.8731
loss = 0.14391395449638367, steps = 93600, cost time = 3.14s
global_step/sec: 31.0686
loss = 0.11294214427471161, steps = 93700, cost time = 3.22s
global_step/sec: 32.9182
loss = 0.1083802729845047, steps = 93800, cost time = 3.04s
global_step/sec: 31.2123
loss = 0.11664984375238419, steps = 93900, cost time = 3.20s
global_step/sec: 32.8320
loss = 0.12191040813922882, steps = 94000, cost time = 3.05s
global_step/sec: 31.7926
loss = 0.11644692718982697, steps = 94100, cost time = 3.15s
global_step/sec: 32.1415
loss = 0.13768145442008972, steps = 94200, cost time = 3.11s
global_step/sec: 32.1917
loss = 0.1342630684375763, steps = 94300, cost time = 3.11s
global_step/sec: 31.9904
loss = 0.1220112144947052, steps = 94400, cost time = 3.13s
global_step/sec: 31.4733
loss = 0.13449230790138245, steps = 94500, cost time = 3.18s
global_step/sec: 32.1750
loss = 0.13654553890228271, steps = 94600, cost time = 3.11s
global_step/sec: 31.5624
loss = 0.14255666732788086, steps = 94700, cost time = 3.17s
global_step/sec: 31.2018
loss = 0.13372290134429932, steps = 94800, cost time = 3.20s
global_step/sec: 31.4879
loss = 0.11532998830080032, steps = 94900, cost time = 3.18s
global_step/sec: 31.2559
loss = 0.13884693384170532, steps = 95000, cost time = 3.20s
global_step/sec: 31.6306
loss = 0.14203515648841858, steps = 95100, cost time = 3.16s
global_step/sec: 32.1028
loss = 0.1272251307964325, steps = 95200, cost time = 3.11s
global_step/sec: 31.2041
loss = 0.11547882854938507, steps = 95300, cost time = 3.20s
global_step/sec: 32.0936
loss = 0.12265804409980774, steps = 95400, cost time = 3.12s
global_step/sec: 32.7767
loss = 0.12837335467338562, steps = 95500, cost time = 3.05s
global_step/sec: 32.2957
loss = 0.11439003795385361, steps = 95600, cost time = 3.10s
global_step/sec: 31.0620
loss = 0.11372219026088715, steps = 95700, cost time = 3.22s
global_step/sec: 30.8697
loss = 0.10454599559307098, steps = 95800, cost time = 3.24s
global_step/sec: 31.1774
loss = 0.12304657697677612, steps = 95900, cost time = 3.21s
global_step/sec: 31.9866
loss = 0.11786939203739166, steps = 96000, cost time = 3.13s
global_step/sec: 32.3743
loss = 0.11170254647731781, steps = 96100, cost time = 3.09s
global_step/sec: 31.5836
loss = 0.11431897431612015, steps = 96200, cost time = 3.17s
global_step/sec: 32.4207
loss = 0.10839907079935074, steps = 96300, cost time = 3.08s
global_step/sec: 32.0925
loss = 0.13305802643299103, steps = 96400, cost time = 3.12s
global_step/sec: 31.7872
loss = 0.13115178048610687, steps = 96500, cost time = 3.15s
global_step/sec: 31.8249
loss = 0.10393114387989044, steps = 96600, cost time = 3.14s
global_step/sec: 31.5326
loss = 0.1388891488313675, steps = 96700, cost time = 3.17s
global_step/sec: 31.2199
loss = 0.11394663155078888, steps = 96800, cost time = 3.20s
global_step/sec: 32.2240
loss = 0.11419841647148132, steps = 96900, cost time = 3.10s
global_step/sec: 32.1296
loss = 0.12239798903465271, steps = 97000, cost time = 3.11s
global_step/sec: 31.3155
loss = 0.11067871004343033, steps = 97100, cost time = 3.19s
global_step/sec: 31.6150
loss = 0.11432796716690063, steps = 97200, cost time = 3.16s
global_step/sec: 30.3293
loss = 0.13140590488910675, steps = 97300, cost time = 3.30s
global_step/sec: 33.6764
loss = 0.11329695582389832, steps = 97400, cost time = 2.97s
global_step/sec: 31.9177
loss = 0.1369364857673645, steps = 97500, cost time = 3.13s
global_step/sec: 32.5776
loss = 0.12271194905042648, steps = 97600, cost time = 3.07s
global_step/sec: 32.3842
loss = 0.10544951260089874, steps = 97700, cost time = 3.09s
global_step/sec: 31.8282
loss = 0.11881645023822784, steps = 97800, cost time = 3.14s
global_step/sec: 31.1456
loss = 0.1275641769170761, steps = 97900, cost time = 3.21s
global_step/sec: 31.9547
loss = 0.1130296066403389, steps = 98000, cost time = 3.13s
global_step/sec: 31.3443
loss = 0.1265418529510498, steps = 98100, cost time = 3.19s
global_step/sec: 31.3931
loss = 0.10665971785783768, steps = 98200, cost time = 3.19s
global_step/sec: 31.5463
loss = 0.13569828867912292, steps = 98300, cost time = 3.17s
global_step/sec: 32.4909
loss = 0.1358780860900879, steps = 98400, cost time = 3.08s
global_step/sec: 31.4154
loss = 0.12000613659620285, steps = 98500, cost time = 3.18s
global_step/sec: 31.5991
loss = 0.1278408169746399, steps = 98600, cost time = 3.16s
global_step/sec: 31.7530
loss = 0.11765322834253311, steps = 98700, cost time = 3.15s
global_step/sec: 30.9628
loss = 0.11517562717199326, steps = 98800, cost time = 3.23s
global_step/sec: 32.2301
loss = 0.12083151936531067, steps = 98900, cost time = 3.10s
global_step/sec: 29.7012
loss = 0.10701210796833038, steps = 99000, cost time = 3.37s
global_step/sec: 31.0952
loss = 0.1176297515630722, steps = 99100, cost time = 3.22s
global_step/sec: 31.5797
loss = 0.1424238681793213, steps = 99200, cost time = 3.17s
global_step/sec: 32.4167
loss = 0.13682296872138977, steps = 99300, cost time = 3.08s
global_step/sec: 33.0496
loss = 0.11807635426521301, steps = 99400, cost time = 3.03s
global_step/sec: 32.2400
loss = 0.11461191624403, steps = 99500, cost time = 3.10s
global_step/sec: 31.7880
loss = 0.11426758766174316, steps = 99600, cost time = 3.15s
global_step/sec: 32.2500
loss = 0.1178332269191742, steps = 99700, cost time = 3.10s
global_step/sec: 32.0532
loss = 0.10425005853176117, steps = 99800, cost time = 3.12s
global_step/sec: 31.9328
loss = 0.11109938472509384, steps = 99900, cost time = 3.13s
global_step/sec: 31.8735
loss = 0.12016841769218445, steps = 100000, cost time = 3.14s
global_step/sec: 32.4216
loss = 0.12554505467414856, steps = 100100, cost time = 3.08s
global_step/sec: 32.3216
loss = 0.12794066965579987, steps = 100200, cost time = 3.09s
global_step/sec: 30.6691
loss = 0.09998920559883118, steps = 100300, cost time = 3.26s
global_step/sec: 32.8547
loss = 0.11583901941776276, steps = 100400, cost time = 3.04s
global_step/sec: 31.0412
loss = 0.12361400574445724, steps = 100500, cost time = 3.22s
global_step/sec: 32.0143
loss = 0.13406877219676971, steps = 100600, cost time = 3.12s
global_step/sec: 31.6091
loss = 0.11232909560203552, steps = 100700, cost time = 3.16s
global_step/sec: 31.1852
loss = 0.1268804520368576, steps = 100800, cost time = 3.21s
global_step/sec: 30.9747
loss = 0.13360115885734558, steps = 100900, cost time = 3.23s
global_step/sec: 31.1819
loss = 0.14280998706817627, steps = 101000, cost time = 3.21s
global_step/sec: 31.7592
loss = 0.11355991661548615, steps = 101100, cost time = 3.15s
global_step/sec: 31.9193
loss = 0.13898029923439026, steps = 101200, cost time = 3.13s
global_step/sec: 31.8875
loss = 0.12636536359786987, steps = 101300, cost time = 3.14s
global_step/sec: 31.7914
loss = 0.1240355521440506, steps = 101400, cost time = 3.15s
global_step/sec: 31.1212
loss = 0.1344192773103714, steps = 101500, cost time = 3.21s
global_step/sec: 32.1196
loss = 0.1282779574394226, steps = 101600, cost time = 3.11s
global_step/sec: 32.4782
loss = 0.12907543778419495, steps = 101700, cost time = 3.08s
global_step/sec: 31.5972
loss = 0.1172163337469101, steps = 101800, cost time = 3.16s
global_step/sec: 32.5143
loss = 0.15759731829166412, steps = 101900, cost time = 3.08s
global_step/sec: 31.6976
loss = 0.12692546844482422, steps = 102000, cost time = 3.15s
global_step/sec: 32.7353
loss = 0.11171423643827438, steps = 102100, cost time = 3.05s
global_step/sec: 31.9823
loss = 0.10249296575784683, steps = 102200, cost time = 3.13s
global_step/sec: 32.1798
loss = 0.12429873645305634, steps = 102300, cost time = 3.11s
global_step/sec: 30.8062
loss = 0.1206539124250412, steps = 102400, cost time = 3.25s
global_step/sec: 31.7712
loss = 0.11860799789428711, steps = 102500, cost time = 3.15s
global_step/sec: 30.6271
loss = 0.11375591158866882, steps = 102600, cost time = 3.27s
global_step/sec: 30.9971
loss = 0.13031718134880066, steps = 102700, cost time = 3.23s
global_step/sec: 30.0782
loss = 0.12008974701166153, steps = 102800, cost time = 3.32s
global_step/sec: 31.4916
loss = 0.12178598344326019, steps = 102900, cost time = 3.18s
global_step/sec: 30.1837
loss = 0.10967138409614563, steps = 103000, cost time = 3.31s
global_step/sec: 32.3961
loss = 0.12672603130340576, steps = 103100, cost time = 3.09s
global_step/sec: 31.6693
loss = 0.11843113601207733, steps = 103200, cost time = 3.16s
global_step/sec: 31.9869
loss = 0.14188891649246216, steps = 103300, cost time = 3.13s
global_step/sec: 33.1875
loss = 0.12857286632061005, steps = 103400, cost time = 3.01s
global_step/sec: 31.3252
loss = 0.11712604016065598, steps = 103500, cost time = 3.19s
global_step/sec: 31.8522
loss = 0.12265610694885254, steps = 103600, cost time = 3.14s
global_step/sec: 33.3212
loss = 0.11930850893259048, steps = 103700, cost time = 3.00s
global_step/sec: 32.2889
loss = 0.11571086943149567, steps = 103800, cost time = 3.10s
global_step/sec: 32.0765
loss = 0.1235070675611496, steps = 103900, cost time = 3.12s
global_step/sec: 32.7162
loss = 0.10522131621837616, steps = 104000, cost time = 3.06s
global_step/sec: 33.6032
loss = 0.12040910124778748, steps = 104100, cost time = 2.98s
global_step/sec: 30.8375
loss = 0.10776903480291367, steps = 104200, cost time = 3.24s
global_step/sec: 31.0398
loss = 0.11874082684516907, steps = 104300, cost time = 3.22s
global_step/sec: 33.3638
loss = 0.11639304459095001, steps = 104400, cost time = 3.00s
global_step/sec: 31.5937
loss = 0.11442182958126068, steps = 104500, cost time = 3.17s
global_step/sec: 31.9682
loss = 0.11538408696651459, steps = 104600, cost time = 3.13s
global_step/sec: 32.2753
loss = 0.10502399504184723, steps = 104700, cost time = 3.10s
global_step/sec: 32.6646
loss = 0.12004649639129639, steps = 104800, cost time = 3.06s
global_step/sec: 31.6918
loss = 0.11212940514087677, steps = 104900, cost time = 3.16s
global_step/sec: 31.9867
loss = 0.10434217005968094, steps = 105000, cost time = 3.13s
global_step/sec: 31.7387
loss = 0.11859408020973206, steps = 105100, cost time = 3.15s
global_step/sec: 33.1752
loss = 0.1375804841518402, steps = 105200, cost time = 3.01s
global_step/sec: 30.7546
loss = 0.1196049302816391, steps = 105300, cost time = 3.25s
global_step/sec: 31.9922
loss = 0.11161280423402786, steps = 105400, cost time = 3.13s
global_step/sec: 32.3178
loss = 0.1129874438047409, steps = 105500, cost time = 3.09s
global_step/sec: 33.5515
loss = 0.1210784837603569, steps = 105600, cost time = 2.98s
global_step/sec: 33.1867
loss = 0.109976626932621, steps = 105700, cost time = 3.01s
global_step/sec: 32.3255
loss = 0.1013852059841156, steps = 105800, cost time = 3.09s
global_step/sec: 32.7431
loss = 0.12309843301773071, steps = 105900, cost time = 3.05s
global_step/sec: 32.4226
loss = 0.13078835606575012, steps = 106000, cost time = 3.08s
global_step/sec: 31.0792
loss = 0.1099175214767456, steps = 106100, cost time = 3.22s
global_step/sec: 31.9675
loss = 0.11747642606496811, steps = 106200, cost time = 3.13s
global_step/sec: 33.1270
loss = 0.08970937877893448, steps = 106300, cost time = 3.02s
global_step/sec: 31.8914
loss = 0.10466983914375305, steps = 106400, cost time = 3.14s
global_step/sec: 31.2274
loss = 0.08930077403783798, steps = 106500, cost time = 3.20s
global_step/sec: 31.1812
loss = 0.10049496591091156, steps = 106600, cost time = 3.21s
global_step/sec: 32.5788
loss = 0.1298789083957672, steps = 106700, cost time = 3.07s
global_step/sec: 31.9084
loss = 0.12928275763988495, steps = 106800, cost time = 3.13s
global_step/sec: 32.9140
loss = 0.13444340229034424, steps = 106900, cost time = 3.04s
global_step/sec: 32.1366
loss = 0.1245202124118805, steps = 107000, cost time = 3.11s
global_step/sec: 31.7670
loss = 0.12260947376489639, steps = 107100, cost time = 3.15s
global_step/sec: 31.4705
loss = 0.1401480734348297, steps = 107200, cost time = 3.18s
global_step/sec: 32.4798
loss = 0.11160987615585327, steps = 107300, cost time = 3.08s
global_step/sec: 32.5985
loss = 0.13399158418178558, steps = 107400, cost time = 3.07s
global_step/sec: 30.6664
loss = 0.11672084778547287, steps = 107500, cost time = 3.26s
global_step/sec: 31.6436
loss = 0.1232302337884903, steps = 107600, cost time = 3.16s
global_step/sec: 32.3144
loss = 0.11698083579540253, steps = 107700, cost time = 3.09s
global_step/sec: 32.2733
loss = 0.11916406452655792, steps = 107800, cost time = 3.10s
global_step/sec: 31.7870
loss = 0.10539615899324417, steps = 107900, cost time = 3.15s
global_step/sec: 31.0432
loss = 0.13029584288597107, steps = 108000, cost time = 3.22s
global_step/sec: 30.9873
loss = 0.12875334918498993, steps = 108100, cost time = 3.23s
global_step/sec: 31.3795
loss = 0.11543945968151093, steps = 108200, cost time = 3.19s
global_step/sec: 32.1865
loss = 0.12756551802158356, steps = 108300, cost time = 3.11s
global_step/sec: 31.4890
loss = 0.11098505556583405, steps = 108400, cost time = 3.18s
global_step/sec: 31.8801
loss = 0.11362811177968979, steps = 108500, cost time = 3.14s
global_step/sec: 30.0107
loss = 0.12645018100738525, steps = 108600, cost time = 3.33s
global_step/sec: 31.4108
loss = 0.1216076985001564, steps = 108700, cost time = 3.18s
global_step/sec: 31.5990
loss = 0.12021102011203766, steps = 108800, cost time = 3.16s
global_step/sec: 31.7489
loss = 0.12748000025749207, steps = 108900, cost time = 3.15s
global_step/sec: 32.0852
loss = 0.10525061190128326, steps = 109000, cost time = 3.12s
global_step/sec: 32.0336
loss = 0.10590020567178726, steps = 109100, cost time = 3.12s
global_step/sec: 32.2467
loss = 0.1191674992442131, steps = 109200, cost time = 3.10s
global_step/sec: 33.3673
loss = 0.1130126416683197, steps = 109300, cost time = 3.00s
global_step/sec: 31.4232
loss = 0.09505373239517212, steps = 109400, cost time = 3.18s
global_step/sec: 31.6956
loss = 0.09913856536149979, steps = 109500, cost time = 3.16s
global_step/sec: 33.0285
loss = 0.10625599324703217, steps = 109600, cost time = 3.03s
global_step/sec: 33.3167
loss = 0.13205119967460632, steps = 109700, cost time = 3.00s
global_step/sec: 33.0878
loss = 0.13742539286613464, steps = 109800, cost time = 3.02s
global_step/sec: 32.3845
loss = 0.11685813963413239, steps = 109900, cost time = 3.09s
global_step/sec: 32.1828
loss = 0.1342495083808899, steps = 110000, cost time = 3.11s
global_step/sec: 31.8878
loss = 0.1373378336429596, steps = 110100, cost time = 3.14s
global_step/sec: 31.5171
loss = 0.14236901700496674, steps = 110200, cost time = 3.17s
global_step/sec: 30.7314
loss = 0.12509968876838684, steps = 110300, cost time = 3.25s
global_step/sec: 31.9516
loss = 0.13899542391300201, steps = 110400, cost time = 3.13s
global_step/sec: 31.7404
loss = 0.1324937641620636, steps = 110500, cost time = 3.15s
global_step/sec: 32.1311
loss = 0.12270399928092957, steps = 110600, cost time = 3.11s
global_step/sec: 31.6106
loss = 0.12100255489349365, steps = 110700, cost time = 3.16s
global_step/sec: 32.4774
loss = 0.14129960536956787, steps = 110800, cost time = 3.08s
global_step/sec: 34.0165
loss = 0.10552865266799927, steps = 110900, cost time = 2.94s
global_step/sec: 32.1446
loss = 0.12304697185754776, steps = 111000, cost time = 3.11s
global_step/sec: 31.6383
loss = 0.1020369827747345, steps = 111100, cost time = 3.16s
global_step/sec: 30.4648
loss = 0.11327578127384186, steps = 111200, cost time = 3.28s
global_step/sec: 32.2050
loss = 0.10595744103193283, steps = 111300, cost time = 3.11s
global_step/sec: 31.7797
loss = 0.11686746776103973, steps = 111400, cost time = 3.15s
global_step/sec: 31.6796
loss = 0.11712253838777542, steps = 111500, cost time = 3.16s
global_step/sec: 31.7264
loss = 0.11434158682823181, steps = 111600, cost time = 3.15s
global_step/sec: 30.9589
loss = 0.10931558907032013, steps = 111700, cost time = 3.23s
global_step/sec: 32.7594
loss = 0.1172911748290062, steps = 111800, cost time = 3.05s
global_step/sec: 31.3614
loss = 0.1171075850725174, steps = 111900, cost time = 3.19s
global_step/sec: 32.3017
loss = 0.12752364575862885, steps = 112000, cost time = 3.10s
global_step/sec: 31.5149
loss = 0.10484349727630615, steps = 112100, cost time = 3.17s
global_step/sec: 33.5566
loss = 0.12645579874515533, steps = 112200, cost time = 2.98s
global_step/sec: 31.8468
loss = 0.1080297902226448, steps = 112300, cost time = 3.14s
global_step/sec: 32.1224
loss = 0.11169468611478806, steps = 112400, cost time = 3.11s
global_step/sec: 31.7298
loss = 0.10792530328035355, steps = 112500, cost time = 3.15s
global_step/sec: 31.8469
loss = 0.11320102959871292, steps = 112600, cost time = 3.14s
global_step/sec: 30.8303
loss = 0.1004796028137207, steps = 112700, cost time = 3.24s
global_step/sec: 32.1414
loss = 0.1011420339345932, steps = 112800, cost time = 3.11s
global_step/sec: 31.6427
loss = 0.11239674687385559, steps = 112900, cost time = 3.16s
global_step/sec: 31.6043
loss = 0.1073363870382309, steps = 113000, cost time = 3.16s
global_step/sec: 31.8509
loss = 0.11972054839134216, steps = 113100, cost time = 3.14s
global_step/sec: 31.3641
loss = 0.11524821817874908, steps = 113200, cost time = 3.19s
global_step/sec: 31.5983
loss = 0.123214490711689, steps = 113300, cost time = 3.16s
global_step/sec: 32.3524
loss = 0.11565911769866943, steps = 113400, cost time = 3.09s
global_step/sec: 31.8469
loss = 0.10294368863105774, steps = 113500, cost time = 3.14s
global_step/sec: 31.2815
loss = 0.12851673364639282, steps = 113600, cost time = 3.20s
global_step/sec: 32.3890
loss = 0.10078635066747665, steps = 113700, cost time = 3.09s
global_step/sec: 32.6699
loss = 0.1252100169658661, steps = 113800, cost time = 3.06s
global_step/sec: 32.7601
loss = 0.13568608462810516, steps = 113900, cost time = 3.05s
global_step/sec: 32.6717
loss = 0.10110820829868317, steps = 114000, cost time = 3.06s
global_step/sec: 31.9887
loss = 0.10771791636943817, steps = 114100, cost time = 3.13s
global_step/sec: 31.7219
loss = 0.12739083170890808, steps = 114200, cost time = 3.15s
global_step/sec: 30.3842
loss = 0.09698662161827087, steps = 114300, cost time = 3.29s
global_step/sec: 30.8254
loss = 0.11592654883861542, steps = 114400, cost time = 3.24s
global_step/sec: 30.3714
loss = 0.1059638112783432, steps = 114500, cost time = 3.29s
global_step/sec: 31.5922
loss = 0.124335378408432, steps = 114600, cost time = 3.17s
global_step/sec: 32.5468
loss = 0.1191723644733429, steps = 114700, cost time = 3.07s
global_step/sec: 32.5006
loss = 0.11485399305820465, steps = 114800, cost time = 3.08s
global_step/sec: 31.7643
loss = 0.12565648555755615, steps = 114900, cost time = 3.15s
global_step/sec: 32.0707
loss = 0.12579317390918732, steps = 115000, cost time = 3.12s
global_step/sec: 34.3554
loss = 0.12401241809129715, steps = 115100, cost time = 2.91s
global_step/sec: 33.4097
loss = 0.12571480870246887, steps = 115200, cost time = 2.99s
global_step/sec: 31.9341
loss = 0.1215653270483017, steps = 115300, cost time = 3.13s
global_step/sec: 31.9408
loss = 0.11101134121417999, steps = 115400, cost time = 3.13s
global_step/sec: 31.4023
loss = 0.11211492121219635, steps = 115500, cost time = 3.18s
global_step/sec: 31.0276
loss = 0.11599953472614288, steps = 115600, cost time = 3.22s
global_step/sec: 31.2567
loss = 0.12425258755683899, steps = 115700, cost time = 3.20s
global_step/sec: 32.4857
loss = 0.10324347019195557, steps = 115800, cost time = 3.08s
global_step/sec: 32.2972
loss = 0.1111224889755249, steps = 115900, cost time = 3.10s
global_step/sec: 33.2397
loss = 0.12262372672557831, steps = 116000, cost time = 3.01s
global_step/sec: 31.7606
loss = 0.122544065117836, steps = 116100, cost time = 3.15s
global_step/sec: 31.9510
loss = 0.10982348024845123, steps = 116200, cost time = 3.13s
global_step/sec: 31.8161
loss = 0.1328473538160324, steps = 116300, cost time = 3.14s
global_step/sec: 32.6267
loss = 0.12853901088237762, steps = 116400, cost time = 3.06s
global_step/sec: 32.3846
loss = 0.10915476083755493, steps = 116500, cost time = 3.09s
global_step/sec: 32.0005
loss = 0.1239486038684845, steps = 116600, cost time = 3.12s
global_step/sec: 31.8184
loss = 0.1246742382645607, steps = 116700, cost time = 3.14s
global_step/sec: 31.5440
loss = 0.11380738765001297, steps = 116800, cost time = 3.17s
global_step/sec: 31.4479
loss = 0.11750438064336777, steps = 116900, cost time = 3.18s
global_step/sec: 30.8316
loss = 0.11456295847892761, steps = 117000, cost time = 3.24s
global_step/sec: 31.2033
loss = 0.12929728627204895, steps = 117100, cost time = 3.20s
global_step/sec: 31.5325
loss = 0.09706844389438629, steps = 117200, cost time = 3.17s
global_step/sec: 31.5307
loss = 0.11667300760746002, steps = 117300, cost time = 3.17s
global_step/sec: 31.1070
loss = 0.11072331666946411, steps = 117400, cost time = 3.21s
global_step/sec: 31.6048
loss = 0.1093665361404419, steps = 117500, cost time = 3.16s
global_step/sec: 32.6133
loss = 0.11553186923265457, steps = 117600, cost time = 3.07s
global_step/sec: 31.6584
loss = 0.11035285145044327, steps = 117700, cost time = 3.16s
global_step/sec: 31.0511
loss = 0.11564958095550537, steps = 117800, cost time = 3.22s
global_step/sec: 31.3748
loss = 0.12223658710718155, steps = 117900, cost time = 3.19s
global_step/sec: 31.8662
loss = 0.10807611793279648, steps = 118000, cost time = 3.14s
global_step/sec: 32.0435
loss = 0.12489889562129974, steps = 118100, cost time = 3.12s
global_step/sec: 31.5410
loss = 0.12657517194747925, steps = 118200, cost time = 3.17s
global_step/sec: 31.8933
loss = 0.10489199310541153, steps = 118300, cost time = 3.14s
global_step/sec: 31.4695
loss = 0.11021976172924042, steps = 118400, cost time = 3.18s
global_step/sec: 30.9143
loss = 0.12044161558151245, steps = 118500, cost time = 3.23s
global_step/sec: 31.7385
loss = 0.10545502603054047, steps = 118600, cost time = 3.15s
global_step/sec: 32.0478
loss = 0.10075569152832031, steps = 118700, cost time = 3.12s
global_step/sec: 31.5474
loss = 0.10796339809894562, steps = 118800, cost time = 3.17s
global_step/sec: 30.7185
loss = 0.10766120254993439, steps = 118900, cost time = 3.26s
global_step/sec: 30.7718
loss = 0.11685257405042648, steps = 119000, cost time = 3.25s
global_step/sec: 32.1439
loss = 0.11233387887477875, steps = 119100, cost time = 3.11s
global_step/sec: 32.1062
loss = 0.11323399841785431, steps = 119200, cost time = 3.11s
global_step/sec: 32.6315
loss = 0.11503340303897858, steps = 119300, cost time = 3.06s
global_step/sec: 31.4186
loss = 0.10024100542068481, steps = 119400, cost time = 3.18s
global_step/sec: 31.3927
loss = 0.10042867064476013, steps = 119500, cost time = 3.19s
global_step/sec: 32.5365
loss = 0.11885695159435272, steps = 119600, cost time = 3.07s
global_step/sec: 31.7828
loss = 0.09889920055866241, steps = 119700, cost time = 3.15s
global_step/sec: 30.6239
loss = 0.12602227926254272, steps = 119800, cost time = 3.27s
global_step/sec: 31.7292
loss = 0.11428415030241013, steps = 119900, cost time = 3.15s
global_step/sec: 30.9896
loss = 0.1247396320104599, steps = 120000, cost time = 3.23s
global_step/sec: 31.6743
loss = 0.10540181398391724, steps = 120100, cost time = 3.16s
global_step/sec: 31.9901
loss = 0.11835144460201263, steps = 120200, cost time = 3.13s
global_step/sec: 32.1387
loss = 0.11218973249197006, steps = 120300, cost time = 3.11s
global_step/sec: 32.2358
loss = 0.10460827499628067, steps = 120400, cost time = 3.10s
global_step/sec: 31.4985
loss = 0.10918322205543518, steps = 120500, cost time = 3.17s
global_step/sec: 32.6380
loss = 0.1152118369936943, steps = 120600, cost time = 3.06s
global_step/sec: 31.3804
loss = 0.11524622142314911, steps = 120700, cost time = 3.19s
global_step/sec: 32.2608
loss = 0.12474150955677032, steps = 120800, cost time = 3.10s
global_step/sec: 32.5710
loss = 0.11077907681465149, steps = 120900, cost time = 3.07s
global_step/sec: 31.1411
loss = 0.12505555152893066, steps = 121000, cost time = 3.21s
global_step/sec: 32.3420
loss = 0.11176308989524841, steps = 121100, cost time = 3.09s
global_step/sec: 32.3702
loss = 0.11548548936843872, steps = 121200, cost time = 3.09s
global_step/sec: 32.2091
loss = 0.1306540071964264, steps = 121300, cost time = 3.10s
global_step/sec: 32.5263
loss = 0.11074285209178925, steps = 121400, cost time = 3.07s
global_step/sec: 32.0282
loss = 0.12277823686599731, steps = 121500, cost time = 3.12s
global_step/sec: 31.6610
loss = 0.11026729643344879, steps = 121600, cost time = 3.16s
global_step/sec: 31.9546
loss = 0.11523497104644775, steps = 121700, cost time = 3.13s
global_step/sec: 33.3535
loss = 0.10133668780326843, steps = 121800, cost time = 3.00s
global_step/sec: 33.6038
loss = 0.10090532898902893, steps = 121900, cost time = 2.98s
global_step/sec: 33.8218
loss = 0.10900682955980301, steps = 122000, cost time = 2.96s
global_step/sec: 33.4568
loss = 0.08619590103626251, steps = 122100, cost time = 2.99s
global_step/sec: 32.9537
loss = 0.1152978241443634, steps = 122200, cost time = 3.03s
global_step/sec: 34.3038
loss = 0.11699536442756653, steps = 122300, cost time = 2.92s
global_step/sec: 33.8146
loss = 0.12965792417526245, steps = 122400, cost time = 2.96s
global_step/sec: 33.1205
loss = 0.1183772161602974, steps = 122500, cost time = 3.02s
global_step/sec: 33.1371
loss = 0.12320791929960251, steps = 122600, cost time = 3.02s
global_step/sec: 32.1767
loss = 0.12639984488487244, steps = 122700, cost time = 3.11s
global_step/sec: 34.5342
loss = 0.12343007326126099, steps = 122800, cost time = 2.90s
global_step/sec: 34.0973
loss = 0.12738655507564545, steps = 122900, cost time = 2.93s
global_step/sec: 33.2097
loss = 0.1326724737882614, steps = 123000, cost time = 3.01s
global_step/sec: 32.0649
loss = 0.11045485734939575, steps = 123100, cost time = 3.12s
global_step/sec: 33.3296
loss = 0.13251565396785736, steps = 123200, cost time = 3.00s
global_step/sec: 33.1178
loss = 0.12383115291595459, steps = 123300, cost time = 3.02s
global_step/sec: 33.3970
loss = 0.11117862910032272, steps = 123400, cost time = 2.99s
global_step/sec: 33.2851
loss = 0.11986203491687775, steps = 123500, cost time = 3.00s
global_step/sec: 33.4880
loss = 0.13005554676055908, steps = 123600, cost time = 2.99s
global_step/sec: 33.2324
loss = 0.11404775083065033, steps = 123700, cost time = 3.01s
global_step/sec: 32.8142
loss = 0.10651040077209473, steps = 123800, cost time = 3.05s
global_step/sec: 33.8861
loss = 0.11618101596832275, steps = 123900, cost time = 2.95s
global_step/sec: 33.6102
loss = 0.14726899564266205, steps = 124000, cost time = 2.98s
global_step/sec: 33.6956
loss = 0.10289003700017929, steps = 124100, cost time = 2.97s
global_step/sec: 34.5108
loss = 0.13178184628486633, steps = 124200, cost time = 2.90s
global_step/sec: 33.4979
loss = 0.1074616014957428, steps = 124300, cost time = 2.99s
global_step/sec: 29.8860
loss = 0.10683970153331757, steps = 124400, cost time = 3.35s
global_step/sec: 31.1230
loss = 0.11306418478488922, steps = 124500, cost time = 3.21s
global_step/sec: 29.3393
loss = 0.11032547056674957, steps = 124600, cost time = 3.41s
global_step/sec: 29.7542
loss = 0.1170128658413887, steps = 124700, cost time = 3.36s
global_step/sec: 29.5586
loss = 0.10743106156587601, steps = 124800, cost time = 3.38s
global_step/sec: 29.8697
loss = 0.10004262626171112, steps = 124900, cost time = 3.35s
global_step/sec: 30.8113
loss = 0.1156793087720871, steps = 125000, cost time = 3.25s
global_step/sec: 30.7040
loss = 0.09819335490465164, steps = 125100, cost time = 3.26s
global_step/sec: 28.1984
loss = 0.11104077845811844, steps = 125200, cost time = 3.55s
global_step/sec: 30.7927
loss = 0.11149024963378906, steps = 125300, cost time = 3.25s
global_step/sec: 30.6761
loss = 0.11307238042354584, steps = 125400, cost time = 3.26s
global_step/sec: 28.7031
loss = 0.11335551738739014, steps = 125500, cost time = 3.48s
global_step/sec: 29.9894
loss = 0.13214346766471863, steps = 125600, cost time = 3.33s
global_step/sec: 30.3873
loss = 0.14002126455307007, steps = 125700, cost time = 3.29s
global_step/sec: 31.0647
loss = 0.11663483083248138, steps = 125800, cost time = 3.22s
global_step/sec: 29.4987
loss = 0.12394854426383972, steps = 125900, cost time = 3.39s
global_step/sec: 30.6787
loss = 0.12733212113380432, steps = 126000, cost time = 3.26s
global_step/sec: 28.9467
loss = 0.11506805568933487, steps = 126100, cost time = 3.45s
global_step/sec: 30.5715
loss = 0.13023105263710022, steps = 126200, cost time = 3.27s
global_step/sec: 31.2610
loss = 0.12119975686073303, steps = 126300, cost time = 3.20s
global_step/sec: 29.9313
loss = 0.11541655659675598, steps = 126400, cost time = 3.34s
global_step/sec: 31.1988
loss = 0.12244884669780731, steps = 126500, cost time = 3.21s
global_step/sec: 30.3034
loss = 0.12711599469184875, steps = 126600, cost time = 3.30s
global_step/sec: 28.6950
loss = 0.1248963326215744, steps = 126700, cost time = 3.48s
global_step/sec: 29.5351
loss = 0.1260635256767273, steps = 126800, cost time = 3.39s
global_step/sec: 30.4076
loss = 0.09799055755138397, steps = 126900, cost time = 3.29s
global_step/sec: 29.9520
loss = 0.10263588279485703, steps = 127000, cost time = 3.34s
global_step/sec: 30.5912
loss = 0.11209411174058914, steps = 127100, cost time = 3.27s
global_step/sec: 29.4805
loss = 0.12743856012821198, steps = 127200, cost time = 3.39s
global_step/sec: 30.6882
loss = 0.10981126129627228, steps = 127300, cost time = 3.26s
global_step/sec: 31.7575
loss = 0.12156403809785843, steps = 127400, cost time = 3.15s
global_step/sec: 29.4848
loss = 0.10748893022537231, steps = 127500, cost time = 3.39s
global_step/sec: 29.9990
loss = 0.11901051551103592, steps = 127600, cost time = 3.33s
global_step/sec: 29.9709
loss = 0.13549639284610748, steps = 127700, cost time = 3.34s
global_step/sec: 31.1197
loss = 0.12908607721328735, steps = 127800, cost time = 3.21s
global_step/sec: 29.6564
loss = 0.10652396082878113, steps = 127900, cost time = 3.37s
global_step/sec: 30.3241
loss = 0.12438113987445831, steps = 128000, cost time = 3.30s
global_step/sec: 28.7942
loss = 0.12066499143838882, steps = 128100, cost time = 3.47s
global_step/sec: 28.9172
loss = 0.10578790307044983, steps = 128200, cost time = 3.46s
global_step/sec: 30.1087
loss = 0.10705088078975677, steps = 128300, cost time = 3.32s
global_step/sec: 29.7317
loss = 0.13616758584976196, steps = 128400, cost time = 3.36s
global_step/sec: 29.4550
loss = 0.1417236328125, steps = 128500, cost time = 3.40s
global_step/sec: 29.6382
loss = 0.10215507447719574, steps = 128600, cost time = 3.37s
global_step/sec: 29.2442
loss = 0.10740514099597931, steps = 128700, cost time = 3.42s
global_step/sec: 28.7785
loss = 0.11667243391275406, steps = 128800, cost time = 3.47s
global_step/sec: 29.9529
loss = 0.098625548183918, steps = 128900, cost time = 3.34s
global_step/sec: 30.3535
loss = 0.11701726913452148, steps = 129000, cost time = 3.29s
global_step/sec: 30.1509
loss = 0.12824475765228271, steps = 129100, cost time = 3.32s
global_step/sec: 28.5822
loss = 0.12383704632520676, steps = 129200, cost time = 3.50s
global_step/sec: 28.9499
loss = 0.10323876142501831, steps = 129300, cost time = 3.45s
global_step/sec: 30.4284
loss = 0.10868998616933823, steps = 129400, cost time = 3.29s
global_step/sec: 29.5566
loss = 0.1276913583278656, steps = 129500, cost time = 3.38s
global_step/sec: 28.8297
loss = 0.09979382157325745, steps = 129600, cost time = 3.47s
global_step/sec: 29.4815
loss = 0.12706755101680756, steps = 129700, cost time = 3.39s
global_step/sec: 28.5927
loss = 0.11167498677968979, steps = 129800, cost time = 3.50s
global_step/sec: 29.9979
loss = 0.10220219194889069, steps = 129900, cost time = 3.33s
global_step/sec: 29.0120
loss = 0.10864594578742981, steps = 130000, cost time = 3.45s
global_step/sec: 29.0321
loss = 0.12376207113265991, steps = 130100, cost time = 3.44s
global_step/sec: 28.5925
loss = 0.11269660294055939, steps = 130200, cost time = 3.50s
global_step/sec: 28.9190
loss = 0.13103753328323364, steps = 130300, cost time = 3.46s
global_step/sec: 30.1074
loss = 0.1247917041182518, steps = 130400, cost time = 3.32s
global_step/sec: 28.6472
loss = 0.10324268788099289, steps = 130500, cost time = 3.49s
global_step/sec: 29.7991
loss = 0.11746233701705933, steps = 130600, cost time = 3.36s
global_step/sec: 29.7558
loss = 0.1182461529970169, steps = 130700, cost time = 3.36s
global_step/sec: 29.7788
loss = 0.10281532257795334, steps = 130800, cost time = 3.36s
global_step/sec: 29.5281
loss = 0.14439496397972107, steps = 130900, cost time = 3.39s
global_step/sec: 28.9889
loss = 0.11216054856777191, steps = 131000, cost time = 3.45s
global_step/sec: 28.9136
loss = 0.11394497752189636, steps = 131100, cost time = 3.46s
global_step/sec: 29.6920
loss = 0.12013415992259979, steps = 131200, cost time = 3.37s
global_step/sec: 29.5312
loss = 0.10471941530704498, steps = 131300, cost time = 3.39s
global_step/sec: 30.2175
loss = 0.1323016881942749, steps = 131400, cost time = 3.31s
global_step/sec: 29.6381
loss = 0.09919102489948273, steps = 131500, cost time = 3.37s
global_step/sec: 28.8231
loss = 0.1138637512922287, steps = 131600, cost time = 3.47s
global_step/sec: 29.1746
loss = 0.12155485153198242, steps = 131700, cost time = 3.43s
global_step/sec: 29.3502
loss = 0.10894344747066498, steps = 131800, cost time = 3.41s
global_step/sec: 30.3391
loss = 0.1199309304356575, steps = 131900, cost time = 3.30s
global_step/sec: 28.8034
loss = 0.10713803768157959, steps = 132000, cost time = 3.47s
global_step/sec: 29.8566
loss = 0.112344890832901, steps = 132100, cost time = 3.35s
global_step/sec: 30.1326
loss = 0.12163373827934265, steps = 132200, cost time = 3.32s
global_step/sec: 32.7575
loss = 0.11202585697174072, steps = 132300, cost time = 3.05s
global_step/sec: 28.5202
loss = 0.11470986902713776, steps = 132400, cost time = 3.51s
global_step/sec: 29.7848
loss = 0.11220012605190277, steps = 132500, cost time = 3.36s
global_step/sec: 28.9253
loss = 0.12600716948509216, steps = 132600, cost time = 3.46s
global_step/sec: 29.1503
loss = 0.09259311854839325, steps = 132700, cost time = 3.43s
global_step/sec: 30.0798
loss = 0.12015793472528458, steps = 132800, cost time = 3.32s
global_step/sec: 29.7747
loss = 0.12848927080631256, steps = 132900, cost time = 3.36s
global_step/sec: 29.2126
loss = 0.11513613909482956, steps = 133000, cost time = 3.42s
global_step/sec: 29.1164
loss = 0.10631072521209717, steps = 133100, cost time = 3.43s
global_step/sec: 29.9335
loss = 0.12473860383033752, steps = 133200, cost time = 3.34s
global_step/sec: 30.5157
loss = 0.11521174013614655, steps = 133300, cost time = 3.28s
global_step/sec: 30.5494
loss = 0.11227789521217346, steps = 133400, cost time = 3.27s
global_step/sec: 30.2836
loss = 0.11067062616348267, steps = 133500, cost time = 3.30s
global_step/sec: 29.0526
loss = 0.11919823288917542, steps = 133600, cost time = 3.44s
global_step/sec: 28.7796
loss = 0.09940707683563232, steps = 133700, cost time = 3.47s
global_step/sec: 29.0419
loss = 0.09689192473888397, steps = 133800, cost time = 3.44s
global_step/sec: 30.0647
loss = 0.10757840424776077, steps = 133900, cost time = 3.33s
global_step/sec: 31.3605
loss = 0.1121663749217987, steps = 134000, cost time = 3.19s
global_step/sec: 30.6293
loss = 0.11059211194515228, steps = 134100, cost time = 3.26s
global_step/sec: 29.3232
loss = 0.10145814716815948, steps = 134200, cost time = 3.41s
global_step/sec: 28.7872
loss = 0.14606857299804688, steps = 134300, cost time = 3.47s
global_step/sec: 30.6085
loss = 0.11109389364719391, steps = 134400, cost time = 3.27s
global_step/sec: 28.7799
loss = 0.11524892598390579, steps = 134500, cost time = 3.47s
global_step/sec: 28.3832
loss = 0.1052912026643753, steps = 134600, cost time = 3.52s
global_step/sec: 30.2081
loss = 0.10574086010456085, steps = 134700, cost time = 3.31s
global_step/sec: 29.3435
loss = 0.13177813589572906, steps = 134800, cost time = 3.41s
global_step/sec: 29.4296
loss = 0.11353074014186859, steps = 134900, cost time = 3.40s
global_step/sec: 29.2806
loss = 0.10788418352603912, steps = 135000, cost time = 3.42s
global_step/sec: 29.6522
loss = 0.11882196366786957, steps = 135100, cost time = 3.37s
global_step/sec: 28.8342
loss = 0.1213158518075943, steps = 135200, cost time = 3.47s
global_step/sec: 29.3137
loss = 0.1148977279663086, steps = 135300, cost time = 3.41s
global_step/sec: 29.5797
loss = 0.11028969287872314, steps = 135400, cost time = 3.38s
global_step/sec: 29.1871
loss = 0.10285533964633942, steps = 135500, cost time = 3.43s
global_step/sec: 29.4569
loss = 0.12328165769577026, steps = 135600, cost time = 3.39s
global_step/sec: 30.1274
loss = 0.12826453149318695, steps = 135700, cost time = 3.32s
global_step/sec: 30.1710
loss = 0.11184053122997284, steps = 135800, cost time = 3.31s
global_step/sec: 30.0817
loss = 0.11077386140823364, steps = 135900, cost time = 3.32s
global_step/sec: 29.2315
loss = 0.10313522815704346, steps = 136000, cost time = 3.42s
global_step/sec: 29.3537
loss = 0.11393721401691437, steps = 136100, cost time = 3.41s
global_step/sec: 29.4335
loss = 0.13215801119804382, steps = 136200, cost time = 3.40s
global_step/sec: 29.4400
loss = 0.11854709684848785, steps = 136300, cost time = 3.40s
global_step/sec: 30.0166
loss = 0.10789967328310013, steps = 136400, cost time = 3.33s
global_step/sec: 29.9594
loss = 0.11526437848806381, steps = 136500, cost time = 3.34s
global_step/sec: 29.2757
loss = 0.11119730770587921, steps = 136600, cost time = 3.42s
global_step/sec: 29.7304
loss = 0.12044504284858704, steps = 136700, cost time = 3.36s
global_step/sec: 31.5066
loss = 0.10055810213088989, steps = 136800, cost time = 3.17s
global_step/sec: 29.9964
loss = 0.10976645350456238, steps = 136900, cost time = 3.33s
global_step/sec: 30.2650
loss = 0.11123007535934448, steps = 137000, cost time = 3.30s
global_step/sec: 30.6674
loss = 0.09118850529193878, steps = 137100, cost time = 3.26s
global_step/sec: 29.9884
loss = 0.10820333659648895, steps = 137200, cost time = 3.33s
global_step/sec: 29.1428
loss = 0.1136915385723114, steps = 137300, cost time = 3.43s
global_step/sec: 28.4634
loss = 0.10368435084819794, steps = 137400, cost time = 3.51s
global_step/sec: 30.0691
loss = 0.11362945288419724, steps = 137500, cost time = 3.33s
global_step/sec: 29.2585
loss = 0.12495920062065125, steps = 137600, cost time = 3.42s
global_step/sec: 30.3418
loss = 0.08810527622699738, steps = 137700, cost time = 3.30s
global_step/sec: 29.7001
loss = 0.09498319029808044, steps = 137800, cost time = 3.37s
global_step/sec: 28.8634
loss = 0.11344999819993973, steps = 137900, cost time = 3.46s
global_step/sec: 28.5115
loss = 0.12327565997838974, steps = 138000, cost time = 3.51s
global_step/sec: 29.5293
loss = 0.11570854485034943, steps = 138100, cost time = 3.39s
global_step/sec: 29.2777
loss = 0.11218052357435226, steps = 138200, cost time = 3.42s
global_step/sec: 29.4686
loss = 0.1268436312675476, steps = 138300, cost time = 3.39s
global_step/sec: 29.2968
loss = 0.14976033568382263, steps = 138400, cost time = 3.41s
global_step/sec: 29.2221
loss = 0.10997329652309418, steps = 138500, cost time = 3.42s
global_step/sec: 30.3368
loss = 0.12526506185531616, steps = 138600, cost time = 3.30s
global_step/sec: 30.1309
loss = 0.12625786662101746, steps = 138700, cost time = 3.32s
global_step/sec: 28.3750
loss = 0.11600455641746521, steps = 138800, cost time = 3.52s
global_step/sec: 32.0750
loss = 0.11423826962709427, steps = 138900, cost time = 3.12s
global_step/sec: 33.8757
loss = 0.12074436247348785, steps = 139000, cost time = 2.95s
global_step/sec: 33.2905
loss = 0.11248624324798584, steps = 139100, cost time = 3.00s
global_step/sec: 33.1174
loss = 0.10788435488939285, steps = 139200, cost time = 3.02s
global_step/sec: 34.0706
loss = 0.12467585504055023, steps = 139300, cost time = 2.94s
global_step/sec: 34.5329
loss = 0.12143950164318085, steps = 139400, cost time = 2.90s
global_step/sec: 32.9163
loss = 0.11320395022630692, steps = 139500, cost time = 3.04s
global_step/sec: 33.5457
loss = 0.11979718506336212, steps = 139600, cost time = 2.98s
global_step/sec: 34.1929
loss = 0.11185961961746216, steps = 139700, cost time = 2.92s
global_step/sec: 34.1767
loss = 0.11155201494693756, steps = 139800, cost time = 2.93s
global_step/sec: 32.8127
loss = 0.09800831228494644, steps = 139900, cost time = 3.05s
global_step/sec: 34.2611
loss = 0.12700268626213074, steps = 140000, cost time = 2.92s
global_step/sec: 35.7249
loss = 0.11184638738632202, steps = 140100, cost time = 2.80s
global_step/sec: 31.8787
loss = 0.1155700534582138, steps = 140200, cost time = 3.14s
global_step/sec: 30.3820
loss = 0.11208231002092361, steps = 140300, cost time = 3.29s
global_step/sec: 29.4259
loss = 0.12007922679185867, steps = 140400, cost time = 3.40s
global_step/sec: 29.4138
loss = 0.11942259967327118, steps = 140500, cost time = 3.40s
global_step/sec: 29.1371
loss = 0.10929764807224274, steps = 140600, cost time = 3.43s
global_step/sec: 28.6320
loss = 0.08250980079174042, steps = 140700, cost time = 3.49s
global_step/sec: 29.2943
loss = 0.08886078745126724, steps = 140800, cost time = 3.41s
global_step/sec: 30.3785
loss = 0.1196034699678421, steps = 140900, cost time = 3.29s
global_step/sec: 29.8812
loss = 0.10237838327884674, steps = 141000, cost time = 3.35s
global_step/sec: 28.8651
loss = 0.11283543705940247, steps = 141100, cost time = 3.46s
global_step/sec: 28.7530
loss = 0.10227905958890915, steps = 141200, cost time = 3.48s
global_step/sec: 28.7735
loss = 0.11448653042316437, steps = 141300, cost time = 3.48s
global_step/sec: 27.9515
loss = 0.1256493180990219, steps = 141400, cost time = 3.58s
global_step/sec: 28.2721
loss = 0.11704652011394501, steps = 141500, cost time = 3.54s
global_step/sec: 28.3157
loss = 0.10920485854148865, steps = 141600, cost time = 3.53s
global_step/sec: 28.2059
loss = 0.1202511414885521, steps = 141700, cost time = 3.55s
global_step/sec: 27.6671
loss = 0.10416553914546967, steps = 141800, cost time = 3.61s
global_step/sec: 28.8051
loss = 0.10675700008869171, steps = 141900, cost time = 3.47s
global_step/sec: 27.5414
loss = 0.12646864354610443, steps = 142000, cost time = 3.63s
global_step/sec: 28.6377
loss = 0.1258222907781601, steps = 142100, cost time = 3.49s
global_step/sec: 28.3082
loss = 0.1080147996544838, steps = 142200, cost time = 3.53s
global_step/sec: 27.9663
loss = 0.10239966958761215, steps = 142300, cost time = 3.58s
global_step/sec: 29.5396
loss = 0.10476046055555344, steps = 142400, cost time = 3.39s
global_step/sec: 28.2011
loss = 0.10882245749235153, steps = 142500, cost time = 3.55s
global_step/sec: 28.1724
loss = 0.10045191645622253, steps = 142600, cost time = 3.55s
global_step/sec: 28.7918
loss = 0.09708746522665024, steps = 142700, cost time = 3.47s
global_step/sec: 29.5001
loss = 0.12499871104955673, steps = 142800, cost time = 3.39s
global_step/sec: 27.6429
loss = 0.11084002256393433, steps = 142900, cost time = 3.62s
global_step/sec: 28.5612
loss = 0.09758254140615463, steps = 143000, cost time = 3.50s
global_step/sec: 28.5501
loss = 0.11631159484386444, steps = 143100, cost time = 3.50s
global_step/sec: 29.4152
loss = 0.11699051409959793, steps = 143200, cost time = 3.40s
global_step/sec: 28.3373
loss = 0.09811820834875107, steps = 143300, cost time = 3.53s
global_step/sec: 28.0802
loss = 0.10326187312602997, steps = 143400, cost time = 3.56s
global_step/sec: 28.4714
loss = 0.10642367601394653, steps = 143500, cost time = 3.51s
global_step/sec: 28.9343
loss = 0.10767905414104462, steps = 143600, cost time = 3.46s
global_step/sec: 29.5644
loss = 0.10205329954624176, steps = 143700, cost time = 3.38s
global_step/sec: 28.2429
loss = 0.11329571902751923, steps = 143800, cost time = 3.54s
global_step/sec: 27.4356
loss = 0.10418002307415009, steps = 143900, cost time = 3.64s
global_step/sec: 27.3465
loss = 0.11141422390937805, steps = 144000, cost time = 3.66s
global_step/sec: 29.0268
loss = 0.11154772341251373, steps = 144100, cost time = 3.45s
global_step/sec: 27.1557
loss = 0.11696919798851013, steps = 144200, cost time = 3.68s
global_step/sec: 29.1806
loss = 0.12400034070014954, steps = 144300, cost time = 3.43s
global_step/sec: 29.4174
loss = 0.09582354128360748, steps = 144400, cost time = 3.40s
global_step/sec: 28.9807
loss = 0.1122373640537262, steps = 144500, cost time = 3.45s
global_step/sec: 29.2302
loss = 0.11983672529459, steps = 144600, cost time = 3.42s
global_step/sec: 29.5529
loss = 0.10579494386911392, steps = 144700, cost time = 3.38s
global_step/sec: 29.1325
loss = 0.12361658364534378, steps = 144800, cost time = 3.43s
global_step/sec: 28.2286
loss = 0.09821556508541107, steps = 144900, cost time = 3.54s
global_step/sec: 28.9594
loss = 0.10390406847000122, steps = 145000, cost time = 3.45s
global_step/sec: 30.5144
loss = 0.1040637269616127, steps = 145100, cost time = 3.28s
global_step/sec: 27.8654
loss = 0.10280649363994598, steps = 145200, cost time = 3.59s
global_step/sec: 27.8886
loss = 0.11246258020401001, steps = 145300, cost time = 3.59s
global_step/sec: 28.2773
loss = 0.09234828501939774, steps = 145400, cost time = 3.54s
global_step/sec: 29.5923
loss = 0.10230106115341187, steps = 145500, cost time = 3.38s
global_step/sec: 28.5480
loss = 0.11934614181518555, steps = 145600, cost time = 3.50s
global_step/sec: 28.4692
loss = 0.12332751601934433, steps = 145700, cost time = 3.51s
global_step/sec: 29.0435
loss = 0.09482161700725555, steps = 145800, cost time = 3.44s
global_step/sec: 28.4097
loss = 0.1185636967420578, steps = 145900, cost time = 3.52s
global_step/sec: 28.8755
loss = 0.10592537373304367, steps = 146000, cost time = 3.46s
global_step/sec: 30.0358
loss = 0.10864432901144028, steps = 146100, cost time = 3.33s
global_step/sec: 27.8481
loss = 0.10420289635658264, steps = 146200, cost time = 3.59s
global_step/sec: 28.7454
loss = 0.1199239045381546, steps = 146300, cost time = 3.48s
global_step/sec: 29.9739
loss = 0.11468147486448288, steps = 146400, cost time = 3.34s
global_step/sec: 29.3384
loss = 0.11993202567100525, steps = 146500, cost time = 3.41s
global_step/sec: 28.7382
loss = 0.09853535890579224, steps = 146600, cost time = 3.48s
global_step/sec: 29.8357
loss = 0.10341451317071915, steps = 146700, cost time = 3.35s
global_step/sec: 29.0904
loss = 0.12377512454986572, steps = 146800, cost time = 3.44s
global_step/sec: 30.1596
loss = 0.09944295883178711, steps = 146900, cost time = 3.32s
global_step/sec: 30.6122
loss = 0.11074276268482208, steps = 147000, cost time = 3.27s
global_step/sec: 30.9887
loss = 0.09738178551197052, steps = 147100, cost time = 3.23s
global_step/sec: 32.4644
loss = 0.11228662729263306, steps = 147200, cost time = 3.08s
global_step/sec: 31.3282
loss = 0.10809336602687836, steps = 147300, cost time = 3.19s
global_step/sec: 29.3452
loss = 0.10046231001615524, steps = 147400, cost time = 3.41s
global_step/sec: 29.8407
loss = 0.12886390089988708, steps = 147500, cost time = 3.35s
global_step/sec: 29.0932
loss = 0.1151331216096878, steps = 147600, cost time = 3.44s
global_step/sec: 29.8018
loss = 0.11355604231357574, steps = 147700, cost time = 3.36s
global_step/sec: 30.0725
loss = 0.12465596199035645, steps = 147800, cost time = 3.33s
global_step/sec: 29.1955
loss = 0.10604347288608551, steps = 147900, cost time = 3.43s
global_step/sec: 29.0973
loss = 0.10822917520999908, steps = 148000, cost time = 3.44s
global_step/sec: 30.8316
loss = 0.12002857029438019, steps = 148100, cost time = 3.24s
global_step/sec: 30.9336
loss = 0.09161657094955444, steps = 148200, cost time = 3.23s
global_step/sec: 29.2151
loss = 0.11982417106628418, steps = 148300, cost time = 3.42s
global_step/sec: 28.8796
loss = 0.1250622421503067, steps = 148400, cost time = 3.46s
global_step/sec: 29.1658
loss = 0.10612224042415619, steps = 148500, cost time = 3.43s
global_step/sec: 30.1795
loss = 0.10449619591236115, steps = 148600, cost time = 3.31s
global_step/sec: 30.8383
loss = 0.11184059083461761, steps = 148700, cost time = 3.24s
global_step/sec: 29.9378
loss = 0.09261205792427063, steps = 148800, cost time = 3.34s
global_step/sec: 30.0110
loss = 0.09950610250234604, steps = 148900, cost time = 3.33s
global_step/sec: 31.1498
loss = 0.10877355933189392, steps = 149000, cost time = 3.21s
global_step/sec: 31.2263
loss = 0.11419437825679779, steps = 149100, cost time = 3.20s
global_step/sec: 28.8484
loss = 0.11332504451274872, steps = 149200, cost time = 3.47s
global_step/sec: 28.5415
loss = 0.11540640145540237, steps = 149300, cost time = 3.50s
global_step/sec: 27.3318
loss = 0.11218748241662979, steps = 149400, cost time = 3.66s
global_step/sec: 29.5983
loss = 0.11228615790605545, steps = 149500, cost time = 3.38s
global_step/sec: 28.7472
loss = 0.1407865583896637, steps = 149600, cost time = 3.48s
global_step/sec: 26.2090
loss = 0.11360543966293335, steps = 149700, cost time = 3.82s
global_step/sec: 26.8985
loss = 0.1182127520442009, steps = 149800, cost time = 3.72s
global_step/sec: 26.5834
loss = 0.09505116939544678, steps = 149900, cost time = 3.76s
global_step/sec: 28.0804
loss = 0.11155612021684647, steps = 150000, cost time = 3.56s
global_step/sec: 28.5244
loss = 0.10992477834224701, steps = 150100, cost time = 3.51s
global_step/sec: 28.5636
loss = 0.12186699360609055, steps = 150200, cost time = 3.50s
global_step/sec: 27.0173
loss = 0.11838636547327042, steps = 150300, cost time = 3.70s
global_step/sec: 26.4943
loss = 0.12000434100627899, steps = 150400, cost time = 3.77s
global_step/sec: 27.5029
loss = 0.10405203700065613, steps = 150500, cost time = 3.64s
global_step/sec: 27.4420
loss = 0.10732737928628922, steps = 150600, cost time = 3.64s
global_step/sec: 28.7452
loss = 0.10964376479387283, steps = 150700, cost time = 3.48s
global_step/sec: 27.5990
loss = 0.10868291556835175, steps = 150800, cost time = 3.62s
global_step/sec: 28.1837
loss = 0.11977636814117432, steps = 150900, cost time = 3.55s
global_step/sec: 26.8570
loss = 0.10169689357280731, steps = 151000, cost time = 3.72s
global_step/sec: 28.3707
loss = 0.09145991504192352, steps = 151100, cost time = 3.52s
global_step/sec: 26.8026
loss = 0.10455380380153656, steps = 151200, cost time = 3.73s
global_step/sec: 26.5118
loss = 0.12064582109451294, steps = 151300, cost time = 3.77s
global_step/sec: 26.3592
loss = 0.11153416335582733, steps = 151400, cost time = 3.79s
global_step/sec: 27.4273
loss = 0.09263011068105698, steps = 151500, cost time = 3.65s
global_step/sec: 29.2085
loss = 0.09974916279315948, steps = 151600, cost time = 3.42s
global_step/sec: 28.4527
loss = 0.10989704728126526, steps = 151700, cost time = 3.51s
global_step/sec: 27.4904
loss = 0.11780659109354019, steps = 151800, cost time = 3.64s
global_step/sec: 27.6594
loss = 0.11176200211048126, steps = 151900, cost time = 3.62s
global_step/sec: 29.3034
loss = 0.10356089472770691, steps = 152000, cost time = 3.41s
global_step/sec: 26.2417
loss = 0.12769518792629242, steps = 152100, cost time = 3.81s
global_step/sec: 27.4706
loss = 0.12652412056922913, steps = 152200, cost time = 3.64s
global_step/sec: 27.5121
loss = 0.11729411780834198, steps = 152300, cost time = 3.63s
global_step/sec: 27.6901
loss = 0.08431631326675415, steps = 152400, cost time = 3.61s
global_step/sec: 27.4478
loss = 0.11915062367916107, steps = 152500, cost time = 3.64s
global_step/sec: 26.2456
loss = 0.11504501849412918, steps = 152600, cost time = 3.81s
global_step/sec: 27.1595
loss = 0.11021020263433456, steps = 152700, cost time = 3.68s
global_step/sec: 27.0754
loss = 0.10480664670467377, steps = 152800, cost time = 3.69s
global_step/sec: 28.4928
loss = 0.11818888783454895, steps = 152900, cost time = 3.51s
global_step/sec: 27.5991
loss = 0.10462911427021027, steps = 153000, cost time = 3.62s
global_step/sec: 26.7298
loss = 0.10145425796508789, steps = 153100, cost time = 3.74s
global_step/sec: 27.3783
loss = 0.11084806174039841, steps = 153200, cost time = 3.65s
global_step/sec: 28.4963
loss = 0.10593815892934799, steps = 153300, cost time = 3.51s
global_step/sec: 27.5429
loss = 0.08076150715351105, steps = 153400, cost time = 3.63s
global_step/sec: 27.4459
loss = 0.10228386521339417, steps = 153500, cost time = 3.64s
global_step/sec: 28.1355
loss = 0.10317175090312958, steps = 153600, cost time = 3.55s
global_step/sec: 28.9445
loss = 0.13027511537075043, steps = 153700, cost time = 3.45s
global_step/sec: 28.0052
loss = 0.1292574256658554, steps = 153800, cost time = 3.57s
global_step/sec: 29.3752
loss = 0.12285779416561127, steps = 153900, cost time = 3.40s
global_step/sec: 27.7151
loss = 0.11692071706056595, steps = 154000, cost time = 3.61s
global_step/sec: 28.4439
loss = 0.12404283881187439, steps = 154100, cost time = 3.52s
global_step/sec: 26.7799
loss = 0.11735852062702179, steps = 154200, cost time = 3.73s
global_step/sec: 26.4404
loss = 0.14278526604175568, steps = 154300, cost time = 3.78s
global_step/sec: 27.4070
loss = 0.11473929136991501, steps = 154400, cost time = 3.65s
global_step/sec: 25.8469
loss = 0.11597464233636856, steps = 154500, cost time = 3.87s
global_step/sec: 27.4025
loss = 0.1130022406578064, steps = 154600, cost time = 3.65s
global_step/sec: 27.3775
loss = 0.11690197139978409, steps = 154700, cost time = 3.65s
global_step/sec: 27.5476
loss = 0.10246293246746063, steps = 154800, cost time = 3.63s
global_step/sec: 26.9608
loss = 0.10535011440515518, steps = 154900, cost time = 3.71s
global_step/sec: 27.7638
loss = 0.11664068698883057, steps = 155000, cost time = 3.60s
global_step/sec: 28.4040
loss = 0.11287448555231094, steps = 155100, cost time = 3.52s
global_step/sec: 26.6401
loss = 0.1321946680545807, steps = 155200, cost time = 3.75s
global_step/sec: 27.0646
loss = 0.12395411729812622, steps = 155300, cost time = 3.69s
global_step/sec: 28.9986
loss = 0.10631145536899567, steps = 155400, cost time = 3.45s
global_step/sec: 27.7876
loss = 0.10581855475902557, steps = 155500, cost time = 3.60s
global_step/sec: 27.6319
loss = 0.0898737758398056, steps = 155600, cost time = 3.62s
global_step/sec: 25.8665
loss = 0.12540778517723083, steps = 155700, cost time = 3.87s
global_step/sec: 26.2727
loss = 0.10380049049854279, steps = 155800, cost time = 3.81s
global_step/sec: 26.2851
loss = 0.1083768978714943, steps = 155900, cost time = 3.80s
global_step/sec: 26.6555
loss = 0.10755162686109543, steps = 156000, cost time = 3.75s
global_step/sec: 26.9281
loss = 0.12018047273159027, steps = 156100, cost time = 3.71s
global_step/sec: 27.4565
loss = 0.09898547828197479, steps = 156200, cost time = 3.64s
global_step/sec: 85003.5715
loss = 0.11266455054283142, steps = 156249, cost time = 1.84s
Evaluation complate:[1000/3907]
Evaluation complate:[2000/3907]
Evaluation complate:[3000/3907]
Evaluation complate:[3907/3907]
ACC = 0.7635899782180786
AUC = 0.7436737418174744
