INFO:tensorflow:Parsing ./data/taobao_train_data
INFO:tensorflow:Parsing ./data/taobao_test_data
2022-03-31 09:29:35.007873: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3400000000 Hz
2022-03-31 09:29:35.040266: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5733120 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-03-31 09:29:35.040359: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Using TensorFlow version 1.15.5
Checking dataset
Numbers of training dataset is 50000
Numbers of test dataset is 10000
Saving model checkpoints to /benchmark_result/checkpoint/2022-03-31-14-47-37/dssm_deeprec_fp32
global_step/sec: 18.4991
loss = 1914.4189453125, steps = 0, cost time = 5.41s
global_step/sec: 25.3530
loss = 1217.88037109375, steps = 100, cost time = 3.94s
global_step/sec: 23.9254
loss = 1089.5723876953125, steps = 200, cost time = 4.18s
global_step/sec: 24.0239
loss = 1212.166748046875, steps = 300, cost time = 4.16s
global_step/sec: 24.6849
loss = 990.1256103515625, steps = 400, cost time = 4.05s
global_step/sec: 26.0985
loss = 1265.490966796875, steps = 500, cost time = 3.83s
global_step/sec: 25.3148
loss = 1116.5657958984375, steps = 600, cost time = 3.95s
global_step/sec: 25.3906
loss = 964.728271484375, steps = 700, cost time = 3.94s
global_step/sec: 24.0613
loss = 1184.4677734375, steps = 800, cost time = 4.16s
global_step/sec: 25.2065
loss = 1190.2447509765625, steps = 900, cost time = 3.97s
global_step/sec: 24.3454
loss = 1100.732421875, steps = 1000, cost time = 4.11s
global_step/sec: 25.2593
loss = 1195.812744140625, steps = 1100, cost time = 3.96s
global_step/sec: 28.0733
loss = 1259.724853515625, steps = 1200, cost time = 3.56s
global_step/sec: 28.7386
loss = 1093.505859375, steps = 1300, cost time = 3.48s
global_step/sec: 24.6813
loss = 986.5562133789062, steps = 1400, cost time = 4.05s
global_step/sec: 25.1195
loss = 1220.54296875, steps = 1500, cost time = 3.98s
global_step/sec: 25.2650
loss = 1246.1112060546875, steps = 1600, cost time = 3.96s
global_step/sec: 25.9382
loss = 1175.488525390625, steps = 1700, cost time = 3.86s
global_step/sec: 25.2230
loss = 1011.0093994140625, steps = 1800, cost time = 3.96s
global_step/sec: 24.3803
loss = 1278.0128173828125, steps = 1900, cost time = 4.10s
global_step/sec: 24.2604
loss = 1156.0753173828125, steps = 2000, cost time = 4.12s
global_step/sec: 26.1220
loss = 1323.1494140625, steps = 2100, cost time = 3.83s
global_step/sec: 26.4129
loss = 1105.130126953125, steps = 2200, cost time = 3.79s
global_step/sec: 26.1192
loss = 1232.661376953125, steps = 2300, cost time = 3.83s
global_step/sec: 24.0923
loss = 1258.341796875, steps = 2400, cost time = 4.15s
global_step/sec: 24.6123
loss = 1004.2950439453125, steps = 2500, cost time = 4.06s
global_step/sec: 24.8866
loss = 1168.4971923828125, steps = 2600, cost time = 4.02s
global_step/sec: 24.8575
loss = 1168.46044921875, steps = 2700, cost time = 4.02s
global_step/sec: 24.2499
loss = 1187.591552734375, steps = 2800, cost time = 4.12s
global_step/sec: 24.8421
loss = 1123.851806640625, steps = 2900, cost time = 4.03s
global_step/sec: 24.2279
loss = 1123.8170166015625, steps = 3000, cost time = 4.13s
global_step/sec: 24.6758
loss = 1130.1400146484375, steps = 3100, cost time = 4.05s
global_step/sec: 25.0035
loss = 1117.42041015625, steps = 3200, cost time = 4.00s
global_step/sec: 24.6723
loss = 1117.3953857421875, steps = 3300, cost time = 4.05s
global_step/sec: 26.5841
loss = 1296.7510986328125, steps = 3400, cost time = 3.76s
global_step/sec: 24.3358
loss = 1187.40625, steps = 3500, cost time = 4.11s
global_step/sec: 24.1279
loss = 1174.604736328125, steps = 3600, cost time = 4.14s
global_step/sec: 25.2322
loss = 1174.5859375, steps = 3700, cost time = 3.96s
global_step/sec: 24.5570
loss = 978.9736328125, steps = 3800, cost time = 4.07s
global_step/sec: 25.3611
loss = 1168.1728515625, steps = 3900, cost time = 3.94s
global_step/sec: 25.3385
loss = 1245.04052734375, steps = 4000, cost time = 3.95s
global_step/sec: 23.8739
loss = 1054.0771484375, steps = 4100, cost time = 4.19s
global_step/sec: 24.1617
loss = 1066.662353515625, steps = 4200, cost time = 4.14s
global_step/sec: 25.5726
loss = 966.4515380859375, steps = 4300, cost time = 3.91s
global_step/sec: 23.7945
loss = 1322.51318359375, steps = 4400, cost time = 4.20s
global_step/sec: 24.3238
loss = 1328.9752197265625, steps = 4500, cost time = 4.11s
global_step/sec: 24.2115
loss = 1142.6029052734375, steps = 4600, cost time = 4.13s
global_step/sec: 25.4268
loss = 1110.84521484375, steps = 4700, cost time = 3.93s
global_step/sec: 24.4837
loss = 1072.8985595703125, steps = 4800, cost time = 4.08s
global_step/sec: 24.8138
loss = 1168.053955078125, steps = 4900, cost time = 4.03s
global_step/sec: 24.5651
loss = 972.602783203125, steps = 5000, cost time = 4.07s
global_step/sec: 23.8831
loss = 1129.842041015625, steps = 5100, cost time = 4.19s
global_step/sec: 24.2376
loss = 1148.9102783203125, steps = 5200, cost time = 4.13s
global_step/sec: 24.0626
loss = 1180.7918701171875, steps = 5300, cost time = 4.16s
global_step/sec: 24.5385
loss = 1219.201904296875, steps = 5400, cost time = 4.08s
global_step/sec: 25.1028
loss = 1315.91845703125, steps = 5500, cost time = 3.98s
global_step/sec: 24.6518
loss = 1219.1845703125, steps = 5600, cost time = 4.06s
global_step/sec: 24.6740
loss = 1028.795654296875, steps = 5700, cost time = 4.05s
global_step/sec: 24.3337
loss = 1187.1485595703125, steps = 5800, cost time = 4.11s
global_step/sec: 26.6727
loss = 1136.143798828125, steps = 5900, cost time = 3.75s
global_step/sec: 27.0676
loss = 1142.4947509765625, steps = 6000, cost time = 3.69s
global_step/sec: 27.6111
loss = 1199.927734375, steps = 6100, cost time = 3.62s
global_step/sec: 26.0805
loss = 1110.7388916015625, steps = 6200, cost time = 3.83s
global_step/sec: 26.1685
loss = 1009.9669189453125, steps = 6300, cost time = 3.82s
global_step/sec: 24.8696
loss = 1104.3931884765625, steps = 6400, cost time = 4.02s
global_step/sec: 25.4520
loss = 1098.0576171875, steps = 6500, cost time = 3.93s
global_step/sec: 24.2595
loss = 1187.1087646484375, steps = 6600, cost time = 4.12s
global_step/sec: 24.7936
loss = 1283.507080078125, steps = 6700, cost time = 4.03s
global_step/sec: 24.5328
loss = 1167.9385986328125, steps = 6800, cost time = 4.08s
global_step/sec: 24.7025
loss = 1167.9375, steps = 6900, cost time = 4.05s
global_step/sec: 24.0606
loss = 1212.700439453125, steps = 7000, cost time = 4.16s
global_step/sec: 23.6385
loss = 1199.885498046875, steps = 7100, cost time = 4.23s
global_step/sec: 24.0395
loss = 1129.72900390625, steps = 7200, cost time = 4.16s
global_step/sec: 23.8799
loss = 1091.7021484375, steps = 7300, cost time = 4.19s
global_step/sec: 24.4355
loss = 1129.72265625, steps = 7400, cost time = 4.09s
global_step/sec: 24.4349
loss = 1016.1795043945312, steps = 7500, cost time = 4.09s
global_step/sec: 24.0925
loss = 1136.0712890625, steps = 7600, cost time = 4.15s
global_step/sec: 24.3817
loss = 1193.4630126953125, steps = 7700, cost time = 4.10s
global_step/sec: 24.4571
loss = 1167.904296875, steps = 7800, cost time = 4.09s
global_step/sec: 24.2678
loss = 1085.361572265625, steps = 7900, cost time = 4.12s
global_step/sec: 24.8171
loss = 1193.455078125, steps = 8000, cost time = 4.03s
global_step/sec: 24.9655
loss = 1041.2568359375, steps = 8100, cost time = 4.01s
global_step/sec: 24.6486
loss = 1206.256591796875, steps = 8200, cost time = 4.06s
global_step/sec: 25.2991
loss = 1354.761962890625, steps = 8300, cost time = 3.95s
global_step/sec: 24.5847
loss = 997.3929443359375, steps = 8400, cost time = 4.07s
global_step/sec: 25.4985
loss = 1136.046630859375, steps = 8500, cost time = 3.92s
global_step/sec: 24.4791
loss = 1174.26806640625, steps = 8600, cost time = 4.09s
global_step/sec: 24.3360
loss = 1219.067138671875, steps = 8700, cost time = 4.11s
global_step/sec: 24.6186
loss = 1219.06494140625, steps = 8800, cost time = 4.06s
global_step/sec: 24.7187
loss = 1110.649169921875, steps = 8900, cost time = 4.05s
global_step/sec: 24.0120
loss = 959.99072265625, steps = 9000, cost time = 4.16s
global_step/sec: 24.8478
loss = 1206.2352294921875, steps = 9100, cost time = 4.02s
global_step/sec: 24.0890
loss = 1296.36865234375, steps = 9200, cost time = 4.15s
global_step/sec: 25.3322
loss = 1091.65283203125, steps = 9300, cost time = 3.95s
global_step/sec: 24.9227
loss = 1167.8685302734375, steps = 9400, cost time = 4.01s
global_step/sec: 24.6588
loss = 1276.9775390625, steps = 9500, cost time = 4.06s
global_step/sec: 24.2085
loss = 1257.628173828125, steps = 9600, cost time = 4.13s
global_step/sec: 25.3930
loss = 1296.3592529296875, steps = 9700, cost time = 3.94s
global_step/sec: 26.3092
loss = 1072.6961669921875, steps = 9800, cost time = 3.80s
global_step/sec: 24.4515
loss = 1110.6376953125, steps = 9900, cost time = 4.09s
global_step/sec: 24.0181
loss = 1136.0184326171875, steps = 10000, cost time = 4.16s
global_step/sec: 24.3818
loss = 1433.089111328125, steps = 10100, cost time = 4.10s
global_step/sec: 24.3399
loss = 1123.3111572265625, steps = 10200, cost time = 4.11s
global_step/sec: 25.2893
loss = 1104.2930908203125, steps = 10300, cost time = 3.95s
global_step/sec: 24.3428
loss = 1212.62841796875, steps = 10400, cost time = 4.11s
global_step/sec: 24.6959
loss = 1034.929443359375, steps = 10500, cost time = 4.05s
global_step/sec: 26.2225
loss = 1148.7333984375, steps = 10600, cost time = 3.81s
global_step/sec: 28.6364
loss = 1110.62353515625, steps = 10700, cost time = 3.49s
global_step/sec: 28.1823
loss = 1060.0771484375, steps = 10800, cost time = 3.55s
global_step/sec: 27.1257
loss = 1187.010498046875, steps = 10900, cost time = 3.69s
global_step/sec: 24.2595
loss = 1097.9541015625, steps = 11000, cost time = 4.12s
global_step/sec: 24.5547
loss = 1034.921142578125, steps = 11100, cost time = 4.07s
global_step/sec: 24.2509
loss = 1148.725830078125, steps = 11200, cost time = 4.12s
global_step/sec: 24.8511
loss = 1078.9906005859375, steps = 11300, cost time = 4.02s
global_step/sec: 24.7636
loss = 1148.724609375, steps = 11400, cost time = 4.04s
global_step/sec: 24.5669
loss = 1180.6104736328125, steps = 11500, cost time = 4.07s
global_step/sec: 25.4390
loss = 1193.399658203125, steps = 11600, cost time = 3.93s
global_step/sec: 25.1046
loss = 1116.9521484375, steps = 11700, cost time = 3.98s
global_step/sec: 24.4046
loss = 1167.8387451171875, steps = 11800, cost time = 4.10s
global_step/sec: 24.3425
loss = 1155.08740234375, steps = 11900, cost time = 4.11s
global_step/sec: 24.3003
loss = 1174.2197265625, steps = 12000, cost time = 4.12s
global_step/sec: 25.0883
loss = 1174.218505859375, steps = 12100, cost time = 3.99s
global_step/sec: 24.2865
loss = 1193.39111328125, steps = 12200, cost time = 4.12s
global_step/sec: 51096.2798
loss = 23.061935424804688, steps = 12207, cost time = 0.24s
Evaluation complate:[3/3]
ACC = 0.9325000047683716
AUC = 0.49822551012039185
