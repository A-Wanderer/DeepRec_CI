WARNING:tensorflow:From train.py:15: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

WARNING:tensorflow:From train.py:15: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

WARNING:tensorflow:From train.py:441: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

INFO:tensorflow:Parsing ./data/train.csv
INFO:tensorflow:Parsing ./data/eval.csv
WARNING:tensorflow:From train.py:454: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.

WARNING:tensorflow:From train.py:454: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_types(dataset)`.
WARNING:tensorflow:From train.py:455: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(dataset)`.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:347: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_types(iterator)`.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:348: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(iterator)`.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:350: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_classes(iterator)`.
WARNING:tensorflow:From train.py:242: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From train.py:246: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.

WARNING:tensorflow:From train.py:247: The name tf.feature_column.input_layer is deprecated. Please use tf.compat.v1.feature_column.input_layer instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column.py:206: EmbeddingColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:3182: HashedCategoricalColumn._get_sparse_tensors (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column.py:2158: HashedCategoricalColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:3122: HashedCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column.py:207: EmbeddingColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column.py:206: NumericColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column.py:2158: NumericColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column.py:207: NumericColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column.py:206: IndicatorColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column.py:2158: IndicatorColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4300: IdentityCategoricalColumn._get_sparse_tensors (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column.py:2158: IdentityCategoricalColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4271: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4326: IdentityCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From train.py:86: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From train.py:88: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

WARNING:tensorflow:From train.py:234: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.Dense instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From train.py:279: The name tf.feature_column.linear_model is deprecated. Please use tf.compat.v1.feature_column.linear_model instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column.py:556: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.add_weight` method instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:From train.py:296: The name tf.losses.sigmoid_cross_entropy is deprecated. Please use tf.compat.v1.losses.sigmoid_cross_entropy instead.

WARNING:tensorflow:From train.py:300: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.

WARNING:tensorflow:From train.py:303: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.

WARNING:tensorflow:From train.py:304: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.

WARNING:tensorflow:From train.py:308: The name tf.train.FtrlOptimizer is deprecated. Please use tf.compat.v1.train.FtrlOptimizer instead.

WARNING:tensorflow:From train.py:313: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

WARNING:tensorflow:From train.py:313: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From train.py:215: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.

WARNING:tensorflow:From train.py:218: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From train.py:482: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From train.py:515: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2022-03-31 10:04:42.725141: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2022-03-31 10:04:42.778771: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3400000000 Hz
2022-03-31 10:04:42.811934: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6577be0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-03-31 10:04:42.812102: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From train.py:516: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From train.py:517: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.

WARNING:tensorflow:From train.py:518: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

WARNING:tensorflow:From train.py:519: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From train.py:520: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From train.py:520: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From train.py:522: The name tf.RunOptions is deprecated. Please use tf.compat.v1.RunOptions instead.

WARNING:tensorflow:From train.py:523: The name tf.RunMetadata is deprecated. Please use tf.compat.v1.RunMetadata instead.

Using TensorFlow version 1.15.5
Checking dataset
Numbers of training dataset is 8000000
Numbers of test dataset is 2000000
Saving model checkpoints to /benchmark_result/checkpoint/2022-03-31-14-47-37/wdl_tf_fp32
****Computing statistics of train dataset*****
global_step/sec: 27.1096
loss = 0.6846864223480225, steps = 0, cost time = 3.69s
global_step/sec: 37.1155
loss = 0.48446157574653625, steps = 100, cost time = 2.69s
global_step/sec: 42.9706
loss = 0.45924150943756104, steps = 200, cost time = 2.33s
global_step/sec: 39.7767
loss = 0.5282816290855408, steps = 300, cost time = 2.51s
global_step/sec: 45.0495
loss = 0.50276780128479, steps = 400, cost time = 2.22s
global_step/sec: 45.7872
loss = 0.4990781247615814, steps = 500, cost time = 2.18s
global_step/sec: 39.5912
loss = 0.5533353090286255, steps = 600, cost time = 2.53s
global_step/sec: 38.7731
loss = 0.54237300157547, steps = 700, cost time = 2.58s
global_step/sec: 44.6653
loss = 0.5275354385375977, steps = 800, cost time = 2.24s
global_step/sec: 42.5002
loss = 0.487455815076828, steps = 900, cost time = 2.35s
global_step/sec: 36.8765
loss = 0.5195817947387695, steps = 1000, cost time = 2.71s
global_step/sec: 34.5735
loss = 0.5286506414413452, steps = 1100, cost time = 2.89s
global_step/sec: 38.8870
loss = 0.4855180084705353, steps = 1200, cost time = 2.57s
global_step/sec: 35.4861
loss = 0.48025578260421753, steps = 1300, cost time = 2.82s
global_step/sec: 32.2842
loss = 0.5006744861602783, steps = 1400, cost time = 3.10s
global_step/sec: 41.8104
loss = 0.4681394100189209, steps = 1500, cost time = 2.39s
global_step/sec: 42.5878
loss = 0.4729427099227905, steps = 1600, cost time = 2.35s
global_step/sec: 40.5561
loss = 0.5001420974731445, steps = 1700, cost time = 2.47s
global_step/sec: 38.4188
loss = 0.4851970970630646, steps = 1800, cost time = 2.60s
global_step/sec: 41.2486
loss = 0.47268927097320557, steps = 1900, cost time = 2.42s
global_step/sec: 43.8197
loss = 0.4660954177379608, steps = 2000, cost time = 2.28s
global_step/sec: 39.1972
loss = 0.46166616678237915, steps = 2100, cost time = 2.55s
global_step/sec: 39.3594
loss = 0.5091059803962708, steps = 2200, cost time = 2.54s
global_step/sec: 41.0304
loss = 0.4826541543006897, steps = 2300, cost time = 2.44s
global_step/sec: 38.0616
loss = 0.5058834552764893, steps = 2400, cost time = 2.63s
global_step/sec: 40.7447
loss = 0.45186084508895874, steps = 2500, cost time = 2.45s
global_step/sec: 39.1982
loss = 0.49585801362991333, steps = 2600, cost time = 2.55s
global_step/sec: 29.6925
loss = 0.5280972123146057, steps = 2700, cost time = 3.37s
global_step/sec: 30.9718
loss = 0.5073890686035156, steps = 2800, cost time = 3.23s
global_step/sec: 34.6472
loss = 0.505607008934021, steps = 2900, cost time = 2.89s
global_step/sec: 41.2013
loss = 0.5101412534713745, steps = 3000, cost time = 2.43s
global_step/sec: 37.7005
loss = 0.518805205821991, steps = 3100, cost time = 2.65s
global_step/sec: 34.9780
loss = 0.48987987637519836, steps = 3200, cost time = 2.86s
global_step/sec: 47.3706
loss = 0.4842692017555237, steps = 3300, cost time = 2.11s
global_step/sec: 32.7710
loss = 0.4873419404029846, steps = 3400, cost time = 3.05s
global_step/sec: 34.2062
loss = 0.48574697971343994, steps = 3500, cost time = 2.92s
global_step/sec: 35.8267
loss = 0.45698392391204834, steps = 3600, cost time = 2.79s
global_step/sec: 34.1890
loss = 0.474664568901062, steps = 3700, cost time = 2.92s
global_step/sec: 36.2576
loss = 0.49532437324523926, steps = 3800, cost time = 2.76s
global_step/sec: 35.3967
loss = 0.496696799993515, steps = 3900, cost time = 2.83s
global_step/sec: 30.5028
loss = 0.529786229133606, steps = 4000, cost time = 3.28s
global_step/sec: 30.9874
loss = 0.4903060793876648, steps = 4100, cost time = 3.23s
global_step/sec: 30.8679
loss = 0.4559062123298645, steps = 4200, cost time = 3.24s
global_step/sec: 31.4429
loss = 0.5146815776824951, steps = 4300, cost time = 3.18s
global_step/sec: 40.9968
loss = 0.47551268339157104, steps = 4400, cost time = 2.44s
global_step/sec: 34.8548
loss = 0.4938310980796814, steps = 4500, cost time = 2.87s
global_step/sec: 34.1320
loss = 0.4897271990776062, steps = 4600, cost time = 2.93s
global_step/sec: 35.7957
loss = 0.4468362331390381, steps = 4700, cost time = 2.79s
global_step/sec: 31.9203
loss = 0.48439717292785645, steps = 4800, cost time = 3.13s
global_step/sec: 35.5443
loss = 0.46322113275527954, steps = 4900, cost time = 2.81s
global_step/sec: 39.4499
loss = 0.48741984367370605, steps = 5000, cost time = 2.53s
global_step/sec: 36.9620
loss = 0.471027135848999, steps = 5100, cost time = 2.71s
global_step/sec: 36.4825
loss = 0.4979868531227112, steps = 5200, cost time = 2.74s
global_step/sec: 31.9897
loss = 0.45847612619400024, steps = 5300, cost time = 3.13s
global_step/sec: 35.2120
loss = 0.50861656665802, steps = 5400, cost time = 2.84s
global_step/sec: 33.0712
loss = 0.502820611000061, steps = 5500, cost time = 3.02s
global_step/sec: 32.2004
loss = 0.46703052520751953, steps = 5600, cost time = 3.11s
global_step/sec: 31.0338
loss = 0.5047163963317871, steps = 5700, cost time = 3.22s
global_step/sec: 33.6788
loss = 0.4941776394844055, steps = 5800, cost time = 2.97s
global_step/sec: 40.9482
loss = 0.5015456676483154, steps = 5900, cost time = 2.44s
global_step/sec: 37.2579
loss = 0.4795987606048584, steps = 6000, cost time = 2.68s
global_step/sec: 34.2734
loss = 0.5264493227005005, steps = 6100, cost time = 2.92s
global_step/sec: 38.6805
loss = 0.4907582104206085, steps = 6200, cost time = 2.59s
global_step/sec: 33.7621
loss = 0.5101611614227295, steps = 6300, cost time = 2.96s
global_step/sec: 36.3644
loss = 0.5209499597549438, steps = 6400, cost time = 2.75s
global_step/sec: 31.5343
loss = 0.46071767807006836, steps = 6500, cost time = 3.17s
global_step/sec: 31.2681
loss = 0.48103660345077515, steps = 6600, cost time = 3.20s
global_step/sec: 30.5467
loss = 0.493674635887146, steps = 6700, cost time = 3.27s
global_step/sec: 31.0664
loss = 0.47664666175842285, steps = 6800, cost time = 3.22s
global_step/sec: 34.6186
loss = 0.44583219289779663, steps = 6900, cost time = 2.89s
global_step/sec: 36.9517
loss = 0.5222843289375305, steps = 7000, cost time = 2.71s
global_step/sec: 31.0530
loss = 0.5376043319702148, steps = 7100, cost time = 3.22s
global_step/sec: 32.9066
loss = 0.47764134407043457, steps = 7200, cost time = 3.04s
global_step/sec: 37.9620
loss = 0.48564866185188293, steps = 7300, cost time = 2.63s
global_step/sec: 43.1665
loss = 0.5044150352478027, steps = 7400, cost time = 2.32s
global_step/sec: 45.8911
loss = 0.4627308249473572, steps = 7500, cost time = 2.18s
global_step/sec: 35.4434
loss = 0.49664750695228577, steps = 7600, cost time = 2.82s
global_step/sec: 36.6195
loss = 0.42507094144821167, steps = 7700, cost time = 2.73s
global_step/sec: 28.5515
loss = 0.42876535654067993, steps = 7800, cost time = 3.50s
global_step/sec: 36.1080
loss = 0.4717674255371094, steps = 7900, cost time = 2.77s
global_step/sec: 39.0712
loss = 0.44266176223754883, steps = 8000, cost time = 2.56s
global_step/sec: 31.3116
loss = 0.47030043601989746, steps = 8100, cost time = 3.19s
global_step/sec: 31.6407
loss = 0.49270379543304443, steps = 8200, cost time = 3.16s
global_step/sec: 37.7829
loss = 0.4516565203666687, steps = 8300, cost time = 2.65s
global_step/sec: 31.4267
loss = 0.455518901348114, steps = 8400, cost time = 3.18s
global_step/sec: 36.1581
loss = 0.4843316078186035, steps = 8500, cost time = 2.77s
global_step/sec: 37.6458
loss = 0.46436822414398193, steps = 8600, cost time = 2.66s
global_step/sec: 37.7179
loss = 0.4734497666358948, steps = 8700, cost time = 2.65s
global_step/sec: 31.4049
loss = 0.48246872425079346, steps = 8800, cost time = 3.18s
global_step/sec: 32.9182
loss = 0.487224817276001, steps = 8900, cost time = 3.04s
global_step/sec: 33.7181
loss = 0.4862390160560608, steps = 9000, cost time = 2.97s
global_step/sec: 37.9053
loss = 0.5022604465484619, steps = 9100, cost time = 2.64s
global_step/sec: 35.4535
loss = 0.4833209812641144, steps = 9200, cost time = 2.82s
global_step/sec: 34.2048
loss = 0.49589118361473083, steps = 9300, cost time = 2.92s
global_step/sec: 32.0303
loss = 0.49835094809532166, steps = 9400, cost time = 3.12s
global_step/sec: 35.3663
loss = 0.44708311557769775, steps = 9500, cost time = 2.83s
global_step/sec: 32.1202
loss = 0.4809589982032776, steps = 9600, cost time = 3.11s
global_step/sec: 36.7020
loss = 0.4888986051082611, steps = 9700, cost time = 2.72s
global_step/sec: 29.5401
loss = 0.5067716836929321, steps = 9800, cost time = 3.39s
global_step/sec: 29.0668
loss = 0.45653823018074036, steps = 9900, cost time = 3.44s
global_step/sec: 29.7704
loss = 0.4522859454154968, steps = 10000, cost time = 3.36s
global_step/sec: 32.9765
loss = 0.48602965474128723, steps = 10100, cost time = 3.03s
global_step/sec: 30.0379
loss = 0.477497935295105, steps = 10200, cost time = 3.33s
global_step/sec: 31.3891
loss = 0.46380555629730225, steps = 10300, cost time = 3.19s
global_step/sec: 38.4041
loss = 0.46861928701400757, steps = 10400, cost time = 2.60s
global_step/sec: 41.9192
loss = 0.505033552646637, steps = 10500, cost time = 2.39s
global_step/sec: 32.2313
loss = 0.46217024326324463, steps = 10600, cost time = 3.10s
global_step/sec: 33.4125
loss = 0.4932149052619934, steps = 10700, cost time = 2.99s
global_step/sec: 31.0860
loss = 0.47739118337631226, steps = 10800, cost time = 3.22s
global_step/sec: 31.3055
loss = 0.43516257405281067, steps = 10900, cost time = 3.19s
global_step/sec: 32.6151
loss = 0.4845620393753052, steps = 11000, cost time = 3.07s
global_step/sec: 35.2478
loss = 0.49099063873291016, steps = 11100, cost time = 2.84s
global_step/sec: 34.9028
loss = 0.44039273262023926, steps = 11200, cost time = 2.87s
global_step/sec: 34.7057
loss = 0.46263426542282104, steps = 11300, cost time = 2.88s
global_step/sec: 32.4729
loss = 0.46923017501831055, steps = 11400, cost time = 3.08s
global_step/sec: 31.3672
loss = 0.46828126907348633, steps = 11500, cost time = 3.19s
global_step/sec: 29.1432
loss = 0.4629380702972412, steps = 11600, cost time = 3.43s
global_step/sec: 30.6464
loss = 0.485054612159729, steps = 11700, cost time = 3.26s
global_step/sec: 35.9134
loss = 0.4761902093887329, steps = 11800, cost time = 2.78s
global_step/sec: 35.6035
loss = 0.5047367811203003, steps = 11900, cost time = 2.81s
global_step/sec: 34.4533
loss = 0.46917662024497986, steps = 12000, cost time = 2.90s
global_step/sec: 35.5353
loss = 0.4809531271457672, steps = 12100, cost time = 2.81s
global_step/sec: 33.5317
loss = 0.4342343807220459, steps = 12200, cost time = 2.98s
global_step/sec: 31.6124
loss = 0.486828088760376, steps = 12300, cost time = 3.16s
global_step/sec: 33.0714
loss = 0.4937077462673187, steps = 12400, cost time = 3.02s
global_step/sec: 29.6966
loss = 0.46066057682037354, steps = 12500, cost time = 3.37s
global_step/sec: 31.7205
loss = 0.43287479877471924, steps = 12600, cost time = 3.15s
global_step/sec: 30.3270
loss = 0.4450024366378784, steps = 12700, cost time = 3.30s
global_step/sec: 34.2346
loss = 0.5005613565444946, steps = 12800, cost time = 2.92s
global_step/sec: 30.6879
loss = 0.5098113417625427, steps = 12900, cost time = 3.26s
global_step/sec: 33.7704
loss = 0.5126820802688599, steps = 13000, cost time = 2.96s
global_step/sec: 34.6455
loss = 0.5185667276382446, steps = 13100, cost time = 2.89s
global_step/sec: 33.4383
loss = 0.5034056901931763, steps = 13200, cost time = 2.99s
global_step/sec: 36.7999
loss = 0.47966963052749634, steps = 13300, cost time = 2.72s
global_step/sec: 33.4737
loss = 0.49485525488853455, steps = 13400, cost time = 2.99s
global_step/sec: 35.4041
loss = 0.5012930035591125, steps = 13500, cost time = 2.82s
global_step/sec: 33.7872
loss = 0.5195298194885254, steps = 13600, cost time = 2.96s
global_step/sec: 34.5631
loss = 0.4876350164413452, steps = 13700, cost time = 2.89s
global_step/sec: 32.4246
loss = 0.4831025004386902, steps = 13800, cost time = 3.08s
global_step/sec: 37.1655
loss = 0.46937304735183716, steps = 13900, cost time = 2.69s
global_step/sec: 38.5834
loss = 0.5151805877685547, steps = 14000, cost time = 2.59s
global_step/sec: 36.9794
loss = 0.5028750896453857, steps = 14100, cost time = 2.70s
global_step/sec: 29.3762
loss = 0.4984491467475891, steps = 14200, cost time = 3.40s
global_step/sec: 28.9068
loss = 0.46034353971481323, steps = 14300, cost time = 3.46s
global_step/sec: 28.3444
loss = 0.46812528371810913, steps = 14400, cost time = 3.53s
global_step/sec: 29.6294
loss = 0.47848230600357056, steps = 14500, cost time = 3.38s
global_step/sec: 34.2769
loss = 0.4984009861946106, steps = 14600, cost time = 2.92s
global_step/sec: 34.5709
loss = 0.46526074409484863, steps = 14700, cost time = 2.89s
global_step/sec: 39.1043
loss = 0.49763643741607666, steps = 14800, cost time = 2.56s
global_step/sec: 34.3541
loss = 0.4719895124435425, steps = 14900, cost time = 2.91s
global_step/sec: 34.9189
loss = 0.4965722858905792, steps = 15000, cost time = 2.86s
global_step/sec: 33.8516
loss = 0.4511237144470215, steps = 15100, cost time = 2.95s
global_step/sec: 34.8438
loss = 0.49503597617149353, steps = 15200, cost time = 2.87s
global_step/sec: 36.9100
loss = 0.49956923723220825, steps = 15300, cost time = 2.71s
global_step/sec: 29.7146
loss = 0.4708278179168701, steps = 15400, cost time = 3.37s
global_step/sec: 29.9348
loss = 0.508084774017334, steps = 15500, cost time = 3.34s
global_step/sec: 38.0220
loss = 0.4294969439506531, steps = 15600, cost time = 2.63s
global_step/sec: 31.3323
loss = 0.4201366603374481, steps = 15700, cost time = 3.19s
global_step/sec: 37.9812
loss = 0.4458816349506378, steps = 15800, cost time = 2.63s
global_step/sec: 30.9797
loss = 0.5057682991027832, steps = 15900, cost time = 3.23s
global_step/sec: 28.8816
loss = 0.48982250690460205, steps = 16000, cost time = 3.46s
global_step/sec: 29.5255
loss = 0.5136187076568604, steps = 16100, cost time = 3.39s
global_step/sec: 29.8019
loss = 0.5050545930862427, steps = 16200, cost time = 3.36s
global_step/sec: 31.5771
loss = 0.47850990295410156, steps = 16300, cost time = 3.17s
global_step/sec: 33.9482
loss = 0.5039443373680115, steps = 16400, cost time = 2.95s
global_step/sec: 30.0045
loss = 0.5069548487663269, steps = 16500, cost time = 3.33s
global_step/sec: 35.9788
loss = 0.47024840116500854, steps = 16600, cost time = 2.78s
global_step/sec: 34.0104
loss = 0.5127849578857422, steps = 16700, cost time = 2.94s
global_step/sec: 34.7068
loss = 0.48548221588134766, steps = 16800, cost time = 2.88s
global_step/sec: 31.7242
loss = 0.4497531056404114, steps = 16900, cost time = 3.15s
global_step/sec: 32.5661
loss = 0.48082053661346436, steps = 17000, cost time = 3.07s
global_step/sec: 34.0985
loss = 0.4800204634666443, steps = 17100, cost time = 2.93s
global_step/sec: 34.1539
loss = 0.4457569718360901, steps = 17200, cost time = 2.93s
global_step/sec: 31.1363
loss = 0.49693945050239563, steps = 17300, cost time = 3.21s
global_step/sec: 30.0522
loss = 0.45839184522628784, steps = 17400, cost time = 3.33s
global_step/sec: 38.2593
loss = 0.47392383217811584, steps = 17500, cost time = 2.61s
global_step/sec: 35.6766
loss = 0.4843014180660248, steps = 17600, cost time = 2.80s
global_step/sec: 33.1568
loss = 0.5109196901321411, steps = 17700, cost time = 3.02s
global_step/sec: 35.7507
loss = 0.48146116733551025, steps = 17800, cost time = 2.80s
global_step/sec: 35.1762
loss = 0.49124178290367126, steps = 17900, cost time = 2.84s
global_step/sec: 29.9965
loss = 0.4581471085548401, steps = 18000, cost time = 3.33s
global_step/sec: 28.9644
loss = 0.4675642251968384, steps = 18100, cost time = 3.45s
global_step/sec: 34.7929
loss = 0.509121298789978, steps = 18200, cost time = 2.87s
global_step/sec: 32.1362
loss = 0.4780336618423462, steps = 18300, cost time = 3.11s
global_step/sec: 34.0281
loss = 0.46480023860931396, steps = 18400, cost time = 2.94s
global_step/sec: 37.6025
loss = 0.4849430322647095, steps = 18500, cost time = 2.66s
global_step/sec: 36.8610
loss = 0.5123316049575806, steps = 18600, cost time = 2.71s
global_step/sec: 30.0202
loss = 0.5028578042984009, steps = 18700, cost time = 3.33s
global_step/sec: 36.2610
loss = 0.4810411334037781, steps = 18800, cost time = 2.76s
global_step/sec: 30.4292
loss = 0.4873219430446625, steps = 18900, cost time = 3.29s
global_step/sec: 35.7431
loss = 0.4880788028240204, steps = 19000, cost time = 2.80s
global_step/sec: 36.1681
loss = 0.45971012115478516, steps = 19100, cost time = 2.76s
global_step/sec: 37.6700
loss = 0.4518091082572937, steps = 19200, cost time = 2.65s
global_step/sec: 33.2669
loss = 0.4841291904449463, steps = 19300, cost time = 3.01s
global_step/sec: 35.5813
loss = 0.45721369981765747, steps = 19400, cost time = 2.81s
global_step/sec: 31.0040
loss = 0.48817792534828186, steps = 19500, cost time = 3.23s
global_step/sec: 29.5289
loss = 0.5116502046585083, steps = 19600, cost time = 3.39s
global_step/sec: 31.8172
loss = 0.46406984329223633, steps = 19700, cost time = 3.14s
global_step/sec: 32.7289
loss = 0.4430392384529114, steps = 19800, cost time = 3.06s
global_step/sec: 30.1660
loss = 0.4346768260002136, steps = 19900, cost time = 3.31s
global_step/sec: 32.6362
loss = 0.46977049112319946, steps = 20000, cost time = 3.06s
global_step/sec: 29.3023
loss = 0.46579509973526, steps = 20100, cost time = 3.41s
global_step/sec: 30.8717
loss = 0.5173453688621521, steps = 20200, cost time = 3.24s
global_step/sec: 30.6919
loss = 0.466761976480484, steps = 20300, cost time = 3.26s
global_step/sec: 37.9853
loss = 0.48786765336990356, steps = 20400, cost time = 2.63s
global_step/sec: 32.5558
loss = 0.49213075637817383, steps = 20500, cost time = 3.07s
global_step/sec: 33.8223
loss = 0.45905181765556335, steps = 20600, cost time = 2.96s
global_step/sec: 30.5593
loss = 0.4768068194389343, steps = 20700, cost time = 3.27s
global_step/sec: 29.3140
loss = 0.4881983697414398, steps = 20800, cost time = 3.41s
global_step/sec: 31.8406
loss = 0.5115483403205872, steps = 20900, cost time = 3.14s
global_step/sec: 30.6613
loss = 0.5116106271743774, steps = 21000, cost time = 3.26s
global_step/sec: 31.5854
loss = 0.45014119148254395, steps = 21100, cost time = 3.17s
global_step/sec: 32.9260
loss = 0.48482251167297363, steps = 21200, cost time = 3.04s
global_step/sec: 33.2596
loss = 0.45837029814720154, steps = 21300, cost time = 3.01s
global_step/sec: 32.3438
loss = 0.4295334815979004, steps = 21400, cost time = 3.09s
global_step/sec: 30.2862
loss = 0.4727296233177185, steps = 21500, cost time = 3.30s
global_step/sec: 35.5231
loss = 0.493225634098053, steps = 21600, cost time = 2.82s
global_step/sec: 31.4849
loss = 0.4994698166847229, steps = 21700, cost time = 3.18s
global_step/sec: 30.1272
loss = 0.47515949606895447, steps = 21800, cost time = 3.32s
global_step/sec: 31.7429
loss = 0.4632031321525574, steps = 21900, cost time = 3.15s
global_step/sec: 29.0510
loss = 0.5013631582260132, steps = 22000, cost time = 3.44s
global_step/sec: 28.9008
loss = 0.4909802973270416, steps = 22100, cost time = 3.46s
global_step/sec: 29.1152
loss = 0.4838881492614746, steps = 22200, cost time = 3.43s
global_step/sec: 36.2653
loss = 0.45359671115875244, steps = 22300, cost time = 2.76s
global_step/sec: 39.1537
loss = 0.5082870721817017, steps = 22400, cost time = 2.55s
global_step/sec: 40.2296
loss = 0.4428761303424835, steps = 22500, cost time = 2.49s
global_step/sec: 36.0127
loss = 0.48814043402671814, steps = 22600, cost time = 2.78s
global_step/sec: 30.5916
loss = 0.44789543747901917, steps = 22700, cost time = 3.27s
global_step/sec: 36.3626
loss = 0.42714956402778625, steps = 22800, cost time = 2.75s
global_step/sec: 34.2160
loss = 0.480256050825119, steps = 22900, cost time = 2.92s
global_step/sec: 34.6253
loss = 0.48638176918029785, steps = 23000, cost time = 2.89s
global_step/sec: 35.6972
loss = 0.5015232563018799, steps = 23100, cost time = 2.80s
global_step/sec: 35.6487
loss = 0.48194941878318787, steps = 23200, cost time = 2.81s
global_step/sec: 35.5244
loss = 0.47899001836776733, steps = 23300, cost time = 2.81s
global_step/sec: 35.7330
loss = 0.47460493445396423, steps = 23400, cost time = 2.80s
global_step/sec: 31.9647
loss = 0.452783465385437, steps = 23500, cost time = 3.13s
global_step/sec: 39.0199
loss = 0.49062028527259827, steps = 23600, cost time = 2.56s
global_step/sec: 36.0653
loss = 0.46066027879714966, steps = 23700, cost time = 2.77s
global_step/sec: 33.2934
loss = 0.4640321731567383, steps = 23800, cost time = 3.00s
global_step/sec: 31.5340
loss = 0.43403297662734985, steps = 23900, cost time = 3.17s
global_step/sec: 34.3456
loss = 0.44436514377593994, steps = 24000, cost time = 2.91s
global_step/sec: 31.3129
loss = 0.4410284757614136, steps = 24100, cost time = 3.19s
global_step/sec: 30.7900
loss = 0.43548884987831116, steps = 24200, cost time = 3.25s
global_step/sec: 32.5697
loss = 0.5087944269180298, steps = 24300, cost time = 3.07s
global_step/sec: 30.7216
loss = 0.48053598403930664, steps = 24400, cost time = 3.26s
global_step/sec: 30.4482
loss = 0.46983855962753296, steps = 24500, cost time = 3.28s
global_step/sec: 27.7831
loss = 0.47678858041763306, steps = 24600, cost time = 3.60s
global_step/sec: 29.8582
loss = 0.4299201965332031, steps = 24700, cost time = 3.35s
global_step/sec: 34.3310
loss = 0.49081307649612427, steps = 24800, cost time = 2.91s
global_step/sec: 33.4238
loss = 0.45651403069496155, steps = 24900, cost time = 2.99s
global_step/sec: 39.0570
loss = 0.4883698523044586, steps = 25000, cost time = 2.56s
global_step/sec: 34.2460
loss = 0.4677383601665497, steps = 25100, cost time = 2.92s
global_step/sec: 31.7762
loss = 0.47361817955970764, steps = 25200, cost time = 3.15s
global_step/sec: 33.6942
loss = 0.4471743404865265, steps = 25300, cost time = 2.97s
global_step/sec: 34.0748
loss = 0.43728241324424744, steps = 25400, cost time = 2.93s
global_step/sec: 30.8561
loss = 0.48726946115493774, steps = 25500, cost time = 3.24s
global_step/sec: 29.9687
loss = 0.48687586188316345, steps = 25600, cost time = 3.34s
global_step/sec: 29.9857
loss = 0.44231393933296204, steps = 25700, cost time = 3.33s
global_step/sec: 36.4843
loss = 0.4439130127429962, steps = 25800, cost time = 2.74s
global_step/sec: 34.3780
loss = 0.49308013916015625, steps = 25900, cost time = 2.91s
global_step/sec: 28.9019
loss = 0.48333680629730225, steps = 26000, cost time = 3.46s
global_step/sec: 35.6251
loss = 0.44836026430130005, steps = 26100, cost time = 2.81s
global_step/sec: 31.2027
loss = 0.4358718991279602, steps = 26200, cost time = 3.20s
global_step/sec: 29.6385
loss = 0.46003592014312744, steps = 26300, cost time = 3.37s
global_step/sec: 31.7068
loss = 0.45692259073257446, steps = 26400, cost time = 3.15s
global_step/sec: 34.3225
loss = 0.47352421283721924, steps = 26500, cost time = 2.91s
global_step/sec: 33.1581
loss = 0.47311684489250183, steps = 26600, cost time = 3.02s
global_step/sec: 31.5648
loss = 0.43992704153060913, steps = 26700, cost time = 3.17s
global_step/sec: 30.8198
loss = 0.4800640344619751, steps = 26800, cost time = 3.24s
global_step/sec: 29.8453
loss = 0.47065919637680054, steps = 26900, cost time = 3.35s
global_step/sec: 31.2374
loss = 0.4861462712287903, steps = 27000, cost time = 3.20s
global_step/sec: 33.2691
loss = 0.47409987449645996, steps = 27100, cost time = 3.01s
global_step/sec: 32.5079
loss = 0.4712938666343689, steps = 27200, cost time = 3.08s
global_step/sec: 30.1129
loss = 0.4827357828617096, steps = 27300, cost time = 3.32s
global_step/sec: 30.8498
loss = 0.44708728790283203, steps = 27400, cost time = 3.24s
global_step/sec: 33.8743
loss = 0.45469632744789124, steps = 27500, cost time = 2.95s
global_step/sec: 38.6744
loss = 0.42982757091522217, steps = 27600, cost time = 2.59s
global_step/sec: 36.2205
loss = 0.5040619969367981, steps = 27700, cost time = 2.76s
global_step/sec: 37.1436
loss = 0.4517999291419983, steps = 27800, cost time = 2.69s
global_step/sec: 31.6315
loss = 0.4795917272567749, steps = 27900, cost time = 3.16s
global_step/sec: 32.7935
loss = 0.5282042622566223, steps = 28000, cost time = 3.05s
global_step/sec: 30.7255
loss = 0.4791375994682312, steps = 28100, cost time = 3.25s
global_step/sec: 33.9629
loss = 0.45101267099380493, steps = 28200, cost time = 2.94s
global_step/sec: 33.2458
loss = 0.4475482106208801, steps = 28300, cost time = 3.01s
global_step/sec: 33.5667
loss = 0.44975945353507996, steps = 28400, cost time = 2.98s
global_step/sec: 30.5684
loss = 0.48134845495224, steps = 28500, cost time = 3.27s
global_step/sec: 29.6910
loss = 0.5396209359169006, steps = 28600, cost time = 3.37s
global_step/sec: 32.0076
loss = 0.5384982824325562, steps = 28700, cost time = 3.12s
global_step/sec: 31.9404
loss = 0.4746885895729065, steps = 28800, cost time = 3.13s
global_step/sec: 36.9388
loss = 0.5366542339324951, steps = 28900, cost time = 2.71s
global_step/sec: 33.6027
loss = 0.49272069334983826, steps = 29000, cost time = 2.98s
global_step/sec: 31.4693
loss = 0.5034734606742859, steps = 29100, cost time = 3.18s
global_step/sec: 29.3693
loss = 0.49784019589424133, steps = 29200, cost time = 3.40s
global_step/sec: 30.6743
loss = 0.4627290368080139, steps = 29300, cost time = 3.26s
global_step/sec: 33.5485
loss = 0.48009613156318665, steps = 29400, cost time = 2.98s
global_step/sec: 33.8433
loss = 0.5103417038917542, steps = 29500, cost time = 2.95s
global_step/sec: 33.4034
loss = 0.5064934492111206, steps = 29600, cost time = 2.99s
global_step/sec: 36.1915
loss = 0.5045945048332214, steps = 29700, cost time = 2.76s
global_step/sec: 30.0978
loss = 0.4550679922103882, steps = 29800, cost time = 3.32s
global_step/sec: 29.2920
loss = 0.46965667605400085, steps = 29900, cost time = 3.41s
global_step/sec: 28.8479
loss = 0.46959465742111206, steps = 30000, cost time = 3.47s
global_step/sec: 33.3457
loss = 0.4589312672615051, steps = 30100, cost time = 3.00s
global_step/sec: 33.7039
loss = 0.4800148606300354, steps = 30200, cost time = 2.97s
global_step/sec: 40.9091
loss = 0.4893031418323517, steps = 30300, cost time = 2.44s
global_step/sec: 39.2668
loss = 0.48342975974082947, steps = 30400, cost time = 2.55s
global_step/sec: 35.3248
loss = 0.48493218421936035, steps = 30500, cost time = 2.83s
global_step/sec: 36.5064
loss = 0.5040380954742432, steps = 30600, cost time = 2.74s
global_step/sec: 36.7449
loss = 0.4174506664276123, steps = 30700, cost time = 2.72s
global_step/sec: 35.8082
loss = 0.4788556694984436, steps = 30800, cost time = 2.79s
global_step/sec: 36.5998
loss = 0.43023157119750977, steps = 30900, cost time = 2.73s
global_step/sec: 37.4357
loss = 0.4578642249107361, steps = 31000, cost time = 2.67s
global_step/sec: 33.6661
loss = 0.49308285117149353, steps = 31100, cost time = 2.97s
global_step/sec: 31.9476
loss = 0.4708450138568878, steps = 31200, cost time = 3.13s
global_step/sec: 34.8734
loss = 0.43259233236312866, steps = 31300, cost time = 2.87s
global_step/sec: 32.0676
loss = 0.4818073511123657, steps = 31400, cost time = 3.12s
global_step/sec: 35.6024
loss = 0.4734824299812317, steps = 31500, cost time = 2.81s
global_step/sec: 39.0514
loss = 0.4703160524368286, steps = 31600, cost time = 2.56s
global_step/sec: 34.1204
loss = 0.5090786218643188, steps = 31700, cost time = 2.93s
global_step/sec: 29.1264
loss = 0.4920883774757385, steps = 31800, cost time = 3.43s
global_step/sec: 38.5744
loss = 0.5112034678459167, steps = 31900, cost time = 2.59s
global_step/sec: 29.7045
loss = 0.45245856046676636, steps = 32000, cost time = 3.37s
global_step/sec: 36.0044
loss = 0.481964647769928, steps = 32100, cost time = 2.78s
global_step/sec: 34.2257
loss = 0.47927209734916687, steps = 32200, cost time = 2.92s
global_step/sec: 29.8667
loss = 0.45673754811286926, steps = 32300, cost time = 3.35s
global_step/sec: 29.1714
loss = 0.4781538248062134, steps = 32400, cost time = 3.43s
global_step/sec: 31.8246
loss = 0.47026193141937256, steps = 32500, cost time = 3.14s
global_step/sec: 32.6609
loss = 0.5040522813796997, steps = 32600, cost time = 3.06s
global_step/sec: 31.3797
loss = 0.49759548902511597, steps = 32700, cost time = 3.19s
global_step/sec: 34.1068
loss = 0.45496463775634766, steps = 32800, cost time = 2.93s
global_step/sec: 33.4609
loss = 0.4983551800251007, steps = 32900, cost time = 2.99s
global_step/sec: 30.6212
loss = 0.4621049165725708, steps = 33000, cost time = 3.27s
global_step/sec: 32.0472
loss = 0.4518481194972992, steps = 33100, cost time = 3.12s
global_step/sec: 29.8337
loss = 0.4411400556564331, steps = 33200, cost time = 3.35s
global_step/sec: 35.5493
loss = 0.4549012780189514, steps = 33300, cost time = 2.81s
global_step/sec: 36.1690
loss = 0.5095906257629395, steps = 33400, cost time = 2.76s
global_step/sec: 33.6189
loss = 0.4682914614677429, steps = 33500, cost time = 2.97s
global_step/sec: 31.5257
loss = 0.4593350887298584, steps = 33600, cost time = 3.17s
global_step/sec: 30.4080
loss = 0.44742727279663086, steps = 33700, cost time = 3.29s
global_step/sec: 31.3415
loss = 0.47043368220329285, steps = 33800, cost time = 3.19s
global_step/sec: 29.7846
loss = 0.4685898423194885, steps = 33900, cost time = 3.36s
global_step/sec: 31.1384
loss = 0.5081814527511597, steps = 34000, cost time = 3.21s
global_step/sec: 29.9905
loss = 0.435763418674469, steps = 34100, cost time = 3.33s
global_step/sec: 32.1804
loss = 0.48910391330718994, steps = 34200, cost time = 3.11s
global_step/sec: 31.0978
loss = 0.42732954025268555, steps = 34300, cost time = 3.22s
global_step/sec: 37.3224
loss = 0.48039060831069946, steps = 34400, cost time = 2.68s
global_step/sec: 35.1925
loss = 0.45962563157081604, steps = 34500, cost time = 2.84s
global_step/sec: 32.8951
loss = 0.45889812707901, steps = 34600, cost time = 3.04s
global_step/sec: 38.0380
loss = 0.4610402584075928, steps = 34700, cost time = 2.63s
global_step/sec: 35.4991
loss = 0.4958827495574951, steps = 34800, cost time = 2.82s
global_step/sec: 37.5186
loss = 0.4743334650993347, steps = 34900, cost time = 2.67s
global_step/sec: 35.0550
loss = 0.4768570363521576, steps = 35000, cost time = 2.85s
global_step/sec: 32.8785
loss = 0.48653048276901245, steps = 35100, cost time = 3.04s
global_step/sec: 31.8770
loss = 0.457520067691803, steps = 35200, cost time = 3.14s
global_step/sec: 32.4530
loss = 0.45615723729133606, steps = 35300, cost time = 3.08s
global_step/sec: 31.4675
loss = 0.4487834572792053, steps = 35400, cost time = 3.18s
global_step/sec: 36.3964
loss = 0.4395645260810852, steps = 35500, cost time = 2.75s
global_step/sec: 34.7344
loss = 0.5101442337036133, steps = 35600, cost time = 2.88s
global_step/sec: 33.4024
loss = 0.4773973822593689, steps = 35700, cost time = 2.99s
global_step/sec: 31.7456
loss = 0.4769008755683899, steps = 35800, cost time = 3.15s
global_step/sec: 32.4248
loss = 0.48459964990615845, steps = 35900, cost time = 3.08s
global_step/sec: 32.8062
loss = 0.47109952569007874, steps = 36000, cost time = 3.05s
global_step/sec: 32.3028
loss = 0.4680292010307312, steps = 36100, cost time = 3.10s
global_step/sec: 33.2969
loss = 0.481176495552063, steps = 36200, cost time = 3.00s
global_step/sec: 33.4109
loss = 0.48599642515182495, steps = 36300, cost time = 2.99s
global_step/sec: 32.6671
loss = 0.45393964648246765, steps = 36400, cost time = 3.06s
global_step/sec: 34.7347
loss = 0.5006653666496277, steps = 36500, cost time = 2.88s
global_step/sec: 30.1610
loss = 0.4502008259296417, steps = 36600, cost time = 3.32s
global_step/sec: 31.3823
loss = 0.4735828638076782, steps = 36700, cost time = 3.19s
global_step/sec: 33.6511
loss = 0.5242515802383423, steps = 36800, cost time = 2.97s
global_step/sec: 31.2642
loss = 0.4609339237213135, steps = 36900, cost time = 3.20s
global_step/sec: 30.0170
loss = 0.4556215703487396, steps = 37000, cost time = 3.33s
global_step/sec: 31.9941
loss = 0.5014141798019409, steps = 37100, cost time = 3.13s
global_step/sec: 34.9704
loss = 0.46184682846069336, steps = 37200, cost time = 2.86s
global_step/sec: 29.4763
loss = 0.42940545082092285, steps = 37300, cost time = 3.39s
global_step/sec: 29.2407
loss = 0.49768567085266113, steps = 37400, cost time = 3.42s
global_step/sec: 29.5151
loss = 0.4782821536064148, steps = 37500, cost time = 3.39s
global_step/sec: 30.3076
loss = 0.45710375905036926, steps = 37600, cost time = 3.30s
global_step/sec: 36.6572
loss = 0.49140965938568115, steps = 37700, cost time = 2.73s
global_step/sec: 30.9757
loss = 0.4249379634857178, steps = 37800, cost time = 3.23s
global_step/sec: 33.5189
loss = 0.5081456899642944, steps = 37900, cost time = 2.98s
global_step/sec: 32.4297
loss = 0.4669537842273712, steps = 38000, cost time = 3.08s
global_step/sec: 32.4512
loss = 0.46602070331573486, steps = 38100, cost time = 3.08s
global_step/sec: 33.4822
loss = 0.4682091176509857, steps = 38200, cost time = 2.99s
global_step/sec: 40.2925
loss = 0.5088480710983276, steps = 38300, cost time = 2.48s
global_step/sec: 32.7791
loss = 0.5131267309188843, steps = 38400, cost time = 3.05s
global_step/sec: 32.6287
loss = 0.4534991979598999, steps = 38500, cost time = 3.06s
global_step/sec: 32.1013
loss = 0.4758222699165344, steps = 38600, cost time = 3.12s
global_step/sec: 31.3038
loss = 0.44037002325057983, steps = 38700, cost time = 3.19s
global_step/sec: 38.6128
loss = 0.45797282457351685, steps = 38800, cost time = 2.59s
global_step/sec: 33.0488
loss = 0.4611491560935974, steps = 38900, cost time = 3.03s
global_step/sec: 33.1310
loss = 0.44936367869377136, steps = 39000, cost time = 3.02s
global_step/sec: 30.5780
loss = 0.44187313318252563, steps = 39100, cost time = 3.27s
global_step/sec: 30.3582
loss = 0.49016252160072327, steps = 39200, cost time = 3.29s
global_step/sec: 38.2968
loss = 0.4839818775653839, steps = 39300, cost time = 2.61s
global_step/sec: 32.7632
loss = 0.44611403346061707, steps = 39400, cost time = 3.05s
global_step/sec: 36.8743
loss = 0.44790586829185486, steps = 39500, cost time = 2.71s
global_step/sec: 33.7269
loss = 0.484531432390213, steps = 39600, cost time = 2.96s
global_step/sec: 38.0120
loss = 0.4543963670730591, steps = 39700, cost time = 2.63s
global_step/sec: 34.1912
loss = 0.4583599865436554, steps = 39800, cost time = 2.92s
global_step/sec: 34.9604
loss = 0.4632912278175354, steps = 39900, cost time = 2.86s
global_step/sec: 36.3849
loss = 0.40923577547073364, steps = 40000, cost time = 2.75s
global_step/sec: 37.9570
loss = 0.49034595489501953, steps = 40100, cost time = 2.63s
global_step/sec: 39.0126
loss = 0.5028637647628784, steps = 40200, cost time = 2.56s
global_step/sec: 34.6234
loss = 0.44084399938583374, steps = 40300, cost time = 2.89s
global_step/sec: 35.9220
loss = 0.4737647771835327, steps = 40400, cost time = 2.78s
global_step/sec: 30.7250
loss = 0.4524543583393097, steps = 40500, cost time = 3.25s
global_step/sec: 30.6725
loss = 0.4761628210544586, steps = 40600, cost time = 3.26s
global_step/sec: 30.5127
loss = 0.45643311738967896, steps = 40700, cost time = 3.28s
global_step/sec: 31.5816
loss = 0.514173150062561, steps = 40800, cost time = 3.17s
global_step/sec: 30.9158
loss = 0.4853871166706085, steps = 40900, cost time = 3.23s
global_step/sec: 31.9140
loss = 0.49786579608917236, steps = 41000, cost time = 3.13s
global_step/sec: 29.3764
loss = 0.44553208351135254, steps = 41100, cost time = 3.40s
global_step/sec: 32.8583
loss = 0.4496232867240906, steps = 41200, cost time = 3.04s
global_step/sec: 30.8886
loss = 0.4745042026042938, steps = 41300, cost time = 3.24s
global_step/sec: 31.4634
loss = 0.5000886917114258, steps = 41400, cost time = 3.18s
global_step/sec: 32.4904
loss = 0.5058803558349609, steps = 41500, cost time = 3.08s
global_step/sec: 31.2640
loss = 0.4331614375114441, steps = 41600, cost time = 3.20s
global_step/sec: 33.9782
loss = 0.4671857953071594, steps = 41700, cost time = 2.94s
global_step/sec: 33.9866
loss = 0.4986664950847626, steps = 41800, cost time = 2.94s
global_step/sec: 38.6678
loss = 0.45137473940849304, steps = 41900, cost time = 2.59s
global_step/sec: 39.9662
loss = 0.5070396661758423, steps = 42000, cost time = 2.50s
global_step/sec: 36.7947
loss = 0.4381892681121826, steps = 42100, cost time = 2.72s
global_step/sec: 34.5466
loss = 0.4550498127937317, steps = 42200, cost time = 2.89s
global_step/sec: 37.7237
loss = 0.49429255723953247, steps = 42300, cost time = 2.65s
global_step/sec: 34.9709
loss = 0.457413911819458, steps = 42400, cost time = 2.86s
global_step/sec: 34.2117
loss = 0.4595096707344055, steps = 42500, cost time = 2.92s
global_step/sec: 39.5807
loss = 0.4492197632789612, steps = 42600, cost time = 2.53s
global_step/sec: 32.9096
loss = 0.4216996133327484, steps = 42700, cost time = 3.04s
global_step/sec: 34.4053
loss = 0.47539228200912476, steps = 42800, cost time = 2.91s
global_step/sec: 37.1348
loss = 0.4859812259674072, steps = 42900, cost time = 2.69s
global_step/sec: 30.4588
loss = 0.49030429124832153, steps = 43000, cost time = 3.28s
global_step/sec: 33.1365
loss = 0.45559799671173096, steps = 43100, cost time = 3.02s
global_step/sec: 34.7174
loss = 0.4574529528617859, steps = 43200, cost time = 2.88s
global_step/sec: 37.8356
loss = 0.437281996011734, steps = 43300, cost time = 2.64s
global_step/sec: 33.2703
loss = 0.4645061492919922, steps = 43400, cost time = 3.01s
global_step/sec: 34.6616
loss = 0.45999985933303833, steps = 43500, cost time = 2.89s
global_step/sec: 36.6077
loss = 0.44506072998046875, steps = 43600, cost time = 2.73s
global_step/sec: 38.0595
loss = 0.48453348875045776, steps = 43700, cost time = 2.63s
global_step/sec: 31.2850
loss = 0.4512920677661896, steps = 43800, cost time = 3.20s
global_step/sec: 30.0686
loss = 0.46779337525367737, steps = 43900, cost time = 3.33s
global_step/sec: 34.4354
loss = 0.41857635974884033, steps = 44000, cost time = 2.90s
global_step/sec: 31.1948
loss = 0.4516713321208954, steps = 44100, cost time = 3.21s
global_step/sec: 31.9859
loss = 0.4787861704826355, steps = 44200, cost time = 3.13s
global_step/sec: 31.6188
loss = 0.48645496368408203, steps = 44300, cost time = 3.16s
global_step/sec: 32.7265
loss = 0.4736277461051941, steps = 44400, cost time = 3.06s
global_step/sec: 34.4144
loss = 0.4727991223335266, steps = 44500, cost time = 2.91s
global_step/sec: 32.5488
loss = 0.484599769115448, steps = 44600, cost time = 3.07s
global_step/sec: 35.8105
loss = 0.4826977849006653, steps = 44700, cost time = 2.79s
global_step/sec: 38.9354
loss = 0.4797111749649048, steps = 44800, cost time = 2.57s
global_step/sec: 30.4032
loss = 0.5169371366500854, steps = 44900, cost time = 3.29s
global_step/sec: 30.7200
loss = 0.5016171336174011, steps = 45000, cost time = 3.26s
global_step/sec: 29.3877
loss = 0.4700199365615845, steps = 45100, cost time = 3.40s
global_step/sec: 34.0299
loss = 0.47255611419677734, steps = 45200, cost time = 2.94s
global_step/sec: 35.9725
loss = 0.49834299087524414, steps = 45300, cost time = 2.78s
global_step/sec: 32.3479
loss = 0.42333903908729553, steps = 45400, cost time = 3.09s
global_step/sec: 31.8406
loss = 0.4994252920150757, steps = 45500, cost time = 3.14s
global_step/sec: 33.9474
loss = 0.47269001603126526, steps = 45600, cost time = 2.95s
global_step/sec: 30.7752
loss = 0.4397345185279846, steps = 45700, cost time = 3.25s
global_step/sec: 30.9919
loss = 0.46979600191116333, steps = 45800, cost time = 3.23s
global_step/sec: 31.4227
loss = 0.42999768257141113, steps = 45900, cost time = 3.18s
global_step/sec: 29.0285
loss = 0.4919295907020569, steps = 46000, cost time = 3.44s
global_step/sec: 31.2056
loss = 0.48797136545181274, steps = 46100, cost time = 3.20s
global_step/sec: 34.3277
loss = 0.4633833169937134, steps = 46200, cost time = 2.91s
global_step/sec: 40.0122
loss = 0.48906630277633667, steps = 46300, cost time = 2.50s
global_step/sec: 35.2547
loss = 0.44156450033187866, steps = 46400, cost time = 2.84s
global_step/sec: 32.6596
loss = 0.49632808566093445, steps = 46500, cost time = 3.06s
global_step/sec: 40.3638
loss = 0.45919692516326904, steps = 46600, cost time = 2.48s
global_step/sec: 35.0414
loss = 0.4674575626850128, steps = 46700, cost time = 2.85s
global_step/sec: 30.3057
loss = 0.4354545474052429, steps = 46800, cost time = 3.30s
global_step/sec: 31.0668
loss = 0.4376034736633301, steps = 46900, cost time = 3.22s
global_step/sec: 34.0029
loss = 0.4335688352584839, steps = 47000, cost time = 2.94s
global_step/sec: 31.9629
loss = 0.4889083504676819, steps = 47100, cost time = 3.13s
global_step/sec: 32.1795
loss = 0.4535622298717499, steps = 47200, cost time = 3.11s
global_step/sec: 35.6519
loss = 0.44949042797088623, steps = 47300, cost time = 2.80s
global_step/sec: 38.4481
loss = 0.505364179611206, steps = 47400, cost time = 2.60s
global_step/sec: 37.1110
loss = 0.48158857226371765, steps = 47500, cost time = 2.69s
global_step/sec: 37.3349
loss = 0.48127490282058716, steps = 47600, cost time = 2.68s
global_step/sec: 34.8811
loss = 0.486400306224823, steps = 47700, cost time = 2.87s
global_step/sec: 36.1306
loss = 0.44892358779907227, steps = 47800, cost time = 2.77s
global_step/sec: 32.1393
loss = 0.48995423316955566, steps = 47900, cost time = 3.11s
global_step/sec: 35.7170
loss = 0.44048649072647095, steps = 48000, cost time = 2.80s
global_step/sec: 34.0667
loss = 0.4554831385612488, steps = 48100, cost time = 2.94s
global_step/sec: 35.6557
loss = 0.4590049684047699, steps = 48200, cost time = 2.80s
global_step/sec: 38.3967
loss = 0.4581746459007263, steps = 48300, cost time = 2.60s
global_step/sec: 32.6678
loss = 0.429048091173172, steps = 48400, cost time = 3.06s
global_step/sec: 33.9548
loss = 0.47703975439071655, steps = 48500, cost time = 2.95s
global_step/sec: 29.6914
loss = 0.486542284488678, steps = 48600, cost time = 3.37s
global_step/sec: 28.4871
loss = 0.45715510845184326, steps = 48700, cost time = 3.51s
global_step/sec: 32.1183
loss = 0.4363154470920563, steps = 48800, cost time = 3.11s
global_step/sec: 38.5879
loss = 0.4364704489707947, steps = 48900, cost time = 2.59s
global_step/sec: 34.2338
loss = 0.45695817470550537, steps = 49000, cost time = 2.92s
global_step/sec: 29.1497
loss = 0.48324868083000183, steps = 49100, cost time = 3.43s
global_step/sec: 31.8223
loss = 0.4674536883831024, steps = 49200, cost time = 3.14s
global_step/sec: 37.3793
loss = 0.4626328647136688, steps = 49300, cost time = 2.68s
global_step/sec: 31.5766
loss = 0.46891456842422485, steps = 49400, cost time = 3.17s
global_step/sec: 34.1088
loss = 0.48387742042541504, steps = 49500, cost time = 2.93s
global_step/sec: 33.3638
loss = 0.4421521723270416, steps = 49600, cost time = 3.00s
global_step/sec: 34.9116
loss = 0.4990740716457367, steps = 49700, cost time = 2.86s
global_step/sec: 34.4348
loss = 0.461694598197937, steps = 49800, cost time = 2.90s
global_step/sec: 30.1912
loss = 0.4221465587615967, steps = 49900, cost time = 3.31s
global_step/sec: 30.1397
loss = 0.4475099444389343, steps = 50000, cost time = 3.32s
global_step/sec: 35.3549
loss = 0.5150395631790161, steps = 50100, cost time = 2.83s
global_step/sec: 30.1188
loss = 0.4196820855140686, steps = 50200, cost time = 3.32s
global_step/sec: 30.5124
loss = 0.5004259347915649, steps = 50300, cost time = 3.28s
global_step/sec: 31.3357
loss = 0.432238906621933, steps = 50400, cost time = 3.19s
global_step/sec: 34.8612
loss = 0.47466692328453064, steps = 50500, cost time = 2.87s
global_step/sec: 36.8562
loss = 0.4310351014137268, steps = 50600, cost time = 2.71s
global_step/sec: 36.8929
loss = 0.47022831439971924, steps = 50700, cost time = 2.71s
global_step/sec: 36.4625
loss = 0.48328983783721924, steps = 50800, cost time = 2.74s
global_step/sec: 35.5179
loss = 0.48299646377563477, steps = 50900, cost time = 2.82s
global_step/sec: 33.0581
loss = 0.4644882082939148, steps = 51000, cost time = 3.02s
global_step/sec: 35.6420
loss = 0.49984532594680786, steps = 51100, cost time = 2.81s
global_step/sec: 38.6680
loss = 0.4573327302932739, steps = 51200, cost time = 2.59s
global_step/sec: 35.9686
loss = 0.4691321849822998, steps = 51300, cost time = 2.78s
global_step/sec: 35.4338
loss = 0.49059438705444336, steps = 51400, cost time = 2.82s
global_step/sec: 32.7334
loss = 0.4889354109764099, steps = 51500, cost time = 3.05s
global_step/sec: 37.2641
loss = 0.45261350274086, steps = 51600, cost time = 2.68s
global_step/sec: 35.8429
loss = 0.4535379111766815, steps = 51700, cost time = 2.79s
global_step/sec: 31.1574
loss = 0.42627888917922974, steps = 51800, cost time = 3.21s
global_step/sec: 32.2240
loss = 0.4462379813194275, steps = 51900, cost time = 3.10s
global_step/sec: 29.9732
loss = 0.5034183263778687, steps = 52000, cost time = 3.34s
global_step/sec: 33.8507
loss = 0.46291759610176086, steps = 52100, cost time = 2.95s
global_step/sec: 30.9454
loss = 0.46149054169654846, steps = 52200, cost time = 3.23s
global_step/sec: 30.3321
loss = 0.46986520290374756, steps = 52300, cost time = 3.30s
global_step/sec: 30.5585
loss = 0.4432712495326996, steps = 52400, cost time = 3.27s
global_step/sec: 27.5073
loss = 0.4732973277568817, steps = 52500, cost time = 3.64s
global_step/sec: 29.4142
loss = 0.4341390132904053, steps = 52600, cost time = 3.40s
global_step/sec: 30.3173
loss = 0.46916335821151733, steps = 52700, cost time = 3.30s
global_step/sec: 28.3060
loss = 0.49572789669036865, steps = 52800, cost time = 3.53s
global_step/sec: 31.3724
loss = 0.44664791226387024, steps = 52900, cost time = 3.19s
global_step/sec: 30.9437
loss = 0.5033193826675415, steps = 53000, cost time = 3.23s
global_step/sec: 37.3945
loss = 0.4686375558376312, steps = 53100, cost time = 2.67s
global_step/sec: 38.6105
loss = 0.5152063369750977, steps = 53200, cost time = 2.59s
global_step/sec: 33.7121
loss = 0.5099144577980042, steps = 53300, cost time = 2.97s
global_step/sec: 30.7693
loss = 0.45885995030403137, steps = 53400, cost time = 3.25s
global_step/sec: 39.2905
loss = 0.4984065294265747, steps = 53500, cost time = 2.55s
global_step/sec: 37.5117
loss = 0.4462119936943054, steps = 53600, cost time = 2.67s
global_step/sec: 38.0196
loss = 0.4567902088165283, steps = 53700, cost time = 2.63s
global_step/sec: 38.7518
loss = 0.4670674204826355, steps = 53800, cost time = 2.58s
global_step/sec: 37.0825
loss = 0.4755052626132965, steps = 53900, cost time = 2.70s
global_step/sec: 32.5622
loss = 0.46963247656822205, steps = 54000, cost time = 3.07s
global_step/sec: 34.4676
loss = 0.515883207321167, steps = 54100, cost time = 2.90s
global_step/sec: 30.5108
loss = 0.46254271268844604, steps = 54200, cost time = 3.28s
global_step/sec: 32.0591
loss = 0.44028133153915405, steps = 54300, cost time = 3.12s
global_step/sec: 28.6904
loss = 0.4924473762512207, steps = 54400, cost time = 3.49s
global_step/sec: 34.5774
loss = 0.44068193435668945, steps = 54500, cost time = 2.89s
global_step/sec: 32.8515
loss = 0.495772123336792, steps = 54600, cost time = 3.04s
global_step/sec: 33.3659
loss = 0.46404969692230225, steps = 54700, cost time = 3.00s
global_step/sec: 29.6426
loss = 0.4639979302883148, steps = 54800, cost time = 3.37s
global_step/sec: 30.6189
loss = 0.45434245467185974, steps = 54900, cost time = 3.27s
global_step/sec: 31.1836
loss = 0.4802943468093872, steps = 55000, cost time = 3.21s
global_step/sec: 30.6660
loss = 0.4597907066345215, steps = 55100, cost time = 3.26s
global_step/sec: 33.0379
loss = 0.45637238025665283, steps = 55200, cost time = 3.03s
global_step/sec: 30.4613
loss = 0.4332084059715271, steps = 55300, cost time = 3.28s
global_step/sec: 33.9352
loss = 0.4236326813697815, steps = 55400, cost time = 2.95s
global_step/sec: 30.6146
loss = 0.4617891311645508, steps = 55500, cost time = 3.27s
global_step/sec: 30.0114
loss = 0.4399052560329437, steps = 55600, cost time = 3.33s
global_step/sec: 34.3634
loss = 0.45814839005470276, steps = 55700, cost time = 2.91s
global_step/sec: 35.1885
loss = 0.47511130571365356, steps = 55800, cost time = 2.84s
global_step/sec: 30.0242
loss = 0.5132428407669067, steps = 55900, cost time = 3.33s
global_step/sec: 33.7396
loss = 0.4434286952018738, steps = 56000, cost time = 2.96s
global_step/sec: 36.1137
loss = 0.4633963406085968, steps = 56100, cost time = 2.77s
global_step/sec: 38.0510
loss = 0.4511212110519409, steps = 56200, cost time = 2.63s
global_step/sec: 31.5618
loss = 0.48958224058151245, steps = 56300, cost time = 3.17s
global_step/sec: 30.5367
loss = 0.4317810833454132, steps = 56400, cost time = 3.27s
global_step/sec: 32.9800
loss = 0.49852973222732544, steps = 56500, cost time = 3.03s
global_step/sec: 38.5212
loss = 0.4607572555541992, steps = 56600, cost time = 2.60s
global_step/sec: 37.6228
loss = 0.4906885325908661, steps = 56700, cost time = 2.66s
global_step/sec: 38.5846
loss = 0.4310353994369507, steps = 56800, cost time = 2.59s
global_step/sec: 35.8024
loss = 0.41106921434402466, steps = 56900, cost time = 2.79s
global_step/sec: 37.8931
loss = 0.43554961681365967, steps = 57000, cost time = 2.64s
global_step/sec: 37.2084
loss = 0.4597981572151184, steps = 57100, cost time = 2.69s
global_step/sec: 34.4510
loss = 0.4267734885215759, steps = 57200, cost time = 2.90s
global_step/sec: 30.7903
loss = 0.4609512686729431, steps = 57300, cost time = 3.25s
global_step/sec: 35.2175
loss = 0.4587167501449585, steps = 57400, cost time = 2.84s
global_step/sec: 35.7979
loss = 0.4675842523574829, steps = 57500, cost time = 2.79s
global_step/sec: 31.7421
loss = 0.4778487980365753, steps = 57600, cost time = 3.15s
global_step/sec: 31.4752
loss = 0.4172074794769287, steps = 57700, cost time = 3.18s
global_step/sec: 32.2962
loss = 0.4291798770427704, steps = 57800, cost time = 3.10s
global_step/sec: 32.2983
loss = 0.46872973442077637, steps = 57900, cost time = 3.10s
global_step/sec: 32.4552
loss = 0.4479941725730896, steps = 58000, cost time = 3.08s
global_step/sec: 30.8282
loss = 0.4659882187843323, steps = 58100, cost time = 3.24s
global_step/sec: 38.9702
loss = 0.44212228059768677, steps = 58200, cost time = 2.57s
global_step/sec: 34.6913
loss = 0.44774001836776733, steps = 58300, cost time = 2.88s
global_step/sec: 31.7986
loss = 0.46970880031585693, steps = 58400, cost time = 3.14s
global_step/sec: 32.1746
loss = 0.4804018437862396, steps = 58500, cost time = 3.11s
global_step/sec: 36.3855
loss = 0.4329656660556793, steps = 58600, cost time = 2.75s
global_step/sec: 30.8524
loss = 0.508271336555481, steps = 58700, cost time = 3.24s
global_step/sec: 31.1189
loss = 0.46927618980407715, steps = 58800, cost time = 3.21s
global_step/sec: 30.7226
loss = 0.47337597608566284, steps = 58900, cost time = 3.25s
global_step/sec: 34.3389
loss = 0.4405185878276825, steps = 59000, cost time = 2.91s
global_step/sec: 38.8244
loss = 0.46255195140838623, steps = 59100, cost time = 2.58s
global_step/sec: 33.2373
loss = 0.43601876497268677, steps = 59200, cost time = 3.01s
global_step/sec: 36.2692
loss = 0.47125041484832764, steps = 59300, cost time = 2.76s
global_step/sec: 34.9141
loss = 0.4617427587509155, steps = 59400, cost time = 2.86s
global_step/sec: 36.2505
loss = 0.46537038683891296, steps = 59500, cost time = 2.76s
global_step/sec: 35.0945
loss = 0.39991170167922974, steps = 59600, cost time = 2.85s
global_step/sec: 34.5268
loss = 0.4418758153915405, steps = 59700, cost time = 2.90s
global_step/sec: 33.9022
loss = 0.4917721450328827, steps = 59800, cost time = 2.95s
global_step/sec: 32.8180
loss = 0.49295029044151306, steps = 59900, cost time = 3.05s
global_step/sec: 29.4788
loss = 0.5001268982887268, steps = 60000, cost time = 3.39s
global_step/sec: 29.6631
loss = 0.4970632791519165, steps = 60100, cost time = 3.37s
global_step/sec: 31.7731
loss = 0.5008518695831299, steps = 60200, cost time = 3.15s
global_step/sec: 30.0562
loss = 0.47620177268981934, steps = 60300, cost time = 3.33s
global_step/sec: 34.1888
loss = 0.511705756187439, steps = 60400, cost time = 2.92s
global_step/sec: 31.4061
loss = 0.4620482325553894, steps = 60500, cost time = 3.18s
global_step/sec: 34.5982
loss = 0.47486579418182373, steps = 60600, cost time = 2.89s
global_step/sec: 32.5643
loss = 0.5041987299919128, steps = 60700, cost time = 3.07s
global_step/sec: 31.9925
loss = 0.4813691973686218, steps = 60800, cost time = 3.13s
global_step/sec: 31.3952
loss = 0.4382386803627014, steps = 60900, cost time = 3.19s
global_step/sec: 34.2920
loss = 0.5050636529922485, steps = 61000, cost time = 2.92s
global_step/sec: 33.3398
loss = 0.4180305004119873, steps = 61100, cost time = 3.00s
global_step/sec: 38.8367
loss = 0.4799655079841614, steps = 61200, cost time = 2.57s
global_step/sec: 35.7863
loss = 0.4150541424751282, steps = 61300, cost time = 2.79s
global_step/sec: 35.9768
loss = 0.47389131784439087, steps = 61400, cost time = 2.78s
global_step/sec: 34.0268
loss = 0.44449520111083984, steps = 61500, cost time = 2.94s
global_step/sec: 33.5534
loss = 0.4717153310775757, steps = 61600, cost time = 2.98s
global_step/sec: 35.4590
loss = 0.4538098871707916, steps = 61700, cost time = 2.82s
global_step/sec: 36.8941
loss = 0.4986498951911926, steps = 61800, cost time = 2.71s
global_step/sec: 37.0087
loss = 0.5202155113220215, steps = 61900, cost time = 2.70s
global_step/sec: 34.8902
loss = 0.4501168131828308, steps = 62000, cost time = 2.87s
global_step/sec: 36.7220
loss = 0.5046195387840271, steps = 62100, cost time = 2.72s
global_step/sec: 34.0410
loss = 0.5016336441040039, steps = 62200, cost time = 2.94s
global_step/sec: 35.9274
loss = 0.4945649802684784, steps = 62300, cost time = 2.78s
global_step/sec: 35.6015
loss = 0.4540417492389679, steps = 62400, cost time = 2.81s
global_step/sec: 35.7245
loss = 0.42709919810295105, steps = 62500, cost time = 2.80s
global_step/sec: 34.7375
loss = 0.47332462668418884, steps = 62600, cost time = 2.88s
global_step/sec: 40.8313
loss = 0.4753667712211609, steps = 62700, cost time = 2.45s
global_step/sec: 36.3904
loss = 0.46431657671928406, steps = 62800, cost time = 2.75s
global_step/sec: 39.0475
loss = 0.49674782156944275, steps = 62900, cost time = 2.56s
global_step/sec: 33.4489
loss = 0.4352090060710907, steps = 63000, cost time = 2.99s
global_step/sec: 35.5210
loss = 0.4799965023994446, steps = 63100, cost time = 2.82s
global_step/sec: 32.3742
loss = 0.448465496301651, steps = 63200, cost time = 3.09s
global_step/sec: 32.7914
loss = 0.5039346218109131, steps = 63300, cost time = 3.05s
global_step/sec: 31.2840
loss = 0.44603222608566284, steps = 63400, cost time = 3.20s
global_step/sec: 31.3804
loss = 0.47269558906555176, steps = 63500, cost time = 3.19s
global_step/sec: 30.0732
loss = 0.4747110605239868, steps = 63600, cost time = 3.33s
global_step/sec: 34.4548
loss = 0.47818130254745483, steps = 63700, cost time = 2.90s
global_step/sec: 32.0032
loss = 0.451623797416687, steps = 63800, cost time = 3.12s
global_step/sec: 30.6494
loss = 0.47430360317230225, steps = 63900, cost time = 3.26s
global_step/sec: 32.2032
loss = 0.47056567668914795, steps = 64000, cost time = 3.11s
global_step/sec: 34.0763
loss = 0.4498584270477295, steps = 64100, cost time = 2.93s
global_step/sec: 35.6006
loss = 0.442695289850235, steps = 64200, cost time = 2.81s
global_step/sec: 30.8353
loss = 0.43815305829048157, steps = 64300, cost time = 3.24s
global_step/sec: 34.1036
loss = 0.47911667823791504, steps = 64400, cost time = 2.93s
global_step/sec: 32.2036
loss = 0.44158363342285156, steps = 64500, cost time = 3.11s
global_step/sec: 34.2920
loss = 0.44646981358528137, steps = 64600, cost time = 2.92s
global_step/sec: 35.3613
loss = 0.4547468423843384, steps = 64700, cost time = 2.83s
global_step/sec: 35.4537
loss = 0.43819108605384827, steps = 64800, cost time = 2.82s
global_step/sec: 35.6762
loss = 0.44823122024536133, steps = 64900, cost time = 2.80s
global_step/sec: 32.1796
loss = 0.49079859256744385, steps = 65000, cost time = 3.11s
global_step/sec: 36.2265
loss = 0.4665975868701935, steps = 65100, cost time = 2.76s
global_step/sec: 37.7593
loss = 0.4748389422893524, steps = 65200, cost time = 2.65s
global_step/sec: 30.6561
loss = 0.46653497219085693, steps = 65300, cost time = 3.26s
global_step/sec: 29.4397
loss = 0.4516962170600891, steps = 65400, cost time = 3.40s
global_step/sec: 33.4454
loss = 0.43883347511291504, steps = 65500, cost time = 2.99s
global_step/sec: 35.6117
loss = 0.45768317580223083, steps = 65600, cost time = 2.81s
global_step/sec: 29.9344
loss = 0.4592839479446411, steps = 65700, cost time = 3.34s
global_step/sec: 30.1351
loss = 0.4617484211921692, steps = 65800, cost time = 3.32s
global_step/sec: 33.1295
loss = 0.43130022287368774, steps = 65900, cost time = 3.02s
global_step/sec: 32.6852
loss = 0.42579877376556396, steps = 66000, cost time = 3.06s
global_step/sec: 33.9131
loss = 0.5160552263259888, steps = 66100, cost time = 2.95s
global_step/sec: 35.3059
loss = 0.518983781337738, steps = 66200, cost time = 2.83s
global_step/sec: 30.2643
loss = 0.4546065330505371, steps = 66300, cost time = 3.30s
global_step/sec: 31.6763
loss = 0.5133376121520996, steps = 66400, cost time = 3.16s
global_step/sec: 31.8316
loss = 0.4515911936759949, steps = 66500, cost time = 3.14s
global_step/sec: 32.4059
loss = 0.4332110583782196, steps = 66600, cost time = 3.09s
global_step/sec: 34.2395
loss = 0.46314844489097595, steps = 66700, cost time = 2.92s
global_step/sec: 30.3556
loss = 0.4641075134277344, steps = 66800, cost time = 3.29s
global_step/sec: 35.9376
loss = 0.4726575016975403, steps = 66900, cost time = 2.78s
global_step/sec: 35.0226
loss = 0.47989821434020996, steps = 67000, cost time = 2.86s
global_step/sec: 31.3163
loss = 0.4766981601715088, steps = 67100, cost time = 3.19s
global_step/sec: 35.2671
loss = 0.4676724076271057, steps = 67200, cost time = 2.84s
global_step/sec: 33.9397
loss = 0.4497201144695282, steps = 67300, cost time = 2.95s
global_step/sec: 36.4477
loss = 0.4505798816680908, steps = 67400, cost time = 2.74s
global_step/sec: 30.0806
loss = 0.4465920925140381, steps = 67500, cost time = 3.32s
global_step/sec: 29.1501
loss = 0.45746108889579773, steps = 67600, cost time = 3.43s
global_step/sec: 29.3199
loss = 0.4686478078365326, steps = 67700, cost time = 3.41s
global_step/sec: 36.0679
loss = 0.44528958201408386, steps = 67800, cost time = 2.77s
global_step/sec: 30.9513
loss = 0.4841391146183014, steps = 67900, cost time = 3.23s
global_step/sec: 32.6212
loss = 0.4483046531677246, steps = 68000, cost time = 3.07s
global_step/sec: 34.1562
loss = 0.4268515408039093, steps = 68100, cost time = 2.93s
global_step/sec: 36.6497
loss = 0.45127204060554504, steps = 68200, cost time = 2.73s
global_step/sec: 37.0634
loss = 0.4606750011444092, steps = 68300, cost time = 2.70s
global_step/sec: 37.2789
loss = 0.47098225355148315, steps = 68400, cost time = 2.68s
global_step/sec: 38.3669
loss = 0.458918035030365, steps = 68500, cost time = 2.61s
global_step/sec: 36.5692
loss = 0.4806100130081177, steps = 68600, cost time = 2.73s
global_step/sec: 34.4311
loss = 0.4554803669452667, steps = 68700, cost time = 2.90s
global_step/sec: 35.4316
loss = 0.4545673727989197, steps = 68800, cost time = 2.82s
global_step/sec: 32.2597
loss = 0.47475913166999817, steps = 68900, cost time = 3.10s
global_step/sec: 31.6134
loss = 0.4566543698310852, steps = 69000, cost time = 3.16s
global_step/sec: 33.2095
loss = 0.42223283648490906, steps = 69100, cost time = 3.01s
global_step/sec: 35.3773
loss = 0.44163525104522705, steps = 69200, cost time = 2.83s
global_step/sec: 36.5013
loss = 0.4701003432273865, steps = 69300, cost time = 2.74s
global_step/sec: 36.9685
loss = 0.4595462679862976, steps = 69400, cost time = 2.71s
global_step/sec: 39.3091
loss = 0.46086061000823975, steps = 69500, cost time = 2.54s
global_step/sec: 30.8360
loss = 0.42549145221710205, steps = 69600, cost time = 3.24s
global_step/sec: 34.3502
loss = 0.42018163204193115, steps = 69700, cost time = 2.91s
global_step/sec: 33.2272
loss = 0.4875980019569397, steps = 69800, cost time = 3.01s
global_step/sec: 36.1760
loss = 0.49758875370025635, steps = 69900, cost time = 2.76s
global_step/sec: 36.7475
loss = 0.47010961174964905, steps = 70000, cost time = 2.72s
global_step/sec: 30.5134
loss = 0.4397915005683899, steps = 70100, cost time = 3.28s
global_step/sec: 38.5140
loss = 0.45059734582901, steps = 70200, cost time = 2.60s
global_step/sec: 33.9388
loss = 0.4831620752811432, steps = 70300, cost time = 2.95s
global_step/sec: 37.1783
loss = 0.4378582239151001, steps = 70400, cost time = 2.69s
global_step/sec: 31.3326
loss = 0.42852720618247986, steps = 70500, cost time = 3.19s
global_step/sec: 30.8557
loss = 0.40557682514190674, steps = 70600, cost time = 3.24s
global_step/sec: 36.9069
loss = 0.4303111433982849, steps = 70700, cost time = 2.71s
global_step/sec: 35.4681
loss = 0.43255698680877686, steps = 70800, cost time = 2.82s
global_step/sec: 36.4354
loss = 0.4445761442184448, steps = 70900, cost time = 2.74s
global_step/sec: 30.4155
loss = 0.49723684787750244, steps = 71000, cost time = 3.29s
global_step/sec: 33.8887
loss = 0.47585922479629517, steps = 71100, cost time = 2.95s
global_step/sec: 36.1550
loss = 0.4845500886440277, steps = 71200, cost time = 2.77s
global_step/sec: 37.8250
loss = 0.4496763348579407, steps = 71300, cost time = 2.64s
global_step/sec: 35.5737
loss = 0.45003542304039, steps = 71400, cost time = 2.81s
global_step/sec: 34.6479
loss = 0.4649924635887146, steps = 71500, cost time = 2.89s
global_step/sec: 31.9840
loss = 0.47159284353256226, steps = 71600, cost time = 3.13s
global_step/sec: 33.4141
loss = 0.4521409273147583, steps = 71700, cost time = 2.99s
global_step/sec: 30.1556
loss = 0.44897422194480896, steps = 71800, cost time = 3.32s
global_step/sec: 29.9238
loss = 0.4615548849105835, steps = 71900, cost time = 3.34s
global_step/sec: 29.3185
loss = 0.4962747097015381, steps = 72000, cost time = 3.41s
global_step/sec: 35.0902
loss = 0.4618322253227234, steps = 72100, cost time = 2.85s
global_step/sec: 32.5588
loss = 0.42786094546318054, steps = 72200, cost time = 3.07s
global_step/sec: 31.0111
loss = 0.45400795340538025, steps = 72300, cost time = 3.22s
global_step/sec: 31.9290
loss = 0.49331310391426086, steps = 72400, cost time = 3.13s
global_step/sec: 31.6206
loss = 0.4641894996166229, steps = 72500, cost time = 3.16s
global_step/sec: 35.0182
loss = 0.4301512539386749, steps = 72600, cost time = 2.86s
global_step/sec: 33.3430
loss = 0.46257734298706055, steps = 72700, cost time = 3.00s
global_step/sec: 37.5292
loss = 0.4467775821685791, steps = 72800, cost time = 2.66s
global_step/sec: 34.3637
loss = 0.4580930471420288, steps = 72900, cost time = 2.91s
global_step/sec: 37.6994
loss = 0.4724326729774475, steps = 73000, cost time = 2.65s
global_step/sec: 33.8886
loss = 0.4739390015602112, steps = 73100, cost time = 2.95s
global_step/sec: 32.5616
loss = 0.42082181572914124, steps = 73200, cost time = 3.07s
global_step/sec: 31.2830
loss = 0.45141512155532837, steps = 73300, cost time = 3.20s
global_step/sec: 33.1293
loss = 0.452412486076355, steps = 73400, cost time = 3.02s
global_step/sec: 31.9637
loss = 0.45955175161361694, steps = 73500, cost time = 3.13s
global_step/sec: 30.5837
loss = 0.49471813440322876, steps = 73600, cost time = 3.27s
global_step/sec: 33.5662
loss = 0.4816877245903015, steps = 73700, cost time = 2.98s
global_step/sec: 29.6604
loss = 0.45753106474876404, steps = 73800, cost time = 3.37s
global_step/sec: 34.9980
loss = 0.4485318660736084, steps = 73900, cost time = 2.86s
global_step/sec: 35.0736
loss = 0.42682766914367676, steps = 74000, cost time = 2.85s
global_step/sec: 32.4361
loss = 0.4448314309120178, steps = 74100, cost time = 3.08s
global_step/sec: 37.3424
loss = 0.440460741519928, steps = 74200, cost time = 2.68s
global_step/sec: 33.4671
loss = 0.46948006749153137, steps = 74300, cost time = 2.99s
global_step/sec: 34.4493
loss = 0.4805206060409546, steps = 74400, cost time = 2.90s
global_step/sec: 32.7344
loss = 0.4717300832271576, steps = 74500, cost time = 3.05s
global_step/sec: 28.8984
loss = 0.4758528769016266, steps = 74600, cost time = 3.46s
global_step/sec: 32.9894
loss = 0.4164191484451294, steps = 74700, cost time = 3.03s
global_step/sec: 30.8816
loss = 0.4825919270515442, steps = 74800, cost time = 3.24s
global_step/sec: 30.6189
loss = 0.4446740746498108, steps = 74900, cost time = 3.27s
global_step/sec: 29.1184
loss = 0.4415949583053589, steps = 75000, cost time = 3.43s
global_step/sec: 32.3021
loss = 0.41441524028778076, steps = 75100, cost time = 3.10s
global_step/sec: 35.1220
loss = 0.4363579750061035, steps = 75200, cost time = 2.85s
global_step/sec: 40.7423
loss = 0.44025224447250366, steps = 75300, cost time = 2.45s
global_step/sec: 37.3893
loss = 0.46981731057167053, steps = 75400, cost time = 2.67s
global_step/sec: 35.5062
loss = 0.4907585382461548, steps = 75500, cost time = 2.82s
global_step/sec: 39.0575
loss = 0.47102004289627075, steps = 75600, cost time = 2.56s
global_step/sec: 30.2287
loss = 0.5227952003479004, steps = 75700, cost time = 3.31s
global_step/sec: 29.4075
loss = 0.46081817150115967, steps = 75800, cost time = 3.40s
global_step/sec: 30.5513
loss = 0.5348483324050903, steps = 75900, cost time = 3.27s
global_step/sec: 29.1041
loss = 0.46018433570861816, steps = 76000, cost time = 3.44s
global_step/sec: 31.8958
loss = 0.47000086307525635, steps = 76100, cost time = 3.14s
global_step/sec: 33.9477
loss = 0.5253402590751648, steps = 76200, cost time = 2.95s
global_step/sec: 32.0142
loss = 0.5275477170944214, steps = 76300, cost time = 3.12s
global_step/sec: 30.0137
loss = 0.5037530064582825, steps = 76400, cost time = 3.33s
global_step/sec: 30.5141
loss = 0.47283339500427246, steps = 76500, cost time = 3.28s
global_step/sec: 34.6713
loss = 0.47043782472610474, steps = 76600, cost time = 2.88s
global_step/sec: 35.1808
loss = 0.4633710980415344, steps = 76700, cost time = 2.84s
global_step/sec: 30.8802
loss = 0.48599347472190857, steps = 76800, cost time = 3.24s
global_step/sec: 32.2659
loss = 0.4446568787097931, steps = 76900, cost time = 3.10s
global_step/sec: 30.1841
loss = 0.4450046718120575, steps = 77000, cost time = 3.31s
global_step/sec: 31.3788
loss = 0.41472765803337097, steps = 77100, cost time = 3.19s
global_step/sec: 29.1231
loss = 0.466523140668869, steps = 77200, cost time = 3.43s
global_step/sec: 30.4821
loss = 0.4820755124092102, steps = 77300, cost time = 3.28s
global_step/sec: 35.2693
loss = 0.5051682591438293, steps = 77400, cost time = 2.84s
global_step/sec: 36.5896
loss = 0.4653410017490387, steps = 77500, cost time = 2.73s
global_step/sec: 35.7710
loss = 0.45673853158950806, steps = 77600, cost time = 2.80s
global_step/sec: 31.1259
loss = 0.4480573534965515, steps = 77700, cost time = 3.21s
global_step/sec: 33.3965
loss = 0.4679984152317047, steps = 77800, cost time = 2.99s
global_step/sec: 33.0117
loss = 0.4670364260673523, steps = 77900, cost time = 3.03s
global_step/sec: 35.7633
loss = 0.4152314066886902, steps = 78000, cost time = 2.80s
global_step/sec: 33.3971
loss = 0.43934202194213867, steps = 78100, cost time = 2.99s
global_step/sec: 34.2258
loss = 0.42582130432128906, steps = 78200, cost time = 2.92s
global_step/sec: 35.2494
loss = 0.43603581190109253, steps = 78300, cost time = 2.84s
global_step/sec: 33.7352
loss = 0.46317049860954285, steps = 78400, cost time = 2.96s
global_step/sec: 28.8210
loss = 0.46700650453567505, steps = 78500, cost time = 3.47s
global_step/sec: 35.8519
loss = 0.4985712170600891, steps = 78600, cost time = 2.79s
global_step/sec: 33.6742
loss = 0.46490150690078735, steps = 78700, cost time = 2.97s
global_step/sec: 31.5202
loss = 0.47536519169807434, steps = 78800, cost time = 3.17s
global_step/sec: 29.3521
loss = 0.441461980342865, steps = 78900, cost time = 3.41s
global_step/sec: 29.6797
loss = 0.48338836431503296, steps = 79000, cost time = 3.37s
global_step/sec: 30.1702
loss = 0.4853443503379822, steps = 79100, cost time = 3.31s
global_step/sec: 30.1767
loss = 0.4873705208301544, steps = 79200, cost time = 3.31s
global_step/sec: 35.3571
loss = 0.4589778780937195, steps = 79300, cost time = 2.83s
global_step/sec: 33.5811
loss = 0.4342450499534607, steps = 79400, cost time = 2.98s
global_step/sec: 31.2135
loss = 0.48690730333328247, steps = 79500, cost time = 3.20s
global_step/sec: 34.8512
loss = 0.47846338152885437, steps = 79600, cost time = 2.87s
global_step/sec: 34.5523
loss = 0.45868611335754395, steps = 79700, cost time = 2.89s
global_step/sec: 33.4168
loss = 0.4406251907348633, steps = 79800, cost time = 2.99s
global_step/sec: 33.6240
loss = 0.4891098737716675, steps = 79900, cost time = 2.97s
global_step/sec: 36.1511
loss = 0.4925285279750824, steps = 80000, cost time = 2.77s
global_step/sec: 40.5246
loss = 0.48323386907577515, steps = 80100, cost time = 2.47s
global_step/sec: 35.0642
loss = 0.49132150411605835, steps = 80200, cost time = 2.85s
global_step/sec: 34.0578
loss = 0.45291227102279663, steps = 80300, cost time = 2.94s
global_step/sec: 37.3751
loss = 0.4453631043434143, steps = 80400, cost time = 2.68s
global_step/sec: 34.0471
loss = 0.47373536229133606, steps = 80500, cost time = 2.94s
global_step/sec: 35.6557
loss = 0.434294193983078, steps = 80600, cost time = 2.80s
global_step/sec: 37.8814
loss = 0.45740294456481934, steps = 80700, cost time = 2.64s
global_step/sec: 34.6695
loss = 0.47282764315605164, steps = 80800, cost time = 2.88s
global_step/sec: 36.8071
loss = 0.4774019420146942, steps = 80900, cost time = 2.72s
global_step/sec: 33.8459
loss = 0.46726006269454956, steps = 81000, cost time = 2.95s
global_step/sec: 32.3898
loss = 0.447765588760376, steps = 81100, cost time = 3.09s
global_step/sec: 32.9390
loss = 0.46676698327064514, steps = 81200, cost time = 3.04s
global_step/sec: 31.2614
loss = 0.45961207151412964, steps = 81300, cost time = 3.20s
global_step/sec: 33.4722
loss = 0.4327983260154724, steps = 81400, cost time = 2.99s
global_step/sec: 35.7785
loss = 0.4205923080444336, steps = 81500, cost time = 2.79s
global_step/sec: 30.0274
loss = 0.43725860118865967, steps = 81600, cost time = 3.33s
global_step/sec: 34.5299
loss = 0.4654960036277771, steps = 81700, cost time = 2.90s
global_step/sec: 31.5528
loss = 0.456203818321228, steps = 81800, cost time = 3.17s
global_step/sec: 34.5023
loss = 0.4404190182685852, steps = 81900, cost time = 2.90s
global_step/sec: 33.1355
loss = 0.4516924321651459, steps = 82000, cost time = 3.02s
global_step/sec: 30.5228
loss = 0.4842682182788849, steps = 82100, cost time = 3.28s
global_step/sec: 35.7242
loss = 0.4586108326911926, steps = 82200, cost time = 2.80s
global_step/sec: 29.4045
loss = 0.4636201858520508, steps = 82300, cost time = 3.40s
global_step/sec: 29.9251
loss = 0.5017091631889343, steps = 82400, cost time = 3.34s
global_step/sec: 29.5974
loss = 0.4408441185951233, steps = 82500, cost time = 3.38s
global_step/sec: 28.5100
loss = 0.5024918913841248, steps = 82600, cost time = 3.51s
global_step/sec: 36.9904
loss = 0.4414255917072296, steps = 82700, cost time = 2.70s
global_step/sec: 33.5114
loss = 0.5032144784927368, steps = 82800, cost time = 2.98s
global_step/sec: 32.3172
loss = 0.47778308391571045, steps = 82900, cost time = 3.09s
global_step/sec: 42.1018
loss = 0.46087124943733215, steps = 83000, cost time = 2.38s
global_step/sec: 41.4267
loss = 0.44860944151878357, steps = 83100, cost time = 2.41s
global_step/sec: 36.2979
loss = 0.43477004766464233, steps = 83200, cost time = 2.75s
global_step/sec: 30.8652
loss = 0.43375542759895325, steps = 83300, cost time = 3.24s
global_step/sec: 33.9051
loss = 0.42850416898727417, steps = 83400, cost time = 2.95s
global_step/sec: 34.7354
loss = 0.44622933864593506, steps = 83500, cost time = 2.88s
global_step/sec: 38.2659
loss = 0.4712565541267395, steps = 83600, cost time = 2.61s
global_step/sec: 35.3919
loss = 0.463371217250824, steps = 83700, cost time = 2.83s
global_step/sec: 32.7524
loss = 0.4684258699417114, steps = 83800, cost time = 3.05s
global_step/sec: 33.5339
loss = 0.4998505115509033, steps = 83900, cost time = 2.98s
global_step/sec: 36.1616
loss = 0.5050233602523804, steps = 84000, cost time = 2.77s
global_step/sec: 34.4322
loss = 0.45170512795448303, steps = 84100, cost time = 2.90s
global_step/sec: 32.1738
loss = 0.4586722254753113, steps = 84200, cost time = 3.11s
global_step/sec: 38.5496
loss = 0.47116807103157043, steps = 84300, cost time = 2.59s
global_step/sec: 32.4250
loss = 0.47448790073394775, steps = 84400, cost time = 3.08s
global_step/sec: 31.5085
loss = 0.46127331256866455, steps = 84500, cost time = 3.17s
global_step/sec: 37.0284
loss = 0.46148258447647095, steps = 84600, cost time = 2.70s
global_step/sec: 34.1489
loss = 0.461770236492157, steps = 84700, cost time = 2.93s
global_step/sec: 34.1408
loss = 0.441853404045105, steps = 84800, cost time = 2.93s
global_step/sec: 32.4577
loss = 0.4959096312522888, steps = 84900, cost time = 3.08s
global_step/sec: 39.4590
loss = 0.4764764904975891, steps = 85000, cost time = 2.53s
global_step/sec: 33.0399
loss = 0.48972731828689575, steps = 85100, cost time = 3.03s
global_step/sec: 32.8536
loss = 0.5015562772750854, steps = 85200, cost time = 3.04s
global_step/sec: 30.2987
loss = 0.4493207335472107, steps = 85300, cost time = 3.30s
global_step/sec: 31.3969
loss = 0.48100894689559937, steps = 85400, cost time = 3.19s
global_step/sec: 30.8722
loss = 0.46857067942619324, steps = 85500, cost time = 3.24s
global_step/sec: 35.2704
loss = 0.4519750773906708, steps = 85600, cost time = 2.84s
global_step/sec: 33.4463
loss = 0.4375743269920349, steps = 85700, cost time = 2.99s
global_step/sec: 36.3138
loss = 0.46788328886032104, steps = 85800, cost time = 2.75s
global_step/sec: 31.0942
loss = 0.4398246705532074, steps = 85900, cost time = 3.22s
global_step/sec: 33.5508
loss = 0.44795870780944824, steps = 86000, cost time = 2.98s
global_step/sec: 34.8548
loss = 0.4780321717262268, steps = 86100, cost time = 2.87s
global_step/sec: 38.1327
loss = 0.4195513129234314, steps = 86200, cost time = 2.62s
global_step/sec: 37.2039
loss = 0.44686031341552734, steps = 86300, cost time = 2.69s
global_step/sec: 35.5260
loss = 0.43844276666641235, steps = 86400, cost time = 2.81s
global_step/sec: 31.3618
loss = 0.47443607449531555, steps = 86500, cost time = 3.19s
global_step/sec: 32.9244
loss = 0.5313937664031982, steps = 86600, cost time = 3.04s
global_step/sec: 29.8844
loss = 0.47296491265296936, steps = 86700, cost time = 3.35s
global_step/sec: 29.7081
loss = 0.47312283515930176, steps = 86800, cost time = 3.37s
global_step/sec: 30.8164
loss = 0.44171518087387085, steps = 86900, cost time = 3.25s
global_step/sec: 34.7416
loss = 0.41144147515296936, steps = 87000, cost time = 2.88s
global_step/sec: 35.2912
loss = 0.46030193567276, steps = 87100, cost time = 2.83s
global_step/sec: 35.1064
loss = 0.5141191482543945, steps = 87200, cost time = 2.85s
global_step/sec: 37.5230
loss = 0.46897125244140625, steps = 87300, cost time = 2.67s
global_step/sec: 36.4773
loss = 0.4279393255710602, steps = 87400, cost time = 2.74s
global_step/sec: 36.6234
loss = 0.4850616753101349, steps = 87500, cost time = 2.73s
global_step/sec: 33.0273
loss = 0.4397510290145874, steps = 87600, cost time = 3.03s
global_step/sec: 37.6528
loss = 0.45453882217407227, steps = 87700, cost time = 2.66s
global_step/sec: 34.5879
loss = 0.4784260094165802, steps = 87800, cost time = 2.89s
global_step/sec: 36.6148
loss = 0.46055954694747925, steps = 87900, cost time = 2.73s
global_step/sec: 30.4243
loss = 0.4716109037399292, steps = 88000, cost time = 3.29s
global_step/sec: 33.0570
loss = 0.43038278818130493, steps = 88100, cost time = 3.03s
global_step/sec: 36.7473
loss = 0.47908586263656616, steps = 88200, cost time = 2.72s
global_step/sec: 28.5174
loss = 0.4841388761997223, steps = 88300, cost time = 3.51s
global_step/sec: 29.2421
loss = 0.4666749835014343, steps = 88400, cost time = 3.42s
global_step/sec: 32.3456
loss = 0.4663577079772949, steps = 88500, cost time = 3.09s
global_step/sec: 32.1510
loss = 0.5008171796798706, steps = 88600, cost time = 3.11s
global_step/sec: 32.4275
loss = 0.42558079957962036, steps = 88700, cost time = 3.08s
global_step/sec: 38.6507
loss = 0.4519506096839905, steps = 88800, cost time = 2.59s
global_step/sec: 34.6942
loss = 0.437944233417511, steps = 88900, cost time = 2.88s
global_step/sec: 35.7354
loss = 0.48114779591560364, steps = 89000, cost time = 2.80s
global_step/sec: 31.4609
loss = 0.47053998708724976, steps = 89100, cost time = 3.18s
global_step/sec: 32.9583
loss = 0.5130940675735474, steps = 89200, cost time = 3.03s
global_step/sec: 36.3860
loss = 0.4366756081581116, steps = 89300, cost time = 2.75s
global_step/sec: 36.6390
loss = 0.42898857593536377, steps = 89400, cost time = 2.73s
global_step/sec: 34.4183
loss = 0.40908101201057434, steps = 89500, cost time = 2.91s
global_step/sec: 38.5915
loss = 0.4638855755329132, steps = 89600, cost time = 2.59s
global_step/sec: 40.8232
loss = 0.45823854207992554, steps = 89700, cost time = 2.45s
global_step/sec: 31.2506
loss = 0.45599865913391113, steps = 89800, cost time = 3.20s
global_step/sec: 29.4079
loss = 0.44459277391433716, steps = 89900, cost time = 3.40s
global_step/sec: 29.5942
loss = 0.4643292725086212, steps = 90000, cost time = 3.38s
global_step/sec: 31.8876
loss = 0.44312843680381775, steps = 90100, cost time = 3.14s
global_step/sec: 34.5399
loss = 0.47477298974990845, steps = 90200, cost time = 2.90s
global_step/sec: 34.1618
loss = 0.47009608149528503, steps = 90300, cost time = 2.93s
global_step/sec: 37.3396
loss = 0.4356275498867035, steps = 90400, cost time = 2.68s
global_step/sec: 32.8439
loss = 0.4527827501296997, steps = 90500, cost time = 3.04s
global_step/sec: 34.4809
loss = 0.43715476989746094, steps = 90600, cost time = 2.90s
global_step/sec: 29.1819
loss = 0.45857536792755127, steps = 90700, cost time = 3.43s
global_step/sec: 32.0932
loss = 0.4394038915634155, steps = 90800, cost time = 3.12s
global_step/sec: 37.2030
loss = 0.4475874900817871, steps = 90900, cost time = 2.69s
global_step/sec: 36.4425
loss = 0.45985472202301025, steps = 91000, cost time = 2.74s
global_step/sec: 36.4418
loss = 0.49707555770874023, steps = 91100, cost time = 2.74s
global_step/sec: 30.4810
loss = 0.4701416492462158, steps = 91200, cost time = 3.28s
global_step/sec: 39.7383
loss = 0.49958792328834534, steps = 91300, cost time = 2.52s
global_step/sec: 34.0326
loss = 0.49326270818710327, steps = 91400, cost time = 2.94s
global_step/sec: 32.0651
loss = 0.4976986050605774, steps = 91500, cost time = 3.12s
global_step/sec: 32.8162
loss = 0.47101885080337524, steps = 91600, cost time = 3.05s
global_step/sec: 33.6455
loss = 0.48487818241119385, steps = 91700, cost time = 2.97s
global_step/sec: 32.0134
loss = 0.446433424949646, steps = 91800, cost time = 3.12s
global_step/sec: 34.4050
loss = 0.4891654849052429, steps = 91900, cost time = 2.91s
global_step/sec: 34.5114
loss = 0.4629235863685608, steps = 92000, cost time = 2.90s
global_step/sec: 38.5361
loss = 0.4690873622894287, steps = 92100, cost time = 2.59s
global_step/sec: 35.6049
loss = 0.43927711248397827, steps = 92200, cost time = 2.81s
global_step/sec: 28.9376
loss = 0.5139078497886658, steps = 92300, cost time = 3.46s
global_step/sec: 28.9738
loss = 0.4510353207588196, steps = 92400, cost time = 3.45s
global_step/sec: 34.6902
loss = 0.46854162216186523, steps = 92500, cost time = 2.88s
global_step/sec: 36.0005
loss = 0.47007301449775696, steps = 92600, cost time = 2.78s
global_step/sec: 33.4822
loss = 0.4400312602519989, steps = 92700, cost time = 2.99s
global_step/sec: 31.9430
loss = 0.5036645531654358, steps = 92800, cost time = 3.13s
global_step/sec: 36.8343
loss = 0.4712793827056885, steps = 92900, cost time = 2.71s
global_step/sec: 29.3896
loss = 0.4677799642086029, steps = 93000, cost time = 3.40s
global_step/sec: 30.3910
loss = 0.4405065178871155, steps = 93100, cost time = 3.29s
global_step/sec: 32.7727
loss = 0.470124751329422, steps = 93200, cost time = 3.05s
global_step/sec: 38.5633
loss = 0.47806012630462646, steps = 93300, cost time = 2.59s
global_step/sec: 38.0373
loss = 0.45054954290390015, steps = 93400, cost time = 2.63s
global_step/sec: 34.7315
loss = 0.45058590173721313, steps = 93500, cost time = 2.88s
global_step/sec: 34.6147
loss = 0.4858708679676056, steps = 93600, cost time = 2.89s
global_step/sec: 35.0775
loss = 0.44247299432754517, steps = 93700, cost time = 2.85s
global_step/sec: 38.4880
loss = 0.3983258903026581, steps = 93800, cost time = 2.60s
global_step/sec: 37.9660
loss = 0.4606854319572449, steps = 93900, cost time = 2.63s
global_step/sec: 41.4754
loss = 0.5020009875297546, steps = 94000, cost time = 2.41s
global_step/sec: 43.6208
loss = 0.45486873388290405, steps = 94100, cost time = 2.29s
global_step/sec: 35.5635
loss = 0.5094534754753113, steps = 94200, cost time = 2.81s
global_step/sec: 44.4219
loss = 0.5133756399154663, steps = 94300, cost time = 2.25s
global_step/sec: 38.3162
loss = 0.47156822681427, steps = 94400, cost time = 2.61s
global_step/sec: 36.4193
loss = 0.48577219247817993, steps = 94500, cost time = 2.75s
global_step/sec: 37.5812
loss = 0.48214659094810486, steps = 94600, cost time = 2.66s
global_step/sec: 32.9510
loss = 0.49173682928085327, steps = 94700, cost time = 3.03s
global_step/sec: 34.0574
loss = 0.4665161669254303, steps = 94800, cost time = 2.94s
global_step/sec: 35.2111
loss = 0.4427223801612854, steps = 94900, cost time = 2.84s
global_step/sec: 34.3513
loss = 0.4879688620567322, steps = 95000, cost time = 2.91s
global_step/sec: 34.3194
loss = 0.4881528615951538, steps = 95100, cost time = 2.91s
global_step/sec: 34.4107
loss = 0.48063409328460693, steps = 95200, cost time = 2.91s
global_step/sec: 35.4888
loss = 0.45416000485420227, steps = 95300, cost time = 2.82s
global_step/sec: 42.6706
loss = 0.48028790950775146, steps = 95400, cost time = 2.34s
global_step/sec: 41.4039
loss = 0.46120646595954895, steps = 95500, cost time = 2.42s
global_step/sec: 38.3255
loss = 0.4389859735965729, steps = 95600, cost time = 2.61s
global_step/sec: 32.6897
loss = 0.45655298233032227, steps = 95700, cost time = 3.06s
global_step/sec: 35.4159
loss = 0.42826202511787415, steps = 95800, cost time = 2.82s
global_step/sec: 39.0644
loss = 0.4446849226951599, steps = 95900, cost time = 2.56s
global_step/sec: 43.3675
loss = 0.44992363452911377, steps = 96000, cost time = 2.31s
global_step/sec: 41.1128
loss = 0.4453248381614685, steps = 96100, cost time = 2.43s
global_step/sec: 40.9235
loss = 0.4408825635910034, steps = 96200, cost time = 2.44s
global_step/sec: 32.6540
loss = 0.4314037263393402, steps = 96300, cost time = 3.06s
global_step/sec: 33.6613
loss = 0.46465107798576355, steps = 96400, cost time = 2.97s
global_step/sec: 34.7824
loss = 0.5004976987838745, steps = 96500, cost time = 2.88s
global_step/sec: 34.0010
loss = 0.4180924594402313, steps = 96600, cost time = 2.94s
global_step/sec: 34.1544
loss = 0.48405203223228455, steps = 96700, cost time = 2.93s
global_step/sec: 37.1216
loss = 0.4374540448188782, steps = 96800, cost time = 2.69s
global_step/sec: 41.2904
loss = 0.43804270029067993, steps = 96900, cost time = 2.42s
global_step/sec: 35.1170
loss = 0.46674400568008423, steps = 97000, cost time = 2.85s
global_step/sec: 33.7194
loss = 0.4523710608482361, steps = 97100, cost time = 2.97s
global_step/sec: 33.1180
loss = 0.42893150448799133, steps = 97200, cost time = 3.02s
global_step/sec: 32.7907
loss = 0.46454861760139465, steps = 97300, cost time = 3.05s
global_step/sec: 37.8406
loss = 0.44071298837661743, steps = 97400, cost time = 2.64s
global_step/sec: 40.1917
loss = 0.49647119641304016, steps = 97500, cost time = 2.49s
global_step/sec: 35.2130
loss = 0.4536007046699524, steps = 97600, cost time = 2.84s
global_step/sec: 34.5584
loss = 0.4377414882183075, steps = 97700, cost time = 2.89s
global_step/sec: 37.3541
loss = 0.4343169927597046, steps = 97800, cost time = 2.68s
global_step/sec: 39.5777
loss = 0.4688263237476349, steps = 97900, cost time = 2.53s
global_step/sec: 42.3015
loss = 0.4748791456222534, steps = 98000, cost time = 2.36s
global_step/sec: 41.2640
loss = 0.4739971160888672, steps = 98100, cost time = 2.42s
global_step/sec: 34.6423
loss = 0.42948290705680847, steps = 98200, cost time = 2.89s
global_step/sec: 40.0620
loss = 0.48988670110702515, steps = 98300, cost time = 2.50s
global_step/sec: 35.2105
loss = 0.46990376710891724, steps = 98400, cost time = 2.84s
global_step/sec: 35.3984
loss = 0.4945017993450165, steps = 98500, cost time = 2.82s
global_step/sec: 35.6649
loss = 0.48014408349990845, steps = 98600, cost time = 2.80s
global_step/sec: 34.7407
loss = 0.4372934103012085, steps = 98700, cost time = 2.88s
global_step/sec: 35.4777
loss = 0.43782204389572144, steps = 98800, cost time = 2.82s
global_step/sec: 35.5715
loss = 0.44625046849250793, steps = 98900, cost time = 2.81s
global_step/sec: 35.0043
loss = 0.42857077717781067, steps = 99000, cost time = 2.86s
global_step/sec: 34.6727
loss = 0.47407838702201843, steps = 99100, cost time = 2.88s
global_step/sec: 37.5821
loss = 0.4575921893119812, steps = 99200, cost time = 2.66s
global_step/sec: 34.3842
loss = 0.503189206123352, steps = 99300, cost time = 2.91s
global_step/sec: 42.6398
loss = 0.4482726454734802, steps = 99400, cost time = 2.35s
global_step/sec: 33.3522
loss = 0.42319172620773315, steps = 99500, cost time = 3.00s
global_step/sec: 39.6385
loss = 0.4268985986709595, steps = 99600, cost time = 2.52s
global_step/sec: 41.2978
loss = 0.44680070877075195, steps = 99700, cost time = 2.42s
global_step/sec: 41.7902
loss = 0.422492653131485, steps = 99800, cost time = 2.39s
global_step/sec: 38.2095
loss = 0.4463544487953186, steps = 99900, cost time = 2.62s
global_step/sec: 35.7683
loss = 0.45514577627182007, steps = 100000, cost time = 2.80s
global_step/sec: 37.1694
loss = 0.471305251121521, steps = 100100, cost time = 2.69s
global_step/sec: 35.9377
loss = 0.4839278757572174, steps = 100200, cost time = 2.78s
global_step/sec: 34.1187
loss = 0.4366823136806488, steps = 100300, cost time = 2.93s
global_step/sec: 34.8775
loss = 0.43388497829437256, steps = 100400, cost time = 2.87s
global_step/sec: 36.7028
loss = 0.469305157661438, steps = 100500, cost time = 2.72s
global_step/sec: 42.7822
loss = 0.5103212594985962, steps = 100600, cost time = 2.34s
global_step/sec: 41.8925
loss = 0.46635866165161133, steps = 100700, cost time = 2.39s
global_step/sec: 44.2925
loss = 0.47459864616394043, steps = 100800, cost time = 2.26s
global_step/sec: 41.9722
loss = 0.48377981781959534, steps = 100900, cost time = 2.38s
global_step/sec: 36.0381
loss = 0.4835166335105896, steps = 101000, cost time = 2.77s
global_step/sec: 39.1870
loss = 0.44606009125709534, steps = 101100, cost time = 2.55s
global_step/sec: 34.4952
loss = 0.4792516827583313, steps = 101200, cost time = 2.90s
global_step/sec: 35.9723
loss = 0.4480311870574951, steps = 101300, cost time = 2.78s
global_step/sec: 37.8466
loss = 0.45902714133262634, steps = 101400, cost time = 2.64s
global_step/sec: 36.2225
loss = 0.47751641273498535, steps = 101500, cost time = 2.76s
global_step/sec: 40.9252
loss = 0.4532342553138733, steps = 101600, cost time = 2.44s
global_step/sec: 47.7912
loss = 0.49302276968955994, steps = 101700, cost time = 2.09s
global_step/sec: 40.0017
loss = 0.4443202018737793, steps = 101800, cost time = 2.50s
global_step/sec: 45.3530
loss = 0.546893298625946, steps = 101900, cost time = 2.20s
global_step/sec: 41.1897
loss = 0.44931328296661377, steps = 102000, cost time = 2.43s
global_step/sec: 43.1030
loss = 0.44954895973205566, steps = 102100, cost time = 2.32s
global_step/sec: 45.8209
loss = 0.430578351020813, steps = 102200, cost time = 2.18s
global_step/sec: 47.5586
loss = 0.45605069398880005, steps = 102300, cost time = 2.10s
global_step/sec: 45.3663
loss = 0.4292108118534088, steps = 102400, cost time = 2.20s
global_step/sec: 44.2671
loss = 0.4719146192073822, steps = 102500, cost time = 2.26s
global_step/sec: 46.5033
loss = 0.4508390426635742, steps = 102600, cost time = 2.15s
global_step/sec: 40.9322
loss = 0.48422104120254517, steps = 102700, cost time = 2.44s
global_step/sec: 36.7715
loss = 0.46859049797058105, steps = 102800, cost time = 2.72s
global_step/sec: 47.6180
loss = 0.44562429189682007, steps = 102900, cost time = 2.10s
global_step/sec: 37.2290
loss = 0.4311195909976959, steps = 103000, cost time = 2.69s
global_step/sec: 36.6046
loss = 0.4523038864135742, steps = 103100, cost time = 2.73s
global_step/sec: 37.5324
loss = 0.4627746641635895, steps = 103200, cost time = 2.66s
global_step/sec: 39.7220
loss = 0.4874073266983032, steps = 103300, cost time = 2.52s
global_step/sec: 44.8573
loss = 0.48045384883880615, steps = 103400, cost time = 2.23s
global_step/sec: 37.5525
loss = 0.45331311225891113, steps = 103500, cost time = 2.66s
global_step/sec: 39.3137
loss = 0.4573803246021271, steps = 103600, cost time = 2.54s
global_step/sec: 43.1722
loss = 0.4617081880569458, steps = 103700, cost time = 2.32s
global_step/sec: 35.6000
loss = 0.42888665199279785, steps = 103800, cost time = 2.81s
global_step/sec: 37.0141
loss = 0.47094064950942993, steps = 103900, cost time = 2.70s
global_step/sec: 36.1240
loss = 0.4371263086795807, steps = 104000, cost time = 2.77s
global_step/sec: 43.9058
loss = 0.46387332677841187, steps = 104100, cost time = 2.28s
global_step/sec: 35.6310
loss = 0.43460890650749207, steps = 104200, cost time = 2.81s
global_step/sec: 32.4216
loss = 0.4591379165649414, steps = 104300, cost time = 3.08s
global_step/sec: 33.8784
loss = 0.4549030065536499, steps = 104400, cost time = 2.95s
global_step/sec: 34.3287
loss = 0.46697941422462463, steps = 104500, cost time = 2.91s
global_step/sec: 37.2960
loss = 0.45013105869293213, steps = 104600, cost time = 2.68s
global_step/sec: 37.1993
loss = 0.4452793002128601, steps = 104700, cost time = 2.69s
global_step/sec: 38.9122
loss = 0.4632047712802887, steps = 104800, cost time = 2.57s
global_step/sec: 39.0658
loss = 0.44129353761672974, steps = 104900, cost time = 2.56s
global_step/sec: 40.8491
loss = 0.42530307173728943, steps = 105000, cost time = 2.45s
global_step/sec: 41.2336
loss = 0.44531163573265076, steps = 105100, cost time = 2.43s
global_step/sec: 40.0659
loss = 0.49124670028686523, steps = 105200, cost time = 2.50s
global_step/sec: 40.4924
loss = 0.46885186433792114, steps = 105300, cost time = 2.47s
global_step/sec: 38.2140
loss = 0.434146910905838, steps = 105400, cost time = 2.62s
global_step/sec: 35.5193
loss = 0.4447299540042877, steps = 105500, cost time = 2.82s
global_step/sec: 34.8454
loss = 0.47640150785446167, steps = 105600, cost time = 2.87s
global_step/sec: 39.3891
loss = 0.42886918783187866, steps = 105700, cost time = 2.54s
global_step/sec: 41.5232
loss = 0.4210548996925354, steps = 105800, cost time = 2.41s
global_step/sec: 39.0197
loss = 0.48941129446029663, steps = 105900, cost time = 2.56s
global_step/sec: 38.4397
loss = 0.4567088484764099, steps = 106000, cost time = 2.60s
global_step/sec: 40.2297
loss = 0.412289559841156, steps = 106100, cost time = 2.49s
global_step/sec: 39.6317
loss = 0.4500907361507416, steps = 106200, cost time = 2.52s
global_step/sec: 38.8649
loss = 0.39211732149124146, steps = 106300, cost time = 2.57s
global_step/sec: 38.4418
loss = 0.4237444996833801, steps = 106400, cost time = 2.60s
global_step/sec: 41.0660
loss = 0.4052577614784241, steps = 106500, cost time = 2.44s
global_step/sec: 37.8011
loss = 0.44775983691215515, steps = 106600, cost time = 2.65s
global_step/sec: 38.8332
loss = 0.4876565933227539, steps = 106700, cost time = 2.58s
global_step/sec: 40.8828
loss = 0.46464911103248596, steps = 106800, cost time = 2.45s
global_step/sec: 40.3201
loss = 0.4936409592628479, steps = 106900, cost time = 2.48s
global_step/sec: 40.5382
loss = 0.5060437917709351, steps = 107000, cost time = 2.47s
global_step/sec: 40.5554
loss = 0.4755287170410156, steps = 107100, cost time = 2.47s
global_step/sec: 38.8992
loss = 0.5362748503684998, steps = 107200, cost time = 2.57s
global_step/sec: 38.6988
loss = 0.41613519191741943, steps = 107300, cost time = 2.58s
global_step/sec: 39.4429
loss = 0.46261847019195557, steps = 107400, cost time = 2.54s
global_step/sec: 40.9158
loss = 0.44860368967056274, steps = 107500, cost time = 2.44s
global_step/sec: 38.6573
loss = 0.4990297257900238, steps = 107600, cost time = 2.59s
global_step/sec: 40.8398
loss = 0.43866297602653503, steps = 107700, cost time = 2.45s
global_step/sec: 38.9329
loss = 0.4391741454601288, steps = 107800, cost time = 2.57s
global_step/sec: 38.3824
loss = 0.4411591589450836, steps = 107900, cost time = 2.61s
global_step/sec: 39.7427
loss = 0.46988898515701294, steps = 108000, cost time = 2.52s
global_step/sec: 40.1471
loss = 0.47721558809280396, steps = 108100, cost time = 2.49s
global_step/sec: 41.5096
loss = 0.44089776277542114, steps = 108200, cost time = 2.41s
global_step/sec: 39.4407
loss = 0.45370712876319885, steps = 108300, cost time = 2.54s
global_step/sec: 40.5832
loss = 0.46430081129074097, steps = 108400, cost time = 2.46s
global_step/sec: 40.3457
loss = 0.4592967629432678, steps = 108500, cost time = 2.48s
global_step/sec: 38.9986
loss = 0.4398376941680908, steps = 108600, cost time = 2.56s
global_step/sec: 39.1648
loss = 0.46255525946617126, steps = 108700, cost time = 2.55s
global_step/sec: 38.7100
loss = 0.44316577911376953, steps = 108800, cost time = 2.58s
global_step/sec: 39.7004
loss = 0.4973309636116028, steps = 108900, cost time = 2.52s
global_step/sec: 40.0322
loss = 0.4278320074081421, steps = 109000, cost time = 2.50s
global_step/sec: 37.5462
loss = 0.41993772983551025, steps = 109100, cost time = 2.66s
global_step/sec: 39.0213
loss = 0.46178138256073, steps = 109200, cost time = 2.56s
global_step/sec: 35.9675
loss = 0.44582822918891907, steps = 109300, cost time = 2.78s
global_step/sec: 41.3617
loss = 0.420621395111084, steps = 109400, cost time = 2.42s
global_step/sec: 40.5850
loss = 0.39922523498535156, steps = 109500, cost time = 2.46s
global_step/sec: 40.6259
loss = 0.45502597093582153, steps = 109600, cost time = 2.46s
global_step/sec: 42.6876
loss = 0.4763129949569702, steps = 109700, cost time = 2.34s
global_step/sec: 40.0114
loss = 0.49482262134552, steps = 109800, cost time = 2.50s
global_step/sec: 39.8897
loss = 0.45359790325164795, steps = 109900, cost time = 2.51s
global_step/sec: 37.8844
loss = 0.49937254190444946, steps = 110000, cost time = 2.64s
global_step/sec: 38.8890
loss = 0.47919732332229614, steps = 110100, cost time = 2.57s
global_step/sec: 40.2797
loss = 0.492814838886261, steps = 110200, cost time = 2.48s
global_step/sec: 38.7503
loss = 0.473710298538208, steps = 110300, cost time = 2.58s
global_step/sec: 38.9973
loss = 0.47580742835998535, steps = 110400, cost time = 2.56s
global_step/sec: 40.0640
loss = 0.46881312131881714, steps = 110500, cost time = 2.50s
global_step/sec: 40.2897
loss = 0.44301605224609375, steps = 110600, cost time = 2.48s
global_step/sec: 39.7761
loss = 0.47210854291915894, steps = 110700, cost time = 2.51s
global_step/sec: 39.2039
loss = 0.48590973019599915, steps = 110800, cost time = 2.55s
global_step/sec: 39.8952
loss = 0.4439416229724884, steps = 110900, cost time = 2.51s
global_step/sec: 37.2707
loss = 0.48168668150901794, steps = 111000, cost time = 2.68s
global_step/sec: 39.8441
loss = 0.4195478558540344, steps = 111100, cost time = 2.51s
global_step/sec: 41.5107
loss = 0.44471973180770874, steps = 111200, cost time = 2.41s
global_step/sec: 41.5196
loss = 0.4248172640800476, steps = 111300, cost time = 2.41s
global_step/sec: 43.2787
loss = 0.47478774189949036, steps = 111400, cost time = 2.31s
global_step/sec: 38.7421
loss = 0.45882928371429443, steps = 111500, cost time = 2.58s
global_step/sec: 41.0148
loss = 0.45708638429641724, steps = 111600, cost time = 2.44s
global_step/sec: 40.4679
loss = 0.46067917346954346, steps = 111700, cost time = 2.47s
global_step/sec: 39.3114
loss = 0.45917370915412903, steps = 111800, cost time = 2.54s
global_step/sec: 38.6238
loss = 0.4383721947669983, steps = 111900, cost time = 2.59s
global_step/sec: 41.2298
loss = 0.46689027547836304, steps = 112000, cost time = 2.43s
global_step/sec: 39.7473
loss = 0.440077006816864, steps = 112100, cost time = 2.52s
global_step/sec: 40.0985
loss = 0.48483768105506897, steps = 112200, cost time = 2.49s
global_step/sec: 39.2668
loss = 0.43257492780685425, steps = 112300, cost time = 2.55s
global_step/sec: 39.3193
loss = 0.45316049456596375, steps = 112400, cost time = 2.54s
global_step/sec: 43.9187
loss = 0.45450106263160706, steps = 112500, cost time = 2.28s
global_step/sec: 40.7741
loss = 0.4356161952018738, steps = 112600, cost time = 2.45s
global_step/sec: 40.4484
loss = 0.44249922037124634, steps = 112700, cost time = 2.47s
global_step/sec: 39.0041
loss = 0.42662423849105835, steps = 112800, cost time = 2.56s
global_step/sec: 41.6078
loss = 0.44751793146133423, steps = 112900, cost time = 2.40s
global_step/sec: 41.6992
loss = 0.443070650100708, steps = 113000, cost time = 2.40s
global_step/sec: 38.6430
loss = 0.45000237226486206, steps = 113100, cost time = 2.59s
global_step/sec: 38.8513
loss = 0.45931798219680786, steps = 113200, cost time = 2.57s
global_step/sec: 39.8370
loss = 0.4736466109752655, steps = 113300, cost time = 2.51s
global_step/sec: 40.5400
loss = 0.47234785556793213, steps = 113400, cost time = 2.47s
global_step/sec: 38.7169
loss = 0.4215874671936035, steps = 113500, cost time = 2.58s
global_step/sec: 40.4591
loss = 0.4846828579902649, steps = 113600, cost time = 2.47s
global_step/sec: 39.2234
loss = 0.4218868613243103, steps = 113700, cost time = 2.55s
global_step/sec: 37.9776
loss = 0.49190908670425415, steps = 113800, cost time = 2.63s
global_step/sec: 37.2373
loss = 0.4739518463611603, steps = 113900, cost time = 2.69s
global_step/sec: 38.3440
loss = 0.40695977210998535, steps = 114000, cost time = 2.61s
global_step/sec: 38.8741
loss = 0.461694598197937, steps = 114100, cost time = 2.57s
global_step/sec: 41.2807
loss = 0.49418553709983826, steps = 114200, cost time = 2.42s
global_step/sec: 37.6231
loss = 0.4182514548301697, steps = 114300, cost time = 2.66s
global_step/sec: 39.4219
loss = 0.4299063980579376, steps = 114400, cost time = 2.54s
global_step/sec: 37.5814
loss = 0.4200766980648041, steps = 114500, cost time = 2.66s
global_step/sec: 39.0285
loss = 0.481285959482193, steps = 114600, cost time = 2.56s
global_step/sec: 40.2834
loss = 0.4461396336555481, steps = 114700, cost time = 2.48s
global_step/sec: 38.2270
loss = 0.44154155254364014, steps = 114800, cost time = 2.62s
global_step/sec: 40.1395
loss = 0.45013663172721863, steps = 114900, cost time = 2.49s
global_step/sec: 39.1955
loss = 0.5048325061798096, steps = 115000, cost time = 2.55s
global_step/sec: 40.2019
loss = 0.4937661588191986, steps = 115100, cost time = 2.49s
global_step/sec: 40.8963
loss = 0.454416424036026, steps = 115200, cost time = 2.45s
global_step/sec: 38.8668
loss = 0.48054003715515137, steps = 115300, cost time = 2.57s
global_step/sec: 39.6821
loss = 0.40976178646087646, steps = 115400, cost time = 2.52s
global_step/sec: 41.3977
loss = 0.4477102756500244, steps = 115500, cost time = 2.42s
global_step/sec: 37.4169
loss = 0.4481281638145447, steps = 115600, cost time = 2.67s
global_step/sec: 40.3930
loss = 0.46339455246925354, steps = 115700, cost time = 2.48s
global_step/sec: 40.7326
loss = 0.46927887201309204, steps = 115800, cost time = 2.46s
global_step/sec: 40.1773
loss = 0.4482675790786743, steps = 115900, cost time = 2.49s
global_step/sec: 39.2571
loss = 0.45799416303634644, steps = 116000, cost time = 2.55s
global_step/sec: 40.0666
loss = 0.4732482433319092, steps = 116100, cost time = 2.50s
global_step/sec: 41.3508
loss = 0.46135082840919495, steps = 116200, cost time = 2.42s
global_step/sec: 41.6282
loss = 0.4726549983024597, steps = 116300, cost time = 2.40s
global_step/sec: 40.9921
loss = 0.4792128801345825, steps = 116400, cost time = 2.44s
global_step/sec: 40.8156
loss = 0.45819544792175293, steps = 116500, cost time = 2.45s
global_step/sec: 40.6397
loss = 0.47442394495010376, steps = 116600, cost time = 2.46s
global_step/sec: 39.1938
loss = 0.45950716733932495, steps = 116700, cost time = 2.55s
global_step/sec: 39.5300
loss = 0.4287678003311157, steps = 116800, cost time = 2.53s
global_step/sec: 39.8325
loss = 0.43874049186706543, steps = 116900, cost time = 2.51s
global_step/sec: 40.2509
loss = 0.44564372301101685, steps = 117000, cost time = 2.48s
global_step/sec: 41.1322
loss = 0.4627315104007721, steps = 117100, cost time = 2.43s
global_step/sec: 41.5121
loss = 0.4024900794029236, steps = 117200, cost time = 2.41s
global_step/sec: 39.0102
loss = 0.4596916735172272, steps = 117300, cost time = 2.56s
global_step/sec: 39.2958
loss = 0.43815693259239197, steps = 117400, cost time = 2.54s
global_step/sec: 38.1709
loss = 0.40859851241111755, steps = 117500, cost time = 2.62s
global_step/sec: 38.6120
loss = 0.4523681402206421, steps = 117600, cost time = 2.59s
global_step/sec: 36.9956
loss = 0.4596087336540222, steps = 117700, cost time = 2.70s
global_step/sec: 38.2321
loss = 0.45942404866218567, steps = 117800, cost time = 2.62s
global_step/sec: 36.8845
loss = 0.4559798836708069, steps = 117900, cost time = 2.71s
global_step/sec: 37.5247
loss = 0.451080858707428, steps = 118000, cost time = 2.66s
global_step/sec: 40.5088
loss = 0.45999932289123535, steps = 118100, cost time = 2.47s
global_step/sec: 40.3195
loss = 0.46268653869628906, steps = 118200, cost time = 2.48s
global_step/sec: 40.1445
loss = 0.43836280703544617, steps = 118300, cost time = 2.49s
global_step/sec: 40.6636
loss = 0.4600984454154968, steps = 118400, cost time = 2.46s
global_step/sec: 39.1389
loss = 0.4474621117115021, steps = 118500, cost time = 2.56s
global_step/sec: 39.7347
loss = 0.4517545998096466, steps = 118600, cost time = 2.52s
global_step/sec: 39.9549
loss = 0.4214886426925659, steps = 118700, cost time = 2.50s
global_step/sec: 40.8708
loss = 0.4236305058002472, steps = 118800, cost time = 2.45s
global_step/sec: 43.8285
loss = 0.42833229899406433, steps = 118900, cost time = 2.28s
global_step/sec: 41.6043
loss = 0.46088874340057373, steps = 119000, cost time = 2.40s
global_step/sec: 41.3081
loss = 0.4533293843269348, steps = 119100, cost time = 2.42s
global_step/sec: 39.0206
loss = 0.4358169138431549, steps = 119200, cost time = 2.56s
global_step/sec: 40.2820
loss = 0.43716996908187866, steps = 119300, cost time = 2.48s
global_step/sec: 41.3457
loss = 0.43335115909576416, steps = 119400, cost time = 2.42s
global_step/sec: 39.4822
loss = 0.41232407093048096, steps = 119500, cost time = 2.53s
global_step/sec: 38.7870
loss = 0.4831588864326477, steps = 119600, cost time = 2.58s
global_step/sec: 33.0559
loss = 0.3923983573913574, steps = 119700, cost time = 3.03s
global_step/sec: 36.7460
loss = 0.48718011379241943, steps = 119800, cost time = 2.72s
global_step/sec: 41.4464
loss = 0.4605534076690674, steps = 119900, cost time = 2.41s
global_step/sec: 39.9570
loss = 0.46634870767593384, steps = 120000, cost time = 2.50s
global_step/sec: 39.7993
loss = 0.42288994789123535, steps = 120100, cost time = 2.51s
global_step/sec: 42.5101
loss = 0.4390103816986084, steps = 120200, cost time = 2.35s
global_step/sec: 39.7134
loss = 0.4623686373233795, steps = 120300, cost time = 2.52s
global_step/sec: 40.7100
loss = 0.4378228187561035, steps = 120400, cost time = 2.46s
global_step/sec: 42.9007
loss = 0.44072848558425903, steps = 120500, cost time = 2.33s
global_step/sec: 39.3966
loss = 0.43112894892692566, steps = 120600, cost time = 2.54s
global_step/sec: 40.6638
loss = 0.47300463914871216, steps = 120700, cost time = 2.46s
global_step/sec: 38.0805
loss = 0.49614977836608887, steps = 120800, cost time = 2.63s
global_step/sec: 41.0703
loss = 0.439473956823349, steps = 120900, cost time = 2.43s
global_step/sec: 40.8006
loss = 0.48212650418281555, steps = 121000, cost time = 2.45s
global_step/sec: 40.7545
loss = 0.451852947473526, steps = 121100, cost time = 2.45s
global_step/sec: 40.7757
loss = 0.4416016638278961, steps = 121200, cost time = 2.45s
global_step/sec: 39.6536
loss = 0.4769674241542816, steps = 121300, cost time = 2.52s
global_step/sec: 36.8787
loss = 0.4462459683418274, steps = 121400, cost time = 2.71s
global_step/sec: 39.5024
loss = 0.47321444749832153, steps = 121500, cost time = 2.53s
global_step/sec: 40.0195
loss = 0.4625452160835266, steps = 121600, cost time = 2.50s
global_step/sec: 38.8525
loss = 0.43565380573272705, steps = 121700, cost time = 2.57s
global_step/sec: 36.8806
loss = 0.4192519187927246, steps = 121800, cost time = 2.71s
global_step/sec: 39.4936
loss = 0.4162445068359375, steps = 121900, cost time = 2.53s
global_step/sec: 41.0917
loss = 0.42997124791145325, steps = 122000, cost time = 2.43s
global_step/sec: 40.3822
loss = 0.40887418389320374, steps = 122100, cost time = 2.48s
global_step/sec: 41.0383
loss = 0.4543212652206421, steps = 122200, cost time = 2.44s
global_step/sec: 41.2163
loss = 0.470185786485672, steps = 122300, cost time = 2.43s
global_step/sec: 39.6930
loss = 0.513593316078186, steps = 122400, cost time = 2.52s
global_step/sec: 41.4741
loss = 0.485828161239624, steps = 122500, cost time = 2.41s
global_step/sec: 39.5966
loss = 0.4976043999195099, steps = 122600, cost time = 2.53s
global_step/sec: 38.7587
loss = 0.49744436144828796, steps = 122700, cost time = 2.58s
global_step/sec: 39.7785
loss = 0.493404746055603, steps = 122800, cost time = 2.51s
global_step/sec: 40.0681
loss = 0.462520033121109, steps = 122900, cost time = 2.50s
global_step/sec: 40.0470
loss = 0.47988903522491455, steps = 123000, cost time = 2.50s
global_step/sec: 41.0388
loss = 0.44936487078666687, steps = 123100, cost time = 2.44s
global_step/sec: 42.1428
loss = 0.48032015562057495, steps = 123200, cost time = 2.37s
global_step/sec: 39.8748
loss = 0.475026398897171, steps = 123300, cost time = 2.51s
global_step/sec: 40.2132
loss = 0.4366842806339264, steps = 123400, cost time = 2.49s
global_step/sec: 41.0222
loss = 0.45103970170021057, steps = 123500, cost time = 2.44s
global_step/sec: 41.9137
loss = 0.4776071012020111, steps = 123600, cost time = 2.39s
global_step/sec: 38.8075
loss = 0.4281480014324188, steps = 123700, cost time = 2.58s
global_step/sec: 41.7559
loss = 0.43728289008140564, steps = 123800, cost time = 2.39s
global_step/sec: 39.9424
loss = 0.4216093420982361, steps = 123900, cost time = 2.50s
global_step/sec: 39.4949
loss = 0.5485703945159912, steps = 124000, cost time = 2.53s
global_step/sec: 38.7689
loss = 0.4471859037876129, steps = 124100, cost time = 2.58s
global_step/sec: 39.5928
loss = 0.49237674474716187, steps = 124200, cost time = 2.53s
global_step/sec: 38.9485
loss = 0.44039422273635864, steps = 124300, cost time = 2.57s
global_step/sec: 36.8881
loss = 0.4513692259788513, steps = 124400, cost time = 2.71s
global_step/sec: 39.5155
loss = 0.4570182263851166, steps = 124500, cost time = 2.53s
global_step/sec: 40.0076
loss = 0.4527783989906311, steps = 124600, cost time = 2.50s
global_step/sec: 42.0532
loss = 0.454056978225708, steps = 124700, cost time = 2.38s
global_step/sec: 39.1373
loss = 0.44862425327301025, steps = 124800, cost time = 2.56s
global_step/sec: 35.2533
loss = 0.4254446029663086, steps = 124900, cost time = 2.84s
global_step/sec: 37.1187
loss = 0.47448766231536865, steps = 125000, cost time = 2.69s
global_step/sec: 38.7780
loss = 0.3981006443500519, steps = 125100, cost time = 2.58s
global_step/sec: 39.8080
loss = 0.4452767074108124, steps = 125200, cost time = 2.51s
global_step/sec: 39.0815
loss = 0.451659619808197, steps = 125300, cost time = 2.56s
global_step/sec: 37.1955
loss = 0.4730181097984314, steps = 125400, cost time = 2.69s
global_step/sec: 38.4556
loss = 0.48894432187080383, steps = 125500, cost time = 2.60s
global_step/sec: 40.8511
loss = 0.4804755747318268, steps = 125600, cost time = 2.45s
global_step/sec: 39.6516
loss = 0.5147861242294312, steps = 125700, cost time = 2.52s
global_step/sec: 39.2300
loss = 0.4753546416759491, steps = 125800, cost time = 2.55s
global_step/sec: 40.8131
loss = 0.4960229694843292, steps = 125900, cost time = 2.45s
global_step/sec: 40.6400
loss = 0.4848577380180359, steps = 126000, cost time = 2.46s
global_step/sec: 40.5934
loss = 0.4707060158252716, steps = 126100, cost time = 2.46s
global_step/sec: 38.9032
loss = 0.496810644865036, steps = 126200, cost time = 2.57s
global_step/sec: 36.2138
loss = 0.4657588005065918, steps = 126300, cost time = 2.76s
global_step/sec: 40.4398
loss = 0.4644804000854492, steps = 126400, cost time = 2.47s
global_step/sec: 40.2375
loss = 0.48591530323028564, steps = 126500, cost time = 2.49s
global_step/sec: 39.8944
loss = 0.4546465277671814, steps = 126600, cost time = 2.51s
global_step/sec: 40.8445
loss = 0.498026579618454, steps = 126700, cost time = 2.45s
global_step/sec: 42.2115
loss = 0.48236316442489624, steps = 126800, cost time = 2.37s
global_step/sec: 42.0427
loss = 0.4268396496772766, steps = 126900, cost time = 2.38s
global_step/sec: 41.1517
loss = 0.4453425109386444, steps = 127000, cost time = 2.43s
global_step/sec: 38.9516
loss = 0.43266987800598145, steps = 127100, cost time = 2.57s
global_step/sec: 38.6579
loss = 0.4803135395050049, steps = 127200, cost time = 2.59s
global_step/sec: 40.5328
loss = 0.46224841475486755, steps = 127300, cost time = 2.47s
global_step/sec: 37.9567
loss = 0.4513970613479614, steps = 127400, cost time = 2.63s
global_step/sec: 35.4707
loss = 0.42363637685775757, steps = 127500, cost time = 2.82s
global_step/sec: 41.9850
loss = 0.46378400921821594, steps = 127600, cost time = 2.38s
global_step/sec: 40.2769
loss = 0.4789726734161377, steps = 127700, cost time = 2.48s
global_step/sec: 39.8234
loss = 0.49487337470054626, steps = 127800, cost time = 2.51s
global_step/sec: 38.1626
loss = 0.416018545627594, steps = 127900, cost time = 2.62s
global_step/sec: 39.4246
loss = 0.48799601197242737, steps = 128000, cost time = 2.54s
global_step/sec: 39.9851
loss = 0.4807946979999542, steps = 128100, cost time = 2.50s
global_step/sec: 39.8322
loss = 0.4240781366825104, steps = 128200, cost time = 2.51s
global_step/sec: 38.5667
loss = 0.4187670052051544, steps = 128300, cost time = 2.59s
global_step/sec: 37.4687
loss = 0.505452036857605, steps = 128400, cost time = 2.67s
global_step/sec: 40.5430
loss = 0.5194462537765503, steps = 128500, cost time = 2.47s
global_step/sec: 42.3919
loss = 0.4170231819152832, steps = 128600, cost time = 2.36s
global_step/sec: 41.3488
loss = 0.44396767020225525, steps = 128700, cost time = 2.42s
global_step/sec: 40.5504
loss = 0.4678649306297302, steps = 128800, cost time = 2.47s
global_step/sec: 40.8989
loss = 0.45983022451400757, steps = 128900, cost time = 2.45s
global_step/sec: 39.7667
loss = 0.46406322717666626, steps = 129000, cost time = 2.51s
global_step/sec: 40.3942
loss = 0.488395631313324, steps = 129100, cost time = 2.48s
global_step/sec: 37.6841
loss = 0.45054155588150024, steps = 129200, cost time = 2.65s
global_step/sec: 37.5308
loss = 0.423589825630188, steps = 129300, cost time = 2.66s
global_step/sec: 39.4592
loss = 0.48207104206085205, steps = 129400, cost time = 2.53s
global_step/sec: 38.3333
loss = 0.5022435784339905, steps = 129500, cost time = 2.61s
global_step/sec: 39.8193
loss = 0.4150359034538269, steps = 129600, cost time = 2.51s
global_step/sec: 39.8075
loss = 0.4785917401313782, steps = 129700, cost time = 2.51s
global_step/sec: 40.9366
loss = 0.45427948236465454, steps = 129800, cost time = 2.44s
global_step/sec: 36.9052
loss = 0.4454888105392456, steps = 129900, cost time = 2.71s
global_step/sec: 41.3580
loss = 0.43941861391067505, steps = 130000, cost time = 2.42s
global_step/sec: 39.3271
loss = 0.4747876524925232, steps = 130100, cost time = 2.54s
global_step/sec: 38.2201
loss = 0.42061710357666016, steps = 130200, cost time = 2.62s
global_step/sec: 41.7210
loss = 0.464297890663147, steps = 130300, cost time = 2.40s
global_step/sec: 42.8034
loss = 0.475661963224411, steps = 130400, cost time = 2.34s
global_step/sec: 40.8324
loss = 0.44090214371681213, steps = 130500, cost time = 2.45s
global_step/sec: 42.0352
loss = 0.48548996448516846, steps = 130600, cost time = 2.38s
global_step/sec: 39.0374
loss = 0.4693223536014557, steps = 130700, cost time = 2.56s
global_step/sec: 40.2232
loss = 0.41948050260543823, steps = 130800, cost time = 2.49s
global_step/sec: 39.8311
loss = 0.5095301866531372, steps = 130900, cost time = 2.51s
global_step/sec: 38.6887
loss = 0.4381539225578308, steps = 131000, cost time = 2.58s
global_step/sec: 39.5944
loss = 0.5019823908805847, steps = 131100, cost time = 2.53s
global_step/sec: 40.1109
loss = 0.48417454957962036, steps = 131200, cost time = 2.49s
global_step/sec: 39.5804
loss = 0.4534437954425812, steps = 131300, cost time = 2.53s
global_step/sec: 40.5726
loss = 0.5110149383544922, steps = 131400, cost time = 2.46s
global_step/sec: 39.3714
loss = 0.4272499978542328, steps = 131500, cost time = 2.54s
global_step/sec: 38.2467
loss = 0.4585604667663574, steps = 131600, cost time = 2.61s
global_step/sec: 38.5244
loss = 0.4458315968513489, steps = 131700, cost time = 2.60s
global_step/sec: 38.6499
loss = 0.4643126130104065, steps = 131800, cost time = 2.59s
global_step/sec: 38.7462
loss = 0.4500407874584198, steps = 131900, cost time = 2.58s
global_step/sec: 38.5487
loss = 0.4753294587135315, steps = 132000, cost time = 2.59s
global_step/sec: 38.4386
loss = 0.4333590865135193, steps = 132100, cost time = 2.60s
global_step/sec: 38.3669
loss = 0.49081850051879883, steps = 132200, cost time = 2.61s
global_step/sec: 38.6944
loss = 0.4560697674751282, steps = 132300, cost time = 2.58s
global_step/sec: 39.0062
loss = 0.45759546756744385, steps = 132400, cost time = 2.56s
global_step/sec: 38.4339
loss = 0.4393187165260315, steps = 132500, cost time = 2.60s
global_step/sec: 37.9982
loss = 0.4614226222038269, steps = 132600, cost time = 2.63s
global_step/sec: 37.8388
loss = 0.4171195924282074, steps = 132700, cost time = 2.64s
global_step/sec: 37.7486
loss = 0.46060651540756226, steps = 132800, cost time = 2.65s
global_step/sec: 38.9523
loss = 0.46310192346572876, steps = 132900, cost time = 2.57s
global_step/sec: 38.9057
loss = 0.45884767174720764, steps = 133000, cost time = 2.57s
global_step/sec: 39.6313
loss = 0.45987170934677124, steps = 133100, cost time = 2.52s
global_step/sec: 39.7016
loss = 0.47373971343040466, steps = 133200, cost time = 2.52s
global_step/sec: 39.2129
loss = 0.457241415977478, steps = 133300, cost time = 2.55s
global_step/sec: 39.6236
loss = 0.4627722501754761, steps = 133400, cost time = 2.52s
global_step/sec: 40.0675
loss = 0.4574078321456909, steps = 133500, cost time = 2.50s
global_step/sec: 39.7327
loss = 0.4514232277870178, steps = 133600, cost time = 2.52s
global_step/sec: 39.2481
loss = 0.43518513441085815, steps = 133700, cost time = 2.55s
global_step/sec: 39.4296
loss = 0.4269947409629822, steps = 133800, cost time = 2.54s
global_step/sec: 39.7288
loss = 0.45174211263656616, steps = 133900, cost time = 2.52s
global_step/sec: 39.3656
loss = 0.4489382207393646, steps = 134000, cost time = 2.54s
global_step/sec: 39.6823
loss = 0.46722304821014404, steps = 134100, cost time = 2.52s
global_step/sec: 39.1829
loss = 0.4295969009399414, steps = 134200, cost time = 2.55s
global_step/sec: 39.8088
loss = 0.5201020240783691, steps = 134300, cost time = 2.51s
global_step/sec: 39.9259
loss = 0.4547499716281891, steps = 134400, cost time = 2.50s
global_step/sec: 40.2299
loss = 0.4315229654312134, steps = 134500, cost time = 2.49s
global_step/sec: 39.9620
loss = 0.4399726986885071, steps = 134600, cost time = 2.50s
global_step/sec: 39.8199
loss = 0.42667627334594727, steps = 134700, cost time = 2.51s
global_step/sec: 39.6326
loss = 0.4823004901409149, steps = 134800, cost time = 2.52s
global_step/sec: 39.9969
loss = 0.46999603509902954, steps = 134900, cost time = 2.50s
global_step/sec: 39.6775
loss = 0.46190744638442993, steps = 135000, cost time = 2.52s
global_step/sec: 39.7174
loss = 0.46453115344047546, steps = 135100, cost time = 2.52s
global_step/sec: 39.6190
loss = 0.4449790120124817, steps = 135200, cost time = 2.52s
global_step/sec: 39.8014
loss = 0.4633537232875824, steps = 135300, cost time = 2.51s
global_step/sec: 39.2473
loss = 0.4560580849647522, steps = 135400, cost time = 2.55s
global_step/sec: 39.2128
loss = 0.4491972327232361, steps = 135500, cost time = 2.55s
global_step/sec: 39.0259
loss = 0.4720419645309448, steps = 135600, cost time = 2.56s
global_step/sec: 40.4081
loss = 0.47564348578453064, steps = 135700, cost time = 2.47s
global_step/sec: 39.8382
loss = 0.47033941745758057, steps = 135800, cost time = 2.51s
global_step/sec: 39.5462
loss = 0.49191486835479736, steps = 135900, cost time = 2.53s
global_step/sec: 39.7941
loss = 0.4245679974555969, steps = 136000, cost time = 2.51s
global_step/sec: 39.6511
loss = 0.4733922481536865, steps = 136100, cost time = 2.52s
global_step/sec: 39.3067
loss = 0.45943212509155273, steps = 136200, cost time = 2.54s
global_step/sec: 40.1418
loss = 0.4371747672557831, steps = 136300, cost time = 2.49s
global_step/sec: 39.5270
loss = 0.44657349586486816, steps = 136400, cost time = 2.53s
global_step/sec: 39.9824
loss = 0.45004957914352417, steps = 136500, cost time = 2.50s
global_step/sec: 39.9402
loss = 0.45251333713531494, steps = 136600, cost time = 2.50s
global_step/sec: 40.0012
loss = 0.46294689178466797, steps = 136700, cost time = 2.50s
global_step/sec: 39.9216
loss = 0.3993590176105499, steps = 136800, cost time = 2.50s
global_step/sec: 39.8592
loss = 0.43567317724227905, steps = 136900, cost time = 2.51s
global_step/sec: 39.7973
loss = 0.4527628421783447, steps = 137000, cost time = 2.51s
global_step/sec: 40.0631
loss = 0.44369107484817505, steps = 137100, cost time = 2.50s
global_step/sec: 39.5348
loss = 0.4285494089126587, steps = 137200, cost time = 2.53s
global_step/sec: 39.2377
loss = 0.4719480276107788, steps = 137300, cost time = 2.55s
global_step/sec: 39.2813
loss = 0.42229482531547546, steps = 137400, cost time = 2.55s
global_step/sec: 38.8172
loss = 0.43706315755844116, steps = 137500, cost time = 2.58s
global_step/sec: 39.6025
loss = 0.4849618673324585, steps = 137600, cost time = 2.53s
global_step/sec: 39.6945
loss = 0.40071961283683777, steps = 137700, cost time = 2.52s
global_step/sec: 39.5728
loss = 0.40453463792800903, steps = 137800, cost time = 2.53s
global_step/sec: 39.4350
loss = 0.4734421372413635, steps = 137900, cost time = 2.54s
global_step/sec: 40.1029
loss = 0.51140296459198, steps = 138000, cost time = 2.49s
global_step/sec: 40.1375
loss = 0.46804580092430115, steps = 138100, cost time = 2.49s
global_step/sec: 39.7418
loss = 0.4636691212654114, steps = 138200, cost time = 2.52s
global_step/sec: 39.5681
loss = 0.47826844453811646, steps = 138300, cost time = 2.53s
global_step/sec: 39.3168
loss = 0.533645510673523, steps = 138400, cost time = 2.54s
global_step/sec: 39.0832
loss = 0.4334154725074768, steps = 138500, cost time = 2.56s
global_step/sec: 39.6882
loss = 0.47633302211761475, steps = 138600, cost time = 2.52s
global_step/sec: 39.9552
loss = 0.4774816036224365, steps = 138700, cost time = 2.50s
global_step/sec: 39.6983
loss = 0.4693586826324463, steps = 138800, cost time = 2.52s
global_step/sec: 39.2281
loss = 0.44291073083877563, steps = 138900, cost time = 2.55s
global_step/sec: 39.3969
loss = 0.47953277826309204, steps = 139000, cost time = 2.54s
global_step/sec: 38.7581
loss = 0.44663894176483154, steps = 139100, cost time = 2.58s
global_step/sec: 39.2808
loss = 0.4401510953903198, steps = 139200, cost time = 2.55s
global_step/sec: 39.2693
loss = 0.463510662317276, steps = 139300, cost time = 2.55s
global_step/sec: 39.2312
loss = 0.47697576880455017, steps = 139400, cost time = 2.55s
global_step/sec: 39.4777
loss = 0.45712947845458984, steps = 139500, cost time = 2.53s
global_step/sec: 40.0075
loss = 0.4491546154022217, steps = 139600, cost time = 2.50s
global_step/sec: 39.0175
loss = 0.46448278427124023, steps = 139700, cost time = 2.56s
global_step/sec: 39.1337
loss = 0.4520891308784485, steps = 139800, cost time = 2.56s
global_step/sec: 39.1306
loss = 0.4213675856590271, steps = 139900, cost time = 2.56s
global_step/sec: 39.0750
loss = 0.4884219765663147, steps = 140000, cost time = 2.56s
global_step/sec: 38.7408
loss = 0.450353741645813, steps = 140100, cost time = 2.58s
global_step/sec: 39.9470
loss = 0.44139745831489563, steps = 140200, cost time = 2.50s
global_step/sec: 39.3511
loss = 0.43944185972213745, steps = 140300, cost time = 2.54s
global_step/sec: 39.3575
loss = 0.4529425799846649, steps = 140400, cost time = 2.54s
global_step/sec: 39.3209
loss = 0.4655458629131317, steps = 140500, cost time = 2.54s
global_step/sec: 39.0683
loss = 0.438111275434494, steps = 140600, cost time = 2.56s
global_step/sec: 39.7590
loss = 0.39406588673591614, steps = 140700, cost time = 2.52s
global_step/sec: 39.5323
loss = 0.42367082834243774, steps = 140800, cost time = 2.53s
global_step/sec: 39.7744
loss = 0.4649266302585602, steps = 140900, cost time = 2.51s
global_step/sec: 39.7933
loss = 0.47640442848205566, steps = 141000, cost time = 2.51s
global_step/sec: 39.7989
loss = 0.4689323306083679, steps = 141100, cost time = 2.51s
global_step/sec: 40.1584
loss = 0.443644642829895, steps = 141200, cost time = 2.49s
global_step/sec: 40.2076
loss = 0.4658892750740051, steps = 141300, cost time = 2.49s
global_step/sec: 39.1493
loss = 0.5060443878173828, steps = 141400, cost time = 2.55s
global_step/sec: 39.9474
loss = 0.4825209081172943, steps = 141500, cost time = 2.50s
global_step/sec: 39.6842
loss = 0.4676945209503174, steps = 141600, cost time = 2.52s
global_step/sec: 39.4504
loss = 0.46923214197158813, steps = 141700, cost time = 2.53s
global_step/sec: 39.6979
loss = 0.4536774754524231, steps = 141800, cost time = 2.52s
global_step/sec: 39.4456
loss = 0.4387128949165344, steps = 141900, cost time = 2.54s
global_step/sec: 39.2772
loss = 0.47423556447029114, steps = 142000, cost time = 2.55s
global_step/sec: 39.8080
loss = 0.4857287108898163, steps = 142100, cost time = 2.51s
global_step/sec: 39.9221
loss = 0.4262564182281494, steps = 142200, cost time = 2.50s
global_step/sec: 39.8681
loss = 0.4475734531879425, steps = 142300, cost time = 2.51s
global_step/sec: 39.7472
loss = 0.43552011251449585, steps = 142400, cost time = 2.52s
global_step/sec: 39.8644
loss = 0.40542614459991455, steps = 142500, cost time = 2.51s
global_step/sec: 40.4124
loss = 0.4384585916996002, steps = 142600, cost time = 2.47s
global_step/sec: 40.5861
loss = 0.4090711176395416, steps = 142700, cost time = 2.46s
global_step/sec: 39.9090
loss = 0.49086934328079224, steps = 142800, cost time = 2.51s
global_step/sec: 40.5010
loss = 0.46544554829597473, steps = 142900, cost time = 2.47s
global_step/sec: 40.6200
loss = 0.4374833106994629, steps = 143000, cost time = 2.46s
global_step/sec: 40.3269
loss = 0.4825889766216278, steps = 143100, cost time = 2.48s
global_step/sec: 39.9990
loss = 0.45429831743240356, steps = 143200, cost time = 2.50s
global_step/sec: 40.3948
loss = 0.43606218695640564, steps = 143300, cost time = 2.48s
global_step/sec: 40.0443
loss = 0.45208197832107544, steps = 143400, cost time = 2.50s
global_step/sec: 40.2508
loss = 0.4574517011642456, steps = 143500, cost time = 2.48s
global_step/sec: 39.8798
loss = 0.4479038715362549, steps = 143600, cost time = 2.51s
global_step/sec: 40.0173
loss = 0.3959062099456787, steps = 143700, cost time = 2.50s
global_step/sec: 40.1509
loss = 0.4801691174507141, steps = 143800, cost time = 2.49s
global_step/sec: 39.7555
loss = 0.4079563021659851, steps = 143900, cost time = 2.52s
global_step/sec: 39.9993
loss = 0.4353020489215851, steps = 144000, cost time = 2.50s
global_step/sec: 39.3877
loss = 0.4620358347892761, steps = 144100, cost time = 2.54s
global_step/sec: 39.3984
loss = 0.47026532888412476, steps = 144200, cost time = 2.54s
global_step/sec: 40.3830
loss = 0.47998106479644775, steps = 144300, cost time = 2.48s
global_step/sec: 39.8989
loss = 0.40655839443206787, steps = 144400, cost time = 2.51s
global_step/sec: 40.1104
loss = 0.46060657501220703, steps = 144500, cost time = 2.49s
global_step/sec: 39.8367
loss = 0.4636496901512146, steps = 144600, cost time = 2.51s
global_step/sec: 40.3398
loss = 0.4272410273551941, steps = 144700, cost time = 2.48s
global_step/sec: 39.7054
loss = 0.47660624980926514, steps = 144800, cost time = 2.52s
global_step/sec: 39.9220
loss = 0.41730964183807373, steps = 144900, cost time = 2.50s
global_step/sec: 39.8719
loss = 0.4563484191894531, steps = 145000, cost time = 2.51s
global_step/sec: 39.6495
loss = 0.42911672592163086, steps = 145100, cost time = 2.52s
global_step/sec: 39.6073
loss = 0.42401736974716187, steps = 145200, cost time = 2.52s
global_step/sec: 39.9379
loss = 0.43856537342071533, steps = 145300, cost time = 2.50s
global_step/sec: 39.4586
loss = 0.43049436807632446, steps = 145400, cost time = 2.53s
global_step/sec: 39.8596
loss = 0.45314791798591614, steps = 145500, cost time = 2.51s
global_step/sec: 40.5311
loss = 0.47240591049194336, steps = 145600, cost time = 2.47s
global_step/sec: 40.3837
loss = 0.45205026865005493, steps = 145700, cost time = 2.48s
global_step/sec: 39.8436
loss = 0.42645174264907837, steps = 145800, cost time = 2.51s
global_step/sec: 39.6498
loss = 0.4649493396282196, steps = 145900, cost time = 2.52s
global_step/sec: 40.3159
loss = 0.44541335105895996, steps = 146000, cost time = 2.48s
global_step/sec: 39.8406
loss = 0.43782442808151245, steps = 146100, cost time = 2.51s
global_step/sec: 40.1109
loss = 0.43800342082977295, steps = 146200, cost time = 2.49s
global_step/sec: 39.4293
loss = 0.46659454703330994, steps = 146300, cost time = 2.54s
global_step/sec: 39.3137
loss = 0.453365683555603, steps = 146400, cost time = 2.54s
global_step/sec: 39.5066
loss = 0.4684426188468933, steps = 146500, cost time = 2.53s
global_step/sec: 39.5301
loss = 0.42660754919052124, steps = 146600, cost time = 2.53s
global_step/sec: 40.1437
loss = 0.44994163513183594, steps = 146700, cost time = 2.49s
global_step/sec: 39.5672
loss = 0.46708112955093384, steps = 146800, cost time = 2.53s
global_step/sec: 39.8650
loss = 0.44782617688179016, steps = 146900, cost time = 2.51s
global_step/sec: 39.9991
loss = 0.41593700647354126, steps = 147000, cost time = 2.50s
global_step/sec: 39.7349
loss = 0.4131971001625061, steps = 147100, cost time = 2.52s
global_step/sec: 39.9232
loss = 0.40967071056365967, steps = 147200, cost time = 2.50s
global_step/sec: 39.7701
loss = 0.4478643536567688, steps = 147300, cost time = 2.51s
global_step/sec: 39.5184
loss = 0.45262065529823303, steps = 147400, cost time = 2.53s
global_step/sec: 40.0500
loss = 0.48009464144706726, steps = 147500, cost time = 2.50s
global_step/sec: 39.9976
loss = 0.4915219247341156, steps = 147600, cost time = 2.50s
global_step/sec: 40.7255
loss = 0.4538297951221466, steps = 147700, cost time = 2.46s
global_step/sec: 40.1764
loss = 0.47974658012390137, steps = 147800, cost time = 2.49s
global_step/sec: 40.3522
loss = 0.4547872543334961, steps = 147900, cost time = 2.48s
global_step/sec: 40.2592
loss = 0.4577135145664215, steps = 148000, cost time = 2.48s
global_step/sec: 39.9057
loss = 0.44803065061569214, steps = 148100, cost time = 2.51s
global_step/sec: 39.6088
loss = 0.43457576632499695, steps = 148200, cost time = 2.52s
global_step/sec: 39.8571
loss = 0.47597742080688477, steps = 148300, cost time = 2.51s
global_step/sec: 40.2459
loss = 0.45880866050720215, steps = 148400, cost time = 2.48s
global_step/sec: 39.9313
loss = 0.43408751487731934, steps = 148500, cost time = 2.50s
global_step/sec: 40.0506
loss = 0.4635745584964752, steps = 148600, cost time = 2.50s
global_step/sec: 39.9074
loss = 0.45446598529815674, steps = 148700, cost time = 2.51s
global_step/sec: 40.2599
loss = 0.4157143235206604, steps = 148800, cost time = 2.48s
global_step/sec: 40.0632
loss = 0.4461436867713928, steps = 148900, cost time = 2.50s
global_step/sec: 40.0125
loss = 0.46196457743644714, steps = 149000, cost time = 2.50s
global_step/sec: 39.6309
loss = 0.4519510269165039, steps = 149100, cost time = 2.52s
global_step/sec: 39.6040
loss = 0.4408023953437805, steps = 149200, cost time = 2.52s
global_step/sec: 39.4864
loss = 0.45972779393196106, steps = 149300, cost time = 2.53s
global_step/sec: 39.7879
loss = 0.4883905053138733, steps = 149400, cost time = 2.51s
global_step/sec: 39.3038
loss = 0.45344799757003784, steps = 149500, cost time = 2.54s
global_step/sec: 39.6932
loss = 0.5272088050842285, steps = 149600, cost time = 2.52s
global_step/sec: 39.3392
loss = 0.46007874608039856, steps = 149700, cost time = 2.54s
global_step/sec: 39.6403
loss = 0.4589134156703949, steps = 149800, cost time = 2.52s
global_step/sec: 39.6475
loss = 0.4254615902900696, steps = 149900, cost time = 2.52s
global_step/sec: 39.6035
loss = 0.4759477972984314, steps = 150000, cost time = 2.53s
global_step/sec: 39.3556
loss = 0.4468036890029907, steps = 150100, cost time = 2.54s
global_step/sec: 39.1221
loss = 0.44777441024780273, steps = 150200, cost time = 2.56s
global_step/sec: 40.1764
loss = 0.4612644910812378, steps = 150300, cost time = 2.49s
global_step/sec: 39.8437
loss = 0.49002698063850403, steps = 150400, cost time = 2.51s
global_step/sec: 39.9662
loss = 0.45187467336654663, steps = 150500, cost time = 2.50s
global_step/sec: 40.1644
loss = 0.4588848948478699, steps = 150600, cost time = 2.49s
global_step/sec: 39.5344
loss = 0.43245673179626465, steps = 150700, cost time = 2.53s
global_step/sec: 39.8676
loss = 0.46244433522224426, steps = 150800, cost time = 2.51s
global_step/sec: 39.8028
loss = 0.47154489159584045, steps = 150900, cost time = 2.51s
global_step/sec: 39.0652
loss = 0.4305189847946167, steps = 151000, cost time = 2.56s
global_step/sec: 39.9773
loss = 0.4580346643924713, steps = 151100, cost time = 2.50s
global_step/sec: 39.8025
loss = 0.4588939845561981, steps = 151200, cost time = 2.51s
global_step/sec: 39.9977
loss = 0.47970980405807495, steps = 151300, cost time = 2.50s
global_step/sec: 39.6215
loss = 0.4565632939338684, steps = 151400, cost time = 2.52s
global_step/sec: 39.8186
loss = 0.41445180773735046, steps = 151500, cost time = 2.51s
global_step/sec: 40.0575
loss = 0.4376828074455261, steps = 151600, cost time = 2.50s
global_step/sec: 40.0726
loss = 0.4425731599330902, steps = 151700, cost time = 2.50s
global_step/sec: 40.0792
loss = 0.45711129903793335, steps = 151800, cost time = 2.50s
global_step/sec: 39.6194
loss = 0.44733506441116333, steps = 151900, cost time = 2.52s
global_step/sec: 39.8619
loss = 0.43197327852249146, steps = 152000, cost time = 2.51s
global_step/sec: 39.8175
loss = 0.46786797046661377, steps = 152100, cost time = 2.51s
global_step/sec: 40.1286
loss = 0.48216572403907776, steps = 152200, cost time = 2.49s
global_step/sec: 39.1370
loss = 0.458437442779541, steps = 152300, cost time = 2.56s
global_step/sec: 39.6329
loss = 0.3932328522205353, steps = 152400, cost time = 2.52s
global_step/sec: 38.8302
loss = 0.4895820617675781, steps = 152500, cost time = 2.58s
global_step/sec: 39.3872
loss = 0.46850138902664185, steps = 152600, cost time = 2.54s
global_step/sec: 39.7415
loss = 0.4554014205932617, steps = 152700, cost time = 2.52s
global_step/sec: 39.8829
loss = 0.46454358100891113, steps = 152800, cost time = 2.51s
global_step/sec: 39.7299
loss = 0.43237754702568054, steps = 152900, cost time = 2.52s
global_step/sec: 39.7064
loss = 0.437435507774353, steps = 153000, cost time = 2.52s
global_step/sec: 39.5865
loss = 0.44515854120254517, steps = 153100, cost time = 2.53s
global_step/sec: 39.5318
loss = 0.464792937040329, steps = 153200, cost time = 2.53s
global_step/sec: 39.9947
loss = 0.42774638533592224, steps = 153300, cost time = 2.50s
global_step/sec: 39.6375
loss = 0.4042247533798218, steps = 153400, cost time = 2.52s
global_step/sec: 39.1940
loss = 0.4265685975551605, steps = 153500, cost time = 2.55s
global_step/sec: 39.9794
loss = 0.4521995484828949, steps = 153600, cost time = 2.50s
global_step/sec: 39.7278
loss = 0.501176118850708, steps = 153700, cost time = 2.52s
global_step/sec: 39.4162
loss = 0.4899585247039795, steps = 153800, cost time = 2.54s
global_step/sec: 39.7066
loss = 0.46332859992980957, steps = 153900, cost time = 2.52s
global_step/sec: 40.4603
loss = 0.47737064957618713, steps = 154000, cost time = 2.47s
global_step/sec: 39.5371
loss = 0.47074294090270996, steps = 154100, cost time = 2.53s
global_step/sec: 39.2828
loss = 0.4782690405845642, steps = 154200, cost time = 2.55s
global_step/sec: 39.5746
loss = 0.4980471134185791, steps = 154300, cost time = 2.53s
global_step/sec: 39.8201
loss = 0.46398842334747314, steps = 154400, cost time = 2.51s
global_step/sec: 39.9117
loss = 0.45216837525367737, steps = 154500, cost time = 2.51s
global_step/sec: 40.1222
loss = 0.4686751067638397, steps = 154600, cost time = 2.49s
global_step/sec: 39.7064
loss = 0.4357151985168457, steps = 154700, cost time = 2.52s
global_step/sec: 39.5831
loss = 0.43036311864852905, steps = 154800, cost time = 2.53s
global_step/sec: 40.0913
loss = 0.44823747873306274, steps = 154900, cost time = 2.49s
global_step/sec: 39.5291
loss = 0.4624069929122925, steps = 155000, cost time = 2.53s
global_step/sec: 39.7717
loss = 0.44365382194519043, steps = 155100, cost time = 2.51s
global_step/sec: 39.7798
loss = 0.5027013421058655, steps = 155200, cost time = 2.51s
global_step/sec: 39.7133
loss = 0.45378929376602173, steps = 155300, cost time = 2.52s
global_step/sec: 39.1600
loss = 0.4533812999725342, steps = 155400, cost time = 2.55s
global_step/sec: 39.7709
loss = 0.43794673681259155, steps = 155500, cost time = 2.51s
global_step/sec: 39.8896
loss = 0.40515634417533875, steps = 155600, cost time = 2.51s
global_step/sec: 39.8594
loss = 0.4735485017299652, steps = 155700, cost time = 2.51s
global_step/sec: 39.9336
loss = 0.40645894408226013, steps = 155800, cost time = 2.50s
global_step/sec: 39.5772
loss = 0.44873613119125366, steps = 155900, cost time = 2.53s
global_step/sec: 39.4580
loss = 0.4573192298412323, steps = 156000, cost time = 2.53s
global_step/sec: 39.3775
loss = 0.47510743141174316, steps = 156100, cost time = 2.54s
global_step/sec: 39.6639
loss = 0.40230152010917664, steps = 156200, cost time = 2.52s
global_step/sec: 124278.8701
loss = 0.47200191020965576, steps = 156249, cost time = 1.26s
Evaluation complate:[1000/3907]
Evaluation complate:[2000/3907]
Evaluation complate:[3000/3907]
Evaluation complate:[3907/3907]
ACC = 0.779203474521637
AUC = 0.7751824259757996
