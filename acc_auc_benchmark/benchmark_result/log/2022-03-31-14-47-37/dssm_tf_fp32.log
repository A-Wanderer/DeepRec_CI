WARNING:tensorflow:From train.py:14: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

WARNING:tensorflow:From train.py:14: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

WARNING:tensorflow:From train.py:453: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

INFO:tensorflow:Parsing ./data/taobao_train_data
INFO:tensorflow:Parsing ./data/taobao_test_data
WARNING:tensorflow:From train.py:466: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.

WARNING:tensorflow:From train.py:466: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_types(dataset)`.
WARNING:tensorflow:From train.py:467: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(dataset)`.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:347: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_types(iterator)`.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:348: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(iterator)`.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:350: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_classes(iterator)`.
WARNING:tensorflow:From train.py:261: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From train.py:263: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.

WARNING:tensorflow:From train.py:264: The name tf.feature_column.input_layer is deprecated. Please use tf.compat.v1.feature_column.input_layer instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column.py:206: EmbeddingColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:3182: HashedCategoricalColumn._get_sparse_tensors (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column.py:2158: HashedCategoricalColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:3122: HashedCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column.py:207: EmbeddingColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From train.py:239: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.Dense instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From train.py:243: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).
WARNING:tensorflow:From train.py:128: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From train.py:130: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

WARNING:tensorflow:From train.py:302: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
WARNING:tensorflow:From train.py:304: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From train.py:325: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.

WARNING:tensorflow:From train.py:329: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.

WARNING:tensorflow:From train.py:336: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From train.py:340: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

WARNING:tensorflow:From train.py:340: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

WARNING:tensorflow:From train.py:218: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.

WARNING:tensorflow:From train.py:221: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From train.py:493: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From train.py:526: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2022-03-31 09:49:03.433427: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2022-03-31 09:49:03.477811: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3400000000 Hz
2022-03-31 09:49:03.505802: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5761110 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-03-31 09:49:03.505866: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From train.py:527: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From train.py:528: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.

WARNING:tensorflow:From train.py:529: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

WARNING:tensorflow:From train.py:530: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From train.py:531: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From train.py:531: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From train.py:533: The name tf.RunOptions is deprecated. Please use tf.compat.v1.RunOptions instead.

WARNING:tensorflow:From train.py:534: The name tf.RunMetadata is deprecated. Please use tf.compat.v1.RunMetadata instead.

Using TensorFlow version 1.15.5
Checking dataset
Numbers of training dataset is 50000
Numbers of test dataset is 10000
Saving model checkpoints to /benchmark_result/checkpoint/2022-03-31-14-47-37/dssm_tf_fp32
global_step/sec: 39.9551
loss = 1914.4495849609375, steps = 0, cost time = 2.50s
global_step/sec: 13.7642
loss = 1209.7977294921875, steps = 100, cost time = 7.27s
global_step/sec: 13.9637
loss = 1090.562744140625, steps = 200, cost time = 7.16s
global_step/sec: 15.6172
loss = 1215.529541015625, steps = 300, cost time = 6.40s
global_step/sec: 15.8520
loss = 992.3623657226562, steps = 400, cost time = 6.31s
global_step/sec: 15.0591
loss = 1267.626708984375, steps = 500, cost time = 6.64s
global_step/sec: 13.5360
loss = 1117.842529296875, steps = 600, cost time = 7.39s
global_step/sec: 11.1727
loss = 965.70849609375, steps = 700, cost time = 8.95s
global_step/sec: 13.4408
loss = 1185.270751953125, steps = 800, cost time = 7.44s
global_step/sec: 15.8976
loss = 1190.9232177734375, steps = 900, cost time = 6.29s
global_step/sec: 13.9926
loss = 1101.32421875, steps = 1000, cost time = 7.15s
global_step/sec: 14.4491
loss = 1196.32177734375, steps = 1100, cost time = 6.92s
global_step/sec: 14.1349
loss = 1260.17431640625, steps = 1200, cost time = 7.07s
global_step/sec: 13.9073
loss = 1093.915283203125, steps = 1300, cost time = 7.19s
global_step/sec: 14.8164
loss = 986.9241333007812, steps = 1400, cost time = 6.75s
global_step/sec: 14.4941
loss = 1220.89013671875, steps = 1500, cost time = 6.90s
global_step/sec: 14.4870
loss = 1246.417236328125, steps = 1600, cost time = 6.90s
global_step/sec: 14.1353
loss = 1175.7803955078125, steps = 1700, cost time = 7.07s
global_step/sec: 14.8502
loss = 1011.3657836914062, steps = 1800, cost time = 6.73s
global_step/sec: 15.1699
loss = 1278.292724609375, steps = 1900, cost time = 6.59s
global_step/sec: 14.4172
loss = 1156.33056640625, steps = 2000, cost time = 6.94s
global_step/sec: 13.4625
loss = 1323.383544921875, steps = 2100, cost time = 7.43s
global_step/sec: 14.5305
loss = 1105.3544921875, steps = 2200, cost time = 6.88s
global_step/sec: 14.6103
loss = 1232.8681640625, steps = 2300, cost time = 6.84s
global_step/sec: 13.7281
loss = 1258.5421142578125, steps = 2400, cost time = 7.28s
global_step/sec: 14.1626
loss = 1004.4905395507812, steps = 2500, cost time = 7.06s
global_step/sec: 15.5585
loss = 1168.6826171875, steps = 2600, cost time = 6.43s
global_step/sec: 15.4420
loss = 1168.640380859375, steps = 2700, cost time = 6.48s
global_step/sec: 13.8320
loss = 1187.753662109375, steps = 2800, cost time = 7.23s
global_step/sec: 14.6199
loss = 1124.0128173828125, steps = 2900, cost time = 6.84s
global_step/sec: 14.0779
loss = 1123.9786376953125, steps = 3000, cost time = 7.10s
global_step/sec: 14.1646
loss = 1130.2933349609375, steps = 3100, cost time = 7.06s
global_step/sec: 14.8814
loss = 1117.5699462890625, steps = 3200, cost time = 6.72s
global_step/sec: 14.5516
loss = 1117.5439453125, steps = 3300, cost time = 6.87s
global_step/sec: 14.9672
loss = 1296.896240234375, steps = 3400, cost time = 6.68s
global_step/sec: 15.0558
loss = 1187.5433349609375, steps = 3500, cost time = 6.64s
global_step/sec: 14.4506
loss = 1174.7396240234375, steps = 3600, cost time = 6.92s
global_step/sec: 16.1015
loss = 1174.71630859375, steps = 3700, cost time = 6.21s
global_step/sec: 13.4999
loss = 979.10302734375, steps = 3800, cost time = 7.41s
global_step/sec: 13.4110
loss = 1168.296875, steps = 3900, cost time = 7.46s
global_step/sec: 13.6968
loss = 1245.162841796875, steps = 4000, cost time = 7.30s
global_step/sec: 15.3093
loss = 1054.1983642578125, steps = 4100, cost time = 6.53s
global_step/sec: 14.7226
loss = 1066.779296875, steps = 4200, cost time = 6.79s
global_step/sec: 16.0442
loss = 966.568603515625, steps = 4300, cost time = 6.23s
global_step/sec: 11.7361
loss = 1322.6146240234375, steps = 4400, cost time = 8.52s
global_step/sec: 12.8666
loss = 1329.087646484375, steps = 4500, cost time = 7.77s
global_step/sec: 15.4118
loss = 1142.7127685546875, steps = 4600, cost time = 6.49s
global_step/sec: 14.9336
loss = 1110.95361328125, steps = 4700, cost time = 6.70s
global_step/sec: 14.9960
loss = 1073.007568359375, steps = 4800, cost time = 6.67s
global_step/sec: 14.5578
loss = 1168.1583251953125, steps = 4900, cost time = 6.87s
global_step/sec: 13.8118
loss = 972.7105102539062, steps = 5000, cost time = 7.24s
global_step/sec: 14.1694
loss = 1129.945068359375, steps = 5100, cost time = 7.06s
global_step/sec: 14.1197
loss = 1149.0107421875, steps = 5200, cost time = 7.08s
global_step/sec: 14.7562
loss = 1180.89208984375, steps = 5300, cost time = 6.78s
global_step/sec: 13.6206
loss = 1219.295654296875, steps = 5400, cost time = 7.34s
global_step/sec: 13.7541
loss = 1316.015625, steps = 5500, cost time = 7.27s
global_step/sec: 13.5463
loss = 1219.28125, steps = 5600, cost time = 7.38s
global_step/sec: 12.7819
loss = 1028.889404296875, steps = 5700, cost time = 7.82s
global_step/sec: 12.4411
loss = 1187.2421875, steps = 5800, cost time = 8.04s
global_step/sec: 12.5391
loss = 1136.2337646484375, steps = 5900, cost time = 7.98s
global_step/sec: 12.5776
loss = 1142.5860595703125, steps = 6000, cost time = 7.95s
global_step/sec: 12.4575
loss = 1200.018798828125, steps = 6100, cost time = 8.03s
global_step/sec: 11.6688
loss = 1110.8280029296875, steps = 6200, cost time = 8.57s
global_step/sec: 12.3599
loss = 1010.053955078125, steps = 6300, cost time = 8.09s
global_step/sec: 12.0900
loss = 1104.480712890625, steps = 6400, cost time = 8.27s
global_step/sec: 12.8320
loss = 1098.14453125, steps = 6500, cost time = 7.79s
global_step/sec: 13.0969
loss = 1187.192138671875, steps = 6600, cost time = 7.64s
global_step/sec: 13.1198
loss = 1283.5936279296875, steps = 6700, cost time = 7.62s
global_step/sec: 12.9403
loss = 1168.0224609375, steps = 6800, cost time = 7.73s
global_step/sec: 13.0541
loss = 1168.0198974609375, steps = 6900, cost time = 7.66s
global_step/sec: 12.4060
loss = 1212.7847900390625, steps = 7000, cost time = 8.06s
global_step/sec: 12.0118
loss = 1199.9671630859375, steps = 7100, cost time = 8.33s
global_step/sec: 12.2002
loss = 1129.810546875, steps = 7200, cost time = 8.20s
global_step/sec: 11.6479
loss = 1091.783203125, steps = 7300, cost time = 8.59s
global_step/sec: 11.9382
loss = 1129.802490234375, steps = 7400, cost time = 8.38s
global_step/sec: 11.9313
loss = 1016.258544921875, steps = 7500, cost time = 8.38s
global_step/sec: 11.9555
loss = 1136.149658203125, steps = 7600, cost time = 8.36s
global_step/sec: 12.8257
loss = 1193.54443359375, steps = 7700, cost time = 7.80s
global_step/sec: 12.3653
loss = 1167.983642578125, steps = 7800, cost time = 8.09s
global_step/sec: 12.9821
loss = 1085.440673828125, steps = 7900, cost time = 7.70s
global_step/sec: 14.8636
loss = 1193.5328369140625, steps = 8000, cost time = 6.73s
global_step/sec: 12.9629
loss = 1041.33056640625, steps = 8100, cost time = 7.71s
global_step/sec: 11.1767
loss = 1206.331298828125, steps = 8200, cost time = 8.95s
global_step/sec: 11.4412
loss = 1354.8377685546875, steps = 8300, cost time = 8.74s
global_step/sec: 12.3980
loss = 997.4666748046875, steps = 8400, cost time = 8.07s
global_step/sec: 12.8193
loss = 1136.1219482421875, steps = 8500, cost time = 7.80s
global_step/sec: 13.1609
loss = 1174.34130859375, steps = 8600, cost time = 7.60s
global_step/sec: 12.5517
loss = 1219.1417236328125, steps = 8700, cost time = 7.97s
global_step/sec: 12.6748
loss = 1219.1405029296875, steps = 8800, cost time = 7.89s
global_step/sec: 12.8966
loss = 1110.724365234375, steps = 8900, cost time = 7.75s
global_step/sec: 12.8276
loss = 960.064697265625, steps = 9000, cost time = 7.80s
global_step/sec: 12.9842
loss = 1206.3089599609375, steps = 9100, cost time = 7.70s
global_step/sec: 13.9475
loss = 1296.439453125, steps = 9200, cost time = 7.17s
global_step/sec: 12.7914
loss = 1091.7259521484375, steps = 9300, cost time = 7.82s
global_step/sec: 12.9312
loss = 1167.941162109375, steps = 9400, cost time = 7.73s
global_step/sec: 12.9002
loss = 1277.0445556640625, steps = 9500, cost time = 7.75s
global_step/sec: 12.2765
loss = 1257.698974609375, steps = 9600, cost time = 8.15s
global_step/sec: 12.8288
loss = 1296.429931640625, steps = 9700, cost time = 7.79s
global_step/sec: 12.7784
loss = 1072.768798828125, steps = 9800, cost time = 7.83s
global_step/sec: 12.5981
loss = 1110.703857421875, steps = 9900, cost time = 7.94s
global_step/sec: 12.0646
loss = 1136.09033203125, steps = 10000, cost time = 8.29s
global_step/sec: 12.3848
loss = 1433.1632080078125, steps = 10100, cost time = 8.07s
global_step/sec: 12.6818
loss = 1123.3831787109375, steps = 10200, cost time = 7.89s
global_step/sec: 12.6038
loss = 1104.36376953125, steps = 10300, cost time = 7.93s
global_step/sec: 11.3609
loss = 1212.6964111328125, steps = 10400, cost time = 8.80s
global_step/sec: 13.0013
loss = 1034.9990234375, steps = 10500, cost time = 7.69s
global_step/sec: 13.2253
loss = 1148.804443359375, steps = 10600, cost time = 7.56s
global_step/sec: 12.1928
loss = 1110.692626953125, steps = 10700, cost time = 8.20s
global_step/sec: 13.2305
loss = 1060.145751953125, steps = 10800, cost time = 7.56s
global_step/sec: 12.2287
loss = 1187.07666015625, steps = 10900, cost time = 8.18s
global_step/sec: 12.5284
loss = 1098.0234375, steps = 11000, cost time = 7.98s
global_step/sec: 12.9064
loss = 1034.9918212890625, steps = 11100, cost time = 7.75s
global_step/sec: 12.5584
loss = 1148.7952880859375, steps = 11200, cost time = 7.96s
global_step/sec: 12.1191
loss = 1079.0582275390625, steps = 11300, cost time = 8.25s
global_step/sec: 12.7355
loss = 1148.7943115234375, steps = 11400, cost time = 7.85s
global_step/sec: 12.4056
loss = 1180.6787109375, steps = 11500, cost time = 8.06s
global_step/sec: 12.8422
loss = 1193.4652099609375, steps = 11600, cost time = 7.79s
global_step/sec: 13.5813
loss = 1117.01806640625, steps = 11700, cost time = 7.36s
global_step/sec: 14.4372
loss = 1167.9058837890625, steps = 11800, cost time = 6.93s
global_step/sec: 13.9428
loss = 1155.15576171875, steps = 11900, cost time = 7.17s
global_step/sec: 11.8082
loss = 1174.2867431640625, steps = 12000, cost time = 8.47s
global_step/sec: 10.7176
loss = 1174.28564453125, steps = 12100, cost time = 9.33s
global_step/sec: 12.3311
loss = 1193.458251953125, steps = 12200, cost time = 8.11s
global_step/sec: 25877.3372
loss = 23.040794372558594, steps = 12207, cost time = 0.47s
Evaluation complate:[3/3]
ACC = 0.9124000072479248
AUC = 0.5031068325042725
