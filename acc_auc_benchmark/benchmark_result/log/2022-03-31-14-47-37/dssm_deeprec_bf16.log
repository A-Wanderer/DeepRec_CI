INFO:tensorflow:Parsing ./data/taobao_train_data
INFO:tensorflow:Parsing ./data/taobao_test_data
2022-03-31 09:43:32.756955: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3400000000 Hz
2022-03-31 09:43:32.797314: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x575c5f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-03-31 09:43:32.797383: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Using TensorFlow version 1.15.5
Checking dataset
Numbers of training dataset is 50000
Numbers of test dataset is 10000
Saving model checkpoints to /benchmark_result/checkpoint/2022-03-31-14-47-37/dssm_deeprec_bf16
global_step/sec: 19.8438
loss = 1913.905517578125, steps = 0, cost time = 5.04s
global_step/sec: 19.5075
loss = 1213.771484375, steps = 100, cost time = 5.13s
global_step/sec: 19.5908
loss = 1090.60107421875, steps = 200, cost time = 5.10s
global_step/sec: 21.4187
loss = 1213.2578125, steps = 300, cost time = 4.67s
global_step/sec: 20.0908
loss = 990.8560791015625, steps = 400, cost time = 4.98s
global_step/sec: 20.3044
loss = 1265.974853515625, steps = 500, cost time = 4.93s
global_step/sec: 20.2234
loss = 1116.92822265625, steps = 600, cost time = 4.94s
global_step/sec: 21.7005
loss = 965.002685546875, steps = 700, cost time = 4.61s
global_step/sec: 20.9676
loss = 1184.7174072265625, steps = 800, cost time = 4.77s
global_step/sec: 19.8361
loss = 1190.43017578125, steps = 900, cost time = 5.04s
global_step/sec: 20.7484
loss = 1100.9208984375, steps = 1000, cost time = 4.82s
global_step/sec: 20.5991
loss = 1195.957275390625, steps = 1100, cost time = 4.85s
global_step/sec: 20.4056
loss = 1259.845458984375, steps = 1200, cost time = 4.90s
global_step/sec: 20.6272
loss = 1093.623291015625, steps = 1300, cost time = 4.85s
global_step/sec: 20.0181
loss = 986.6619262695312, steps = 1400, cost time = 5.00s
global_step/sec: 20.8271
loss = 1220.646728515625, steps = 1500, cost time = 4.80s
global_step/sec: 19.7977
loss = 1246.1961669921875, steps = 1600, cost time = 5.05s
global_step/sec: 19.8839
loss = 1175.570556640625, steps = 1700, cost time = 5.03s
global_step/sec: 21.0548
loss = 1011.0833740234375, steps = 1800, cost time = 4.75s
global_step/sec: 21.3543
loss = 1278.08837890625, steps = 1900, cost time = 4.68s
global_step/sec: 20.0303
loss = 1156.1490478515625, steps = 2000, cost time = 4.99s
global_step/sec: 21.5784
loss = 1323.21630859375, steps = 2100, cost time = 4.63s
global_step/sec: 20.0473
loss = 1105.19091796875, steps = 2200, cost time = 4.99s
global_step/sec: 19.9376
loss = 1232.71826171875, steps = 2300, cost time = 5.02s
global_step/sec: 21.0606
loss = 1258.3988037109375, steps = 2400, cost time = 4.75s
global_step/sec: 20.3644
loss = 1004.3510131835938, steps = 2500, cost time = 4.91s
global_step/sec: 19.9001
loss = 1168.550537109375, steps = 2600, cost time = 5.03s
global_step/sec: 21.0382
loss = 1168.510498046875, steps = 2700, cost time = 4.75s
global_step/sec: 21.1524
loss = 1187.635498046875, steps = 2800, cost time = 4.73s
global_step/sec: 20.8587
loss = 1123.896240234375, steps = 2900, cost time = 4.79s
global_step/sec: 20.5084
loss = 1123.86669921875, steps = 3000, cost time = 4.88s
global_step/sec: 20.9852
loss = 1130.18505859375, steps = 3100, cost time = 4.77s
global_step/sec: 20.6624
loss = 1117.463623046875, steps = 3200, cost time = 4.84s
global_step/sec: 21.1123
loss = 1117.438232421875, steps = 3300, cost time = 4.74s
global_step/sec: 22.3671
loss = 1296.79443359375, steps = 3400, cost time = 4.47s
global_step/sec: 22.1376
loss = 1187.45166015625, steps = 3500, cost time = 4.52s
global_step/sec: 22.1460
loss = 1174.644287109375, steps = 3600, cost time = 4.52s
global_step/sec: 21.9919
loss = 1174.623046875, steps = 3700, cost time = 4.55s
global_step/sec: 20.2677
loss = 979.0108642578125, steps = 3800, cost time = 4.93s
global_step/sec: 20.7255
loss = 1168.2080078125, steps = 3900, cost time = 4.82s
global_step/sec: 19.9379
loss = 1245.07666015625, steps = 4000, cost time = 5.02s
global_step/sec: 20.4758
loss = 1054.113037109375, steps = 4100, cost time = 4.88s
global_step/sec: 20.6922
loss = 1066.695068359375, steps = 4200, cost time = 4.83s
global_step/sec: 20.3785
loss = 966.484619140625, steps = 4300, cost time = 4.91s
global_step/sec: 20.3619
loss = 1322.5369873046875, steps = 4400, cost time = 4.91s
global_step/sec: 20.7476
loss = 1329.010498046875, steps = 4500, cost time = 4.82s
global_step/sec: 19.7632
loss = 1142.6361083984375, steps = 4600, cost time = 5.06s
global_step/sec: 21.6360
loss = 1110.876220703125, steps = 4700, cost time = 4.62s
global_step/sec: 20.7122
loss = 1072.9295654296875, steps = 4800, cost time = 4.83s
global_step/sec: 20.2877
loss = 1168.086181640625, steps = 4900, cost time = 4.93s
global_step/sec: 19.7887
loss = 972.6333618164062, steps = 5000, cost time = 5.05s
global_step/sec: 20.0384
loss = 1129.87109375, steps = 5100, cost time = 4.99s
global_step/sec: 19.9861
loss = 1148.939453125, steps = 5200, cost time = 5.00s
global_step/sec: 21.0358
loss = 1180.8194580078125, steps = 5300, cost time = 4.75s
global_step/sec: 22.5734
loss = 1219.2274169921875, steps = 5400, cost time = 4.43s
global_step/sec: 24.0444
loss = 1315.9468994140625, steps = 5500, cost time = 4.16s
global_step/sec: 23.3279
loss = 1219.211669921875, steps = 5600, cost time = 4.29s
global_step/sec: 23.2928
loss = 1028.822998046875, steps = 5700, cost time = 4.29s
global_step/sec: 23.0022
loss = 1187.17529296875, steps = 5800, cost time = 4.35s
global_step/sec: 23.6987
loss = 1136.1689453125, steps = 5900, cost time = 4.22s
global_step/sec: 23.4346
loss = 1142.521484375, steps = 6000, cost time = 4.27s
global_step/sec: 23.0281
loss = 1199.9552001953125, steps = 6100, cost time = 4.34s
global_step/sec: 24.1191
loss = 1110.7635498046875, steps = 6200, cost time = 4.15s
global_step/sec: 23.4308
loss = 1009.9913940429688, steps = 6300, cost time = 4.27s
global_step/sec: 22.9046
loss = 1104.418701171875, steps = 6400, cost time = 4.37s
global_step/sec: 23.2784
loss = 1098.082763671875, steps = 6500, cost time = 4.30s
global_step/sec: 23.1127
loss = 1187.1318359375, steps = 6600, cost time = 4.33s
global_step/sec: 24.2486
loss = 1283.5347900390625, steps = 6700, cost time = 4.12s
global_step/sec: 23.9313
loss = 1167.962646484375, steps = 6800, cost time = 4.18s
global_step/sec: 24.5670
loss = 1167.9620361328125, steps = 6900, cost time = 4.07s
global_step/sec: 18.8548
loss = 1212.72509765625, steps = 7000, cost time = 5.30s
global_step/sec: 15.6740
loss = 1199.907470703125, steps = 7100, cost time = 6.38s
global_step/sec: 15.6590
loss = 1129.75244140625, steps = 7200, cost time = 6.39s
global_step/sec: 17.9442
loss = 1091.725830078125, steps = 7300, cost time = 5.57s
global_step/sec: 16.2838
loss = 1129.74462890625, steps = 7400, cost time = 6.14s
global_step/sec: 16.3212
loss = 1016.2018432617188, steps = 7500, cost time = 6.13s
global_step/sec: 14.1468
loss = 1136.093994140625, steps = 7600, cost time = 7.07s
global_step/sec: 12.5196
loss = 1193.48681640625, steps = 7700, cost time = 7.99s
global_step/sec: 14.2121
loss = 1167.928955078125, steps = 7800, cost time = 7.04s
global_step/sec: 16.1670
loss = 1085.384765625, steps = 7900, cost time = 6.19s
global_step/sec: 16.1437
loss = 1193.4775390625, steps = 8000, cost time = 6.19s
global_step/sec: 15.0009
loss = 1041.27587890625, steps = 8100, cost time = 6.67s
global_step/sec: 15.7553
loss = 1206.2781982421875, steps = 8200, cost time = 6.35s
global_step/sec: 14.7080
loss = 1354.7838134765625, steps = 8300, cost time = 6.80s
global_step/sec: 14.9563
loss = 997.4144287109375, steps = 8400, cost time = 6.69s
global_step/sec: 16.8428
loss = 1136.069580078125, steps = 8500, cost time = 5.94s
global_step/sec: 14.9937
loss = 1174.2880859375, steps = 8600, cost time = 6.67s
global_step/sec: 15.3371
loss = 1219.088134765625, steps = 8700, cost time = 6.52s
global_step/sec: 15.3744
loss = 1219.0882568359375, steps = 8800, cost time = 6.50s
global_step/sec: 16.5432
loss = 1110.67138671875, steps = 8900, cost time = 6.04s
global_step/sec: 16.6529
loss = 960.0111694335938, steps = 9000, cost time = 6.00s
global_step/sec: 15.6667
loss = 1206.257080078125, steps = 9100, cost time = 6.38s
global_step/sec: 15.3305
loss = 1296.384521484375, steps = 9200, cost time = 6.52s
global_step/sec: 14.6950
loss = 1091.673095703125, steps = 9300, cost time = 6.81s
global_step/sec: 16.3426
loss = 1167.8905029296875, steps = 9400, cost time = 6.12s
global_step/sec: 14.9718
loss = 1276.993896484375, steps = 9500, cost time = 6.68s
global_step/sec: 15.1592
loss = 1257.6470947265625, steps = 9600, cost time = 6.60s
global_step/sec: 15.4433
loss = 1296.37744140625, steps = 9700, cost time = 6.48s
global_step/sec: 17.0542
loss = 1072.716796875, steps = 9800, cost time = 5.86s
global_step/sec: 16.0378
loss = 1110.653564453125, steps = 9900, cost time = 6.24s
global_step/sec: 14.5768
loss = 1136.03955078125, steps = 10000, cost time = 6.86s
global_step/sec: 15.3694
loss = 1433.111328125, steps = 10100, cost time = 6.51s
global_step/sec: 15.4604
loss = 1123.33203125, steps = 10200, cost time = 6.47s
global_step/sec: 15.2578
loss = 1104.312255859375, steps = 10300, cost time = 6.55s
global_step/sec: 15.2728
loss = 1212.6474609375, steps = 10400, cost time = 6.55s
global_step/sec: 15.7429
loss = 1034.950439453125, steps = 10500, cost time = 6.35s
global_step/sec: 15.6238
loss = 1148.753173828125, steps = 10600, cost time = 6.40s
global_step/sec: 15.4997
loss = 1110.6431884765625, steps = 10700, cost time = 6.45s
global_step/sec: 15.9320
loss = 1060.0975341796875, steps = 10800, cost time = 6.28s
global_step/sec: 16.5235
loss = 1187.0284423828125, steps = 10900, cost time = 6.05s
global_step/sec: 15.7567
loss = 1097.973388671875, steps = 11000, cost time = 6.35s
global_step/sec: 14.7215
loss = 1034.941650390625, steps = 11100, cost time = 6.79s
global_step/sec: 14.7545
loss = 1148.7470703125, steps = 11200, cost time = 6.78s
global_step/sec: 15.8944
loss = 1079.0091552734375, steps = 11300, cost time = 6.29s
global_step/sec: 15.0998
loss = 1148.7451171875, steps = 11400, cost time = 6.62s
global_step/sec: 16.6580
loss = 1180.6300048828125, steps = 11500, cost time = 6.00s
global_step/sec: 15.8812
loss = 1193.416015625, steps = 11600, cost time = 6.30s
global_step/sec: 13.1706
loss = 1116.9710693359375, steps = 11700, cost time = 7.59s
global_step/sec: 14.1404
loss = 1167.8592529296875, steps = 11800, cost time = 7.07s
global_step/sec: 16.3682
loss = 1155.10693359375, steps = 11900, cost time = 6.11s
global_step/sec: 16.1099
loss = 1174.238525390625, steps = 12000, cost time = 6.21s
global_step/sec: 15.8062
loss = 1174.2384033203125, steps = 12100, cost time = 6.33s
global_step/sec: 16.3605
loss = 1193.410888671875, steps = 12200, cost time = 6.11s
global_step/sec: 27838.4756
loss = 23.090652465820312, steps = 12207, cost time = 0.44s
Evaluation complate:[3/3]
ACC = 0.9334999918937683
AUC = 0.49125009775161743
