INFO:tensorflow:Parsing ./data/taobao_train_data
INFO:tensorflow:Parsing ./data/taobao_test_data
2022-03-24 10:56:13.630100: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3400000000 Hz
2022-03-24 10:56:13.656898: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x575cff0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-03-24 10:56:13.656961: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Using TensorFlow version 1.15.5
Checking dataset
Numbers of training dataset is 50000
Numbers of test dataset is 10000
Saving model checkpoints to /benchmark_result/checkpoint/2022-03-24-15-57-35/dssm_deeprec_bf16
global_step/sec: 23.1888
loss = 1913.905517578125, steps = 0, cost time = 4.31s
global_step/sec: 26.2484
loss = 1213.771484375, steps = 100, cost time = 3.81s
global_step/sec: 18.9985
loss = 1090.60107421875, steps = 200, cost time = 5.26s
global_step/sec: 25.5507
loss = 1213.2578125, steps = 300, cost time = 3.91s
global_step/sec: 24.3281
loss = 990.8560791015625, steps = 400, cost time = 4.11s
global_step/sec: 23.3999
loss = 1265.974853515625, steps = 500, cost time = 4.27s
global_step/sec: 23.9875
loss = 1116.92822265625, steps = 600, cost time = 4.17s
global_step/sec: 23.0628
loss = 965.002685546875, steps = 700, cost time = 4.34s
global_step/sec: 23.8619
loss = 1184.7174072265625, steps = 800, cost time = 4.19s
global_step/sec: 22.8212
loss = 1190.43017578125, steps = 900, cost time = 4.38s
global_step/sec: 24.0004
loss = 1100.9208984375, steps = 1000, cost time = 4.17s
global_step/sec: 23.4101
loss = 1195.957275390625, steps = 1100, cost time = 4.27s
global_step/sec: 23.6369
loss = 1259.845458984375, steps = 1200, cost time = 4.23s
global_step/sec: 22.7863
loss = 1093.623291015625, steps = 1300, cost time = 4.39s
global_step/sec: 23.4748
loss = 986.6619262695312, steps = 1400, cost time = 4.26s
global_step/sec: 23.7257
loss = 1220.646728515625, steps = 1500, cost time = 4.21s
global_step/sec: 22.3220
loss = 1246.1961669921875, steps = 1600, cost time = 4.48s
global_step/sec: 22.6018
loss = 1175.570556640625, steps = 1700, cost time = 4.42s
global_step/sec: 23.9778
loss = 1011.0833740234375, steps = 1800, cost time = 4.17s
global_step/sec: 23.1297
loss = 1278.08837890625, steps = 1900, cost time = 4.32s
global_step/sec: 24.5668
loss = 1156.1490478515625, steps = 2000, cost time = 4.07s
global_step/sec: 23.4370
loss = 1323.21630859375, steps = 2100, cost time = 4.27s
global_step/sec: 22.4692
loss = 1105.19091796875, steps = 2200, cost time = 4.45s
global_step/sec: 21.9839
loss = 1232.71826171875, steps = 2300, cost time = 4.55s
global_step/sec: 22.5440
loss = 1258.3988037109375, steps = 2400, cost time = 4.44s
global_step/sec: 23.7923
loss = 1004.3510131835938, steps = 2500, cost time = 4.20s
global_step/sec: 23.3866
loss = 1168.550537109375, steps = 2600, cost time = 4.28s
global_step/sec: 23.1447
loss = 1168.510498046875, steps = 2700, cost time = 4.32s
global_step/sec: 22.3871
loss = 1187.635498046875, steps = 2800, cost time = 4.47s
global_step/sec: 22.5285
loss = 1123.896240234375, steps = 2900, cost time = 4.44s
global_step/sec: 21.8935
loss = 1123.86669921875, steps = 3000, cost time = 4.57s
global_step/sec: 23.1706
loss = 1130.18505859375, steps = 3100, cost time = 4.32s
global_step/sec: 24.0867
loss = 1117.463623046875, steps = 3200, cost time = 4.15s
global_step/sec: 22.3439
loss = 1117.438232421875, steps = 3300, cost time = 4.48s
global_step/sec: 23.8132
loss = 1296.79443359375, steps = 3400, cost time = 4.20s
global_step/sec: 23.7163
loss = 1187.45166015625, steps = 3500, cost time = 4.22s
global_step/sec: 22.5545
loss = 1174.644287109375, steps = 3600, cost time = 4.43s
global_step/sec: 21.9052
loss = 1174.623046875, steps = 3700, cost time = 4.57s
global_step/sec: 21.9052
loss = 979.0108642578125, steps = 3800, cost time = 4.57s
global_step/sec: 23.3985
loss = 1168.2080078125, steps = 3900, cost time = 4.27s
global_step/sec: 24.1403
loss = 1245.07666015625, steps = 4000, cost time = 4.14s
global_step/sec: 25.2268
loss = 1054.113037109375, steps = 4100, cost time = 3.96s
global_step/sec: 22.5005
loss = 1066.695068359375, steps = 4200, cost time = 4.44s
global_step/sec: 23.3441
loss = 966.484619140625, steps = 4300, cost time = 4.28s
global_step/sec: 23.1709
loss = 1322.5369873046875, steps = 4400, cost time = 4.32s
global_step/sec: 22.2326
loss = 1329.010498046875, steps = 4500, cost time = 4.50s
global_step/sec: 24.6684
loss = 1142.6361083984375, steps = 4600, cost time = 4.05s
global_step/sec: 29.4496
loss = 1110.876220703125, steps = 4700, cost time = 3.40s
global_step/sec: 28.1334
loss = 1072.9295654296875, steps = 4800, cost time = 3.55s
global_step/sec: 30.6820
loss = 1168.086181640625, steps = 4900, cost time = 3.26s
global_step/sec: 27.9656
loss = 972.6333618164062, steps = 5000, cost time = 3.58s
global_step/sec: 26.9880
loss = 1129.87109375, steps = 5100, cost time = 3.71s
global_step/sec: 28.1330
loss = 1148.939453125, steps = 5200, cost time = 3.55s
global_step/sec: 27.8111
loss = 1180.8194580078125, steps = 5300, cost time = 3.60s
global_step/sec: 27.0149
loss = 1219.2274169921875, steps = 5400, cost time = 3.70s
global_step/sec: 27.1337
loss = 1315.9468994140625, steps = 5500, cost time = 3.69s
global_step/sec: 27.5980
loss = 1219.211669921875, steps = 5600, cost time = 3.62s
global_step/sec: 28.9981
loss = 1028.822998046875, steps = 5700, cost time = 3.45s
global_step/sec: 27.3281
loss = 1187.17529296875, steps = 5800, cost time = 3.66s
global_step/sec: 27.9330
loss = 1136.1689453125, steps = 5900, cost time = 3.58s
global_step/sec: 28.5962
loss = 1142.521484375, steps = 6000, cost time = 3.50s
global_step/sec: 29.0116
loss = 1199.9552001953125, steps = 6100, cost time = 3.45s
global_step/sec: 22.3317
loss = 1110.7635498046875, steps = 6200, cost time = 4.48s
global_step/sec: 16.0331
loss = 1009.9913940429688, steps = 6300, cost time = 6.24s
global_step/sec: 16.9010
loss = 1104.418701171875, steps = 6400, cost time = 5.92s
global_step/sec: 17.0170
loss = 1098.082763671875, steps = 6500, cost time = 5.88s
global_step/sec: 18.4973
loss = 1187.1318359375, steps = 6600, cost time = 5.41s
global_step/sec: 18.0007
loss = 1283.5347900390625, steps = 6700, cost time = 5.56s
global_step/sec: 15.6838
loss = 1167.962646484375, steps = 6800, cost time = 6.38s
global_step/sec: 16.6887
loss = 1167.9620361328125, steps = 6900, cost time = 5.99s
global_step/sec: 16.5627
loss = 1212.72509765625, steps = 7000, cost time = 6.04s
global_step/sec: 16.7200
loss = 1199.907470703125, steps = 7100, cost time = 5.98s
global_step/sec: 17.3913
loss = 1129.75244140625, steps = 7200, cost time = 5.75s
global_step/sec: 17.3899
loss = 1091.725830078125, steps = 7300, cost time = 5.75s
global_step/sec: 16.8764
loss = 1129.74462890625, steps = 7400, cost time = 5.93s
global_step/sec: 15.9402
loss = 1016.2018432617188, steps = 7500, cost time = 6.27s
global_step/sec: 16.7160
loss = 1136.093994140625, steps = 7600, cost time = 5.98s
global_step/sec: 17.0531
loss = 1193.48681640625, steps = 7700, cost time = 5.86s
global_step/sec: 16.3094
loss = 1167.928955078125, steps = 7800, cost time = 6.13s
global_step/sec: 17.0390
loss = 1085.384765625, steps = 7900, cost time = 5.87s
global_step/sec: 16.7737
loss = 1193.4775390625, steps = 8000, cost time = 5.96s
global_step/sec: 18.8114
loss = 1041.27587890625, steps = 8100, cost time = 5.32s
global_step/sec: 17.4011
loss = 1206.2781982421875, steps = 8200, cost time = 5.75s
global_step/sec: 16.2809
loss = 1354.7838134765625, steps = 8300, cost time = 6.14s
global_step/sec: 16.4115
loss = 997.4144287109375, steps = 8400, cost time = 6.09s
global_step/sec: 16.6143
loss = 1136.069580078125, steps = 8500, cost time = 6.02s
global_step/sec: 17.3220
loss = 1174.2880859375, steps = 8600, cost time = 5.77s
global_step/sec: 17.0158
loss = 1219.088134765625, steps = 8700, cost time = 5.88s
global_step/sec: 19.8353
loss = 1219.0882568359375, steps = 8800, cost time = 5.04s
global_step/sec: 18.0342
loss = 1110.67138671875, steps = 8900, cost time = 5.55s
global_step/sec: 17.7232
loss = 960.0111694335938, steps = 9000, cost time = 5.64s
global_step/sec: 17.6849
loss = 1206.257080078125, steps = 9100, cost time = 5.65s
global_step/sec: 16.0950
loss = 1296.384521484375, steps = 9200, cost time = 6.21s
global_step/sec: 16.9206
loss = 1091.673095703125, steps = 9300, cost time = 5.91s
global_step/sec: 18.7119
loss = 1167.8905029296875, steps = 9400, cost time = 5.34s
global_step/sec: 18.6304
loss = 1276.993896484375, steps = 9500, cost time = 5.37s
global_step/sec: 17.5442
loss = 1257.6470947265625, steps = 9600, cost time = 5.70s
global_step/sec: 17.9203
loss = 1296.37744140625, steps = 9700, cost time = 5.58s
global_step/sec: 18.1759
loss = 1072.716796875, steps = 9800, cost time = 5.50s
global_step/sec: 17.1602
loss = 1110.653564453125, steps = 9900, cost time = 5.83s
global_step/sec: 18.4628
loss = 1136.03955078125, steps = 10000, cost time = 5.42s
global_step/sec: 18.2436
loss = 1433.111328125, steps = 10100, cost time = 5.48s
global_step/sec: 17.3325
loss = 1123.33203125, steps = 10200, cost time = 5.77s
global_step/sec: 18.7991
loss = 1104.312255859375, steps = 10300, cost time = 5.32s
global_step/sec: 19.7559
loss = 1212.6474609375, steps = 10400, cost time = 5.06s
global_step/sec: 18.7283
loss = 1034.950439453125, steps = 10500, cost time = 5.34s
global_step/sec: 17.7866
loss = 1148.753173828125, steps = 10600, cost time = 5.62s
global_step/sec: 17.1712
loss = 1110.6431884765625, steps = 10700, cost time = 5.82s
global_step/sec: 18.8923
loss = 1060.0975341796875, steps = 10800, cost time = 5.29s
global_step/sec: 18.5788
loss = 1187.0284423828125, steps = 10900, cost time = 5.38s
global_step/sec: 16.1692
loss = 1097.973388671875, steps = 11000, cost time = 6.18s
global_step/sec: 20.5349
loss = 1034.941650390625, steps = 11100, cost time = 4.87s
global_step/sec: 16.7452
loss = 1148.7470703125, steps = 11200, cost time = 5.97s
global_step/sec: 15.0404
loss = 1079.0091552734375, steps = 11300, cost time = 6.65s
global_step/sec: 16.0979
loss = 1148.7451171875, steps = 11400, cost time = 6.21s
global_step/sec: 18.0641
loss = 1180.6300048828125, steps = 11500, cost time = 5.54s
global_step/sec: 17.2962
loss = 1193.416015625, steps = 11600, cost time = 5.78s
global_step/sec: 15.8373
loss = 1116.9710693359375, steps = 11700, cost time = 6.31s
global_step/sec: 17.7587
loss = 1167.8592529296875, steps = 11800, cost time = 5.63s
global_step/sec: 16.6681
loss = 1155.10693359375, steps = 11900, cost time = 6.00s
global_step/sec: 19.0200
loss = 1174.238525390625, steps = 12000, cost time = 5.26s
global_step/sec: 16.9465
loss = 1174.2384033203125, steps = 12100, cost time = 5.90s
global_step/sec: 16.7067
loss = 1193.410888671875, steps = 12200, cost time = 5.99s
global_step/sec: 28493.3176
loss = 23.090652465820312, steps = 12207, cost time = 0.43s
Evaluation complate:[3/3]
ACC = 0.9334999918937683
AUC = 0.49125009775161743
