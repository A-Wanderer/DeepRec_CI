WARNING:tensorflow:From train.py:14: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

WARNING:tensorflow:From train.py:14: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

WARNING:tensorflow:From train.py:453: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

INFO:tensorflow:Parsing ./data/taobao_train_data
INFO:tensorflow:Parsing ./data/taobao_test_data
WARNING:tensorflow:From train.py:466: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.

WARNING:tensorflow:From train.py:466: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_types(dataset)`.
WARNING:tensorflow:From train.py:467: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(dataset)`.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:347: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_types(iterator)`.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:348: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(iterator)`.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:350: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_classes(iterator)`.
WARNING:tensorflow:From train.py:261: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From train.py:263: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.

WARNING:tensorflow:From train.py:264: The name tf.feature_column.input_layer is deprecated. Please use tf.compat.v1.feature_column.input_layer instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column.py:206: EmbeddingColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:3182: HashedCategoricalColumn._get_sparse_tensors (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column.py:2158: HashedCategoricalColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:3122: HashedCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column.py:207: EmbeddingColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From train.py:239: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.Dense instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From train.py:243: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).
WARNING:tensorflow:From train.py:128: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From train.py:130: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

WARNING:tensorflow:From train.py:302: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
WARNING:tensorflow:From train.py:304: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From train.py:325: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.

WARNING:tensorflow:From train.py:329: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.

WARNING:tensorflow:From train.py:336: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From train.py:340: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

WARNING:tensorflow:From train.py:340: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

WARNING:tensorflow:From train.py:218: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.

WARNING:tensorflow:From train.py:221: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From train.py:493: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From train.py:526: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2022-03-24 11:00:30.108493: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2022-03-24 11:00:30.150234: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3400000000 Hz
2022-03-24 11:00:30.178712: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5760fe0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-03-24 11:00:30.178761: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From train.py:527: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From train.py:528: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.

WARNING:tensorflow:From train.py:529: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

WARNING:tensorflow:From train.py:530: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From train.py:531: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From train.py:531: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From train.py:533: The name tf.RunOptions is deprecated. Please use tf.compat.v1.RunOptions instead.

WARNING:tensorflow:From train.py:534: The name tf.RunMetadata is deprecated. Please use tf.compat.v1.RunMetadata instead.

Using TensorFlow version 1.15.5
Checking dataset
Numbers of training dataset is 50000
Numbers of test dataset is 10000
Saving model checkpoints to /benchmark_result/checkpoint/2022-03-24-15-57-35/dssm_tf_fp32
global_step/sec: 49.2623
loss = 1914.4495849609375, steps = 0, cost time = 2.03s
global_step/sec: 13.5280
loss = 1209.7977294921875, steps = 100, cost time = 7.39s
global_step/sec: 13.1378
loss = 1090.562744140625, steps = 200, cost time = 7.61s
global_step/sec: 14.4864
loss = 1215.529541015625, steps = 300, cost time = 6.90s
global_step/sec: 16.1190
loss = 992.3623657226562, steps = 400, cost time = 6.20s
global_step/sec: 14.5071
loss = 1267.626708984375, steps = 500, cost time = 6.89s
global_step/sec: 13.5031
loss = 1117.842529296875, steps = 600, cost time = 7.41s
global_step/sec: 14.8525
loss = 965.70849609375, steps = 700, cost time = 6.73s
global_step/sec: 14.5983
loss = 1185.270751953125, steps = 800, cost time = 6.85s
global_step/sec: 14.8992
loss = 1190.9232177734375, steps = 900, cost time = 6.71s
global_step/sec: 14.8507
loss = 1101.32421875, steps = 1000, cost time = 6.73s
global_step/sec: 13.7376
loss = 1196.32177734375, steps = 1100, cost time = 7.28s
global_step/sec: 14.1331
loss = 1260.17431640625, steps = 1200, cost time = 7.08s
global_step/sec: 14.9166
loss = 1093.915283203125, steps = 1300, cost time = 6.70s
global_step/sec: 14.0673
loss = 986.9241333007812, steps = 1400, cost time = 7.11s
global_step/sec: 13.8412
loss = 1220.89013671875, steps = 1500, cost time = 7.22s
global_step/sec: 14.1730
loss = 1246.417236328125, steps = 1600, cost time = 7.06s
global_step/sec: 15.0311
loss = 1175.7803955078125, steps = 1700, cost time = 6.65s
global_step/sec: 13.4170
loss = 1011.3657836914062, steps = 1800, cost time = 7.45s
global_step/sec: 13.4719
loss = 1278.292724609375, steps = 1900, cost time = 7.42s
global_step/sec: 14.6730
loss = 1156.33056640625, steps = 2000, cost time = 6.82s
global_step/sec: 14.0685
loss = 1323.383544921875, steps = 2100, cost time = 7.11s
global_step/sec: 16.2639
loss = 1105.3544921875, steps = 2200, cost time = 6.15s
global_step/sec: 15.7173
loss = 1232.8681640625, steps = 2300, cost time = 6.36s
global_step/sec: 14.6095
loss = 1258.5421142578125, steps = 2400, cost time = 6.84s
global_step/sec: 14.3194
loss = 1004.4905395507812, steps = 2500, cost time = 6.98s
global_step/sec: 14.2075
loss = 1168.6826171875, steps = 2600, cost time = 7.04s
global_step/sec: 14.8167
loss = 1168.640380859375, steps = 2700, cost time = 6.75s
global_step/sec: 15.9708
loss = 1187.753662109375, steps = 2800, cost time = 6.26s
global_step/sec: 15.4108
loss = 1124.0128173828125, steps = 2900, cost time = 6.49s
global_step/sec: 15.0106
loss = 1123.9786376953125, steps = 3000, cost time = 6.66s
global_step/sec: 15.0991
loss = 1130.2933349609375, steps = 3100, cost time = 6.62s
global_step/sec: 14.4239
loss = 1117.5699462890625, steps = 3200, cost time = 6.93s
global_step/sec: 16.1159
loss = 1117.5439453125, steps = 3300, cost time = 6.21s
global_step/sec: 13.9785
loss = 1296.896240234375, steps = 3400, cost time = 7.15s
global_step/sec: 15.7031
loss = 1187.5433349609375, steps = 3500, cost time = 6.37s
global_step/sec: 16.5389
loss = 1174.7396240234375, steps = 3600, cost time = 6.05s
global_step/sec: 14.5573
loss = 1174.71630859375, steps = 3700, cost time = 6.87s
global_step/sec: 14.8511
loss = 979.10302734375, steps = 3800, cost time = 6.73s
global_step/sec: 16.0320
loss = 1168.296875, steps = 3900, cost time = 6.24s
global_step/sec: 14.9172
loss = 1245.162841796875, steps = 4000, cost time = 6.70s
global_step/sec: 14.2661
loss = 1054.1983642578125, steps = 4100, cost time = 7.01s
global_step/sec: 16.0635
loss = 1066.779296875, steps = 4200, cost time = 6.23s
global_step/sec: 12.3340
loss = 966.568603515625, steps = 4300, cost time = 8.11s
global_step/sec: 12.3245
loss = 1322.6146240234375, steps = 4400, cost time = 8.11s
global_step/sec: 13.7930
loss = 1329.087646484375, steps = 4500, cost time = 7.25s
global_step/sec: 13.3529
loss = 1142.7127685546875, steps = 4600, cost time = 7.49s
global_step/sec: 13.2424
loss = 1110.95361328125, steps = 4700, cost time = 7.55s
global_step/sec: 13.0284
loss = 1073.007568359375, steps = 4800, cost time = 7.68s
global_step/sec: 14.3687
loss = 1168.1583251953125, steps = 4900, cost time = 6.96s
global_step/sec: 13.3551
loss = 972.7105102539062, steps = 5000, cost time = 7.49s
global_step/sec: 12.2564
loss = 1129.945068359375, steps = 5100, cost time = 8.16s
global_step/sec: 11.1337
loss = 1149.0107421875, steps = 5200, cost time = 8.98s
global_step/sec: 11.1160
loss = 1180.89208984375, steps = 5300, cost time = 9.00s
global_step/sec: 11.0021
loss = 1219.295654296875, steps = 5400, cost time = 9.09s
global_step/sec: 11.1501
loss = 1316.015625, steps = 5500, cost time = 8.97s
global_step/sec: 10.8271
loss = 1219.28125, steps = 5600, cost time = 9.24s
global_step/sec: 11.1242
loss = 1028.889404296875, steps = 5700, cost time = 8.99s
global_step/sec: 11.2857
loss = 1187.2421875, steps = 5800, cost time = 8.86s
global_step/sec: 11.3131
loss = 1136.2337646484375, steps = 5900, cost time = 8.84s
global_step/sec: 10.7145
loss = 1142.5860595703125, steps = 6000, cost time = 9.33s
global_step/sec: 10.9769
loss = 1200.018798828125, steps = 6100, cost time = 9.11s
global_step/sec: 10.8371
loss = 1110.8280029296875, steps = 6200, cost time = 9.23s
global_step/sec: 10.9107
loss = 1010.053955078125, steps = 6300, cost time = 9.17s
global_step/sec: 11.0810
loss = 1104.480712890625, steps = 6400, cost time = 9.02s
global_step/sec: 11.3276
loss = 1098.14453125, steps = 6500, cost time = 8.83s
global_step/sec: 11.1366
loss = 1187.192138671875, steps = 6600, cost time = 8.98s
global_step/sec: 11.7867
loss = 1283.5936279296875, steps = 6700, cost time = 8.48s
global_step/sec: 11.4387
loss = 1168.0224609375, steps = 6800, cost time = 8.74s
global_step/sec: 11.8736
loss = 1168.0198974609375, steps = 6900, cost time = 8.42s
global_step/sec: 11.3504
loss = 1212.7847900390625, steps = 7000, cost time = 8.81s
global_step/sec: 11.8835
loss = 1199.9671630859375, steps = 7100, cost time = 8.42s
global_step/sec: 11.3288
loss = 1129.810546875, steps = 7200, cost time = 8.83s
global_step/sec: 11.6603
loss = 1091.783203125, steps = 7300, cost time = 8.58s
global_step/sec: 11.6903
loss = 1129.802490234375, steps = 7400, cost time = 8.55s
global_step/sec: 11.6087
loss = 1016.258544921875, steps = 7500, cost time = 8.61s
global_step/sec: 10.9845
loss = 1136.149658203125, steps = 7600, cost time = 9.10s
global_step/sec: 11.2105
loss = 1193.54443359375, steps = 7700, cost time = 8.92s
global_step/sec: 10.4192
loss = 1167.983642578125, steps = 7800, cost time = 9.60s
global_step/sec: 10.8429
loss = 1085.440673828125, steps = 7900, cost time = 9.22s
global_step/sec: 10.8313
loss = 1193.5328369140625, steps = 8000, cost time = 9.23s
global_step/sec: 10.5805
loss = 1041.33056640625, steps = 8100, cost time = 9.45s
global_step/sec: 10.8904
loss = 1206.331298828125, steps = 8200, cost time = 9.18s
global_step/sec: 11.6301
loss = 1354.8377685546875, steps = 8300, cost time = 8.60s
global_step/sec: 10.4830
loss = 997.4666748046875, steps = 8400, cost time = 9.54s
global_step/sec: 10.8925
loss = 1136.1219482421875, steps = 8500, cost time = 9.18s
global_step/sec: 11.4579
loss = 1174.34130859375, steps = 8600, cost time = 8.73s
global_step/sec: 11.3996
loss = 1219.1417236328125, steps = 8700, cost time = 8.77s
global_step/sec: 11.8869
loss = 1219.1405029296875, steps = 8800, cost time = 8.41s
global_step/sec: 10.9866
loss = 1110.724365234375, steps = 8900, cost time = 9.10s
global_step/sec: 10.7903
loss = 960.064697265625, steps = 9000, cost time = 9.27s
global_step/sec: 11.6217
loss = 1206.3089599609375, steps = 9100, cost time = 8.60s
global_step/sec: 12.3722
loss = 1296.439453125, steps = 9200, cost time = 8.08s
global_step/sec: 11.1150
loss = 1091.7259521484375, steps = 9300, cost time = 9.00s
global_step/sec: 10.9646
loss = 1167.941162109375, steps = 9400, cost time = 9.12s
global_step/sec: 11.2697
loss = 1277.0445556640625, steps = 9500, cost time = 8.87s
global_step/sec: 11.4628
loss = 1257.698974609375, steps = 9600, cost time = 8.72s
global_step/sec: 11.0116
loss = 1296.429931640625, steps = 9700, cost time = 9.08s
global_step/sec: 10.6618
loss = 1072.768798828125, steps = 9800, cost time = 9.38s
global_step/sec: 11.0601
loss = 1110.703857421875, steps = 9900, cost time = 9.04s
global_step/sec: 11.2896
loss = 1136.09033203125, steps = 10000, cost time = 8.86s
global_step/sec: 10.9184
loss = 1433.1632080078125, steps = 10100, cost time = 9.16s
global_step/sec: 11.2571
loss = 1123.3831787109375, steps = 10200, cost time = 8.88s
global_step/sec: 11.0636
loss = 1104.36376953125, steps = 10300, cost time = 9.04s
global_step/sec: 10.9373
loss = 1212.6964111328125, steps = 10400, cost time = 9.14s
global_step/sec: 10.8760
loss = 1034.9990234375, steps = 10500, cost time = 9.19s
global_step/sec: 11.0314
loss = 1148.804443359375, steps = 10600, cost time = 9.07s
global_step/sec: 11.2226
loss = 1110.692626953125, steps = 10700, cost time = 8.91s
global_step/sec: 10.8054
loss = 1060.145751953125, steps = 10800, cost time = 9.25s
global_step/sec: 10.8165
loss = 1187.07666015625, steps = 10900, cost time = 9.25s
global_step/sec: 10.9078
loss = 1098.0234375, steps = 11000, cost time = 9.17s
global_step/sec: 11.2335
loss = 1034.9918212890625, steps = 11100, cost time = 8.90s
global_step/sec: 10.7243
loss = 1148.7952880859375, steps = 11200, cost time = 9.32s
global_step/sec: 11.1625
loss = 1079.0582275390625, steps = 11300, cost time = 8.96s
global_step/sec: 10.8686
loss = 1148.7943115234375, steps = 11400, cost time = 9.20s
global_step/sec: 10.8612
loss = 1180.6787109375, steps = 11500, cost time = 9.21s
global_step/sec: 10.6754
loss = 1193.4652099609375, steps = 11600, cost time = 9.37s
global_step/sec: 11.0568
loss = 1117.01806640625, steps = 11700, cost time = 9.04s
global_step/sec: 11.0309
loss = 1167.9058837890625, steps = 11800, cost time = 9.07s
global_step/sec: 11.0865
loss = 1155.15576171875, steps = 11900, cost time = 9.02s
global_step/sec: 10.6478
loss = 1174.2867431640625, steps = 12000, cost time = 9.39s
global_step/sec: 11.1140
loss = 1174.28564453125, steps = 12100, cost time = 9.00s
global_step/sec: 10.5973
loss = 1193.458251953125, steps = 12200, cost time = 9.44s
global_step/sec: 18887.9386
loss = 23.040794372558594, steps = 12207, cost time = 0.65s
Evaluation complate:[3/3]
ACC = 0.9124000072479248
AUC = 0.5031068325042725
