INFO:tensorflow:Parsing ./data/taobao_train_data
INFO:tensorflow:Parsing ./data/taobao_test_data
2022-03-24 10:56:03.726785: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3400000000 Hz
2022-03-24 10:56:03.754145: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5732df0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-03-24 10:56:03.754194: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Using TensorFlow version 1.15.5
Checking dataset
Numbers of training dataset is 50000
Numbers of test dataset is 10000
Saving model checkpoints to /benchmark_result/checkpoint/2022-03-24-15-57-35/dssm_deeprec_fp32
global_step/sec: 23.7172
loss = 1914.4189453125, steps = 0, cost time = 4.22s
global_step/sec: 30.1976
loss = 1216.061767578125, steps = 100, cost time = 3.31s
global_step/sec: 25.1451
loss = 1090.305419921875, steps = 200, cost time = 3.98s
global_step/sec: 30.3672
loss = 1212.26220703125, steps = 300, cost time = 3.29s
global_step/sec: 27.6643
loss = 990.11474609375, steps = 400, cost time = 3.61s
global_step/sec: 32.6305
loss = 1265.5103759765625, steps = 500, cost time = 3.06s
global_step/sec: 30.5648
loss = 1116.58203125, steps = 600, cost time = 3.27s
global_step/sec: 28.3769
loss = 964.7364501953125, steps = 700, cost time = 3.52s
global_step/sec: 28.1016
loss = 1184.453857421875, steps = 800, cost time = 3.56s
global_step/sec: 24.6918
loss = 1190.231201171875, steps = 900, cost time = 4.05s
global_step/sec: 25.3922
loss = 1100.732666015625, steps = 1000, cost time = 3.94s
global_step/sec: 24.4807
loss = 1195.800537109375, steps = 1100, cost time = 4.08s
global_step/sec: 24.4779
loss = 1259.7158203125, steps = 1200, cost time = 4.09s
global_step/sec: 25.0408
loss = 1093.4990234375, steps = 1300, cost time = 3.99s
global_step/sec: 26.4020
loss = 986.5545043945312, steps = 1400, cost time = 3.79s
global_step/sec: 25.8904
loss = 1220.547119140625, steps = 1500, cost time = 3.86s
global_step/sec: 26.2136
loss = 1246.111572265625, steps = 1600, cost time = 3.81s
global_step/sec: 26.2834
loss = 1175.486572265625, steps = 1700, cost time = 3.80s
global_step/sec: 27.3594
loss = 1011.0045166015625, steps = 1800, cost time = 3.66s
global_step/sec: 24.6951
loss = 1278.0068359375, steps = 1900, cost time = 4.05s
global_step/sec: 24.9787
loss = 1156.0791015625, steps = 2000, cost time = 4.00s
global_step/sec: 27.2503
loss = 1323.160888671875, steps = 2100, cost time = 3.67s
global_step/sec: 26.6208
loss = 1105.129638671875, steps = 2200, cost time = 3.76s
global_step/sec: 25.7144
loss = 1232.657958984375, steps = 2300, cost time = 3.89s
global_step/sec: 27.1388
loss = 1258.343017578125, steps = 2400, cost time = 3.68s
global_step/sec: 24.0119
loss = 1004.291259765625, steps = 2500, cost time = 4.16s
global_step/sec: 26.8174
loss = 1168.498046875, steps = 2600, cost time = 3.73s
global_step/sec: 24.6212
loss = 1168.4566650390625, steps = 2700, cost time = 4.06s
global_step/sec: 26.1520
loss = 1187.593505859375, steps = 2800, cost time = 3.82s
global_step/sec: 26.6292
loss = 1123.85009765625, steps = 2900, cost time = 3.76s
global_step/sec: 25.8608
loss = 1123.816162109375, steps = 3000, cost time = 3.87s
global_step/sec: 24.6580
loss = 1130.140625, steps = 3100, cost time = 4.06s
global_step/sec: 26.5592
loss = 1117.4197998046875, steps = 3200, cost time = 3.77s
global_step/sec: 26.1535
loss = 1117.39404296875, steps = 3300, cost time = 3.82s
global_step/sec: 24.9334
loss = 1296.7509765625, steps = 3400, cost time = 4.01s
global_step/sec: 25.6239
loss = 1187.408447265625, steps = 3500, cost time = 3.90s
global_step/sec: 25.5475
loss = 1174.6036376953125, steps = 3600, cost time = 3.91s
global_step/sec: 25.8509
loss = 1174.5845947265625, steps = 3700, cost time = 3.87s
global_step/sec: 24.6345
loss = 978.974365234375, steps = 3800, cost time = 4.06s
global_step/sec: 26.3581
loss = 1168.1715087890625, steps = 3900, cost time = 3.79s
global_step/sec: 27.4142
loss = 1245.0421142578125, steps = 4000, cost time = 3.65s
global_step/sec: 24.1992
loss = 1054.0771484375, steps = 4100, cost time = 4.13s
global_step/sec: 24.6703
loss = 1066.662841796875, steps = 4200, cost time = 4.05s
global_step/sec: 25.8621
loss = 966.4497680664062, steps = 4300, cost time = 3.87s
global_step/sec: 25.6991
loss = 1322.508056640625, steps = 4400, cost time = 3.89s
global_step/sec: 28.1980
loss = 1328.976318359375, steps = 4500, cost time = 3.55s
global_step/sec: 27.0352
loss = 1142.604736328125, steps = 4600, cost time = 3.70s
global_step/sec: 26.1641
loss = 1110.8446044921875, steps = 4700, cost time = 3.82s
global_step/sec: 25.1216
loss = 1072.8984375, steps = 4800, cost time = 3.98s
global_step/sec: 24.1612
loss = 1168.056640625, steps = 4900, cost time = 4.14s
global_step/sec: 24.0839
loss = 972.6004638671875, steps = 5000, cost time = 4.15s
global_step/sec: 26.5716
loss = 1129.841552734375, steps = 5100, cost time = 3.76s
global_step/sec: 24.9554
loss = 1148.9097900390625, steps = 5200, cost time = 4.01s
global_step/sec: 25.3600
loss = 1180.791015625, steps = 5300, cost time = 3.94s
global_step/sec: 24.8090
loss = 1219.196533203125, steps = 5400, cost time = 4.03s
global_step/sec: 29.1697
loss = 1315.9173583984375, steps = 5500, cost time = 3.43s
global_step/sec: 28.1701
loss = 1219.185546875, steps = 5600, cost time = 3.55s
global_step/sec: 28.6292
loss = 1028.7974853515625, steps = 5700, cost time = 3.49s
global_step/sec: 28.1617
loss = 1187.1478271484375, steps = 5800, cost time = 3.55s
global_step/sec: 29.8056
loss = 1136.142822265625, steps = 5900, cost time = 3.36s
global_step/sec: 28.7035
loss = 1142.4930419921875, steps = 6000, cost time = 3.48s
global_step/sec: 28.9793
loss = 1199.927001953125, steps = 6100, cost time = 3.45s
global_step/sec: 28.0000
loss = 1110.73779296875, steps = 6200, cost time = 3.57s
global_step/sec: 28.4611
loss = 1009.9669799804688, steps = 6300, cost time = 3.51s
global_step/sec: 31.7535
loss = 1104.39208984375, steps = 6400, cost time = 3.15s
global_step/sec: 28.4000
loss = 1098.056884765625, steps = 6500, cost time = 3.52s
global_step/sec: 26.8878
loss = 1187.1087646484375, steps = 6600, cost time = 3.72s
global_step/sec: 28.7329
loss = 1283.506103515625, steps = 6700, cost time = 3.48s
global_step/sec: 30.5941
loss = 1167.938720703125, steps = 6800, cost time = 3.27s
global_step/sec: 30.1424
loss = 1167.935302734375, steps = 6900, cost time = 3.32s
global_step/sec: 29.3813
loss = 1212.69921875, steps = 7000, cost time = 3.40s
global_step/sec: 24.2352
loss = 1199.8851318359375, steps = 7100, cost time = 4.13s
global_step/sec: 17.1015
loss = 1129.728759765625, steps = 7200, cost time = 5.85s
global_step/sec: 17.5370
loss = 1091.7008056640625, steps = 7300, cost time = 5.70s
global_step/sec: 17.7371
loss = 1129.72265625, steps = 7400, cost time = 5.64s
global_step/sec: 20.3815
loss = 1016.1796875, steps = 7500, cost time = 4.91s
global_step/sec: 22.3846
loss = 1136.071044921875, steps = 7600, cost time = 4.47s
global_step/sec: 18.6833
loss = 1193.46240234375, steps = 7700, cost time = 5.35s
global_step/sec: 17.8939
loss = 1167.903564453125, steps = 7800, cost time = 5.59s
global_step/sec: 17.7085
loss = 1085.3604736328125, steps = 7900, cost time = 5.65s
global_step/sec: 18.4955
loss = 1193.455078125, steps = 8000, cost time = 5.41s
global_step/sec: 18.1580
loss = 1041.25390625, steps = 8100, cost time = 5.51s
global_step/sec: 18.1023
loss = 1206.258544921875, steps = 8200, cost time = 5.52s
global_step/sec: 17.8791
loss = 1354.763916015625, steps = 8300, cost time = 5.59s
global_step/sec: 19.1920
loss = 997.3911743164062, steps = 8400, cost time = 5.21s
global_step/sec: 15.9078
loss = 1136.047607421875, steps = 8500, cost time = 6.29s
global_step/sec: 18.7341
loss = 1174.26611328125, steps = 8600, cost time = 5.34s
global_step/sec: 18.6234
loss = 1219.0657958984375, steps = 8700, cost time = 5.37s
global_step/sec: 16.9297
loss = 1219.065185546875, steps = 8800, cost time = 5.91s
global_step/sec: 18.2939
loss = 1110.6513671875, steps = 8900, cost time = 5.47s
global_step/sec: 17.7581
loss = 959.989990234375, steps = 9000, cost time = 5.63s
global_step/sec: 17.8675
loss = 1206.2352294921875, steps = 9100, cost time = 5.60s
global_step/sec: 18.5222
loss = 1296.365478515625, steps = 9200, cost time = 5.40s
global_step/sec: 16.6612
loss = 1091.651123046875, steps = 9300, cost time = 6.00s
global_step/sec: 17.2974
loss = 1167.868896484375, steps = 9400, cost time = 5.78s
global_step/sec: 17.4772
loss = 1276.9752197265625, steps = 9500, cost time = 5.72s
global_step/sec: 18.8744
loss = 1257.6251220703125, steps = 9600, cost time = 5.30s
global_step/sec: 17.5855
loss = 1296.35546875, steps = 9700, cost time = 5.69s
global_step/sec: 19.1359
loss = 1072.695556640625, steps = 9800, cost time = 5.23s
global_step/sec: 19.8655
loss = 1110.63330078125, steps = 9900, cost time = 5.03s
global_step/sec: 18.6120
loss = 1136.018310546875, steps = 10000, cost time = 5.37s
global_step/sec: 17.5490
loss = 1433.087158203125, steps = 10100, cost time = 5.70s
global_step/sec: 16.9205
loss = 1123.310791015625, steps = 10200, cost time = 5.91s
global_step/sec: 17.2393
loss = 1104.2978515625, steps = 10300, cost time = 5.80s
global_step/sec: 17.4940
loss = 1212.6279296875, steps = 10400, cost time = 5.72s
global_step/sec: 19.9831
loss = 1034.929931640625, steps = 10500, cost time = 5.00s
global_step/sec: 19.9900
loss = 1148.732177734375, steps = 10600, cost time = 5.00s
global_step/sec: 19.1854
loss = 1110.6226806640625, steps = 10700, cost time = 5.21s
global_step/sec: 18.2586
loss = 1060.077392578125, steps = 10800, cost time = 5.48s
global_step/sec: 19.1087
loss = 1187.009033203125, steps = 10900, cost time = 5.23s
global_step/sec: 17.9212
loss = 1097.9530029296875, steps = 11000, cost time = 5.58s
global_step/sec: 18.0962
loss = 1034.920654296875, steps = 11100, cost time = 5.53s
global_step/sec: 19.4397
loss = 1148.7265625, steps = 11200, cost time = 5.14s
global_step/sec: 17.0613
loss = 1078.990966796875, steps = 11300, cost time = 5.86s
global_step/sec: 19.2847
loss = 1148.724609375, steps = 11400, cost time = 5.19s
global_step/sec: 19.1748
loss = 1180.609375, steps = 11500, cost time = 5.22s
global_step/sec: 18.4860
loss = 1193.397216796875, steps = 11600, cost time = 5.41s
global_step/sec: 17.9984
loss = 1116.9515380859375, steps = 11700, cost time = 5.56s
global_step/sec: 17.8436
loss = 1167.837890625, steps = 11800, cost time = 5.60s
global_step/sec: 22.6541
loss = 1155.087890625, steps = 11900, cost time = 4.41s
global_step/sec: 19.0734
loss = 1174.218505859375, steps = 12000, cost time = 5.24s
global_step/sec: 17.1863
loss = 1174.21728515625, steps = 12100, cost time = 5.82s
global_step/sec: 18.6077
loss = 1193.390625, steps = 12200, cost time = 5.37s
global_step/sec: 41290.7346
loss = 23.045936584472656, steps = 12207, cost time = 0.30s
Evaluation complate:[3/3]
ACC = 0.9319000244140625
AUC = 0.5021907091140747
