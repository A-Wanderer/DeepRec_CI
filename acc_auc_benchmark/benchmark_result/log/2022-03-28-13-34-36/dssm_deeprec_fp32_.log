INFO:tensorflow:Parsing ./data/taobao_train_data
INFO:tensorflow:Parsing ./data/taobao_test_data
2022-03-28 07:49:44.226222: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3400000000 Hz
2022-03-28 07:49:44.229072: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3f65f50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-03-28 07:49:44.229116: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Using TensorFlow version 1.15.5
Checking dataset
Numbers of training dataset is 50000
Numbers of test dataset is 10000
Saving model checkpoints to /benchmark_result/checkpoint/2022-03-28-13-34-36/dssm_deeprec_fp32_
global_step/sec: 24.4932
loss = 1912.866943359375, steps = 0, cost time = 4.08s
loss = 1912.866943359375, steps = 0
global_step/sec: 27.9235
loss = 1276.251708984375, steps = 100, cost time = 3.58s
loss = 1276.251708984375, steps = 100
global_step/sec: 23.9893
loss = 1117.477783203125, steps = 200, cost time = 4.17s
loss = 1117.477783203125, steps = 200
global_step/sec: 33.1737
loss = 1212.6568603515625, steps = 300, cost time = 3.01s
loss = 1212.6568603515625, steps = 300
global_step/sec: 27.9614
loss = 987.6976318359375, steps = 400, cost time = 3.58s
loss = 987.6976318359375, steps = 400
global_step/sec: 28.2094
loss = 1263.4034423828125, steps = 500, cost time = 3.54s
loss = 1263.4034423828125, steps = 500
global_step/sec: 27.9150
loss = 1114.9305419921875, steps = 600, cost time = 3.58s
loss = 1114.9305419921875, steps = 600
global_step/sec: 27.4059
loss = 964.5444946289062, steps = 700, cost time = 3.65s
loss = 964.5444946289062, steps = 700
global_step/sec: 28.1103
loss = 1183.498291015625, steps = 800, cost time = 3.56s
loss = 1183.498291015625, steps = 800
global_step/sec: 28.5107
loss = 1189.31201171875, steps = 900, cost time = 3.51s
loss = 1189.31201171875, steps = 900
global_step/sec: 28.3315
loss = 1099.953369140625, steps = 1000, cost time = 3.53s
loss = 1099.953369140625, steps = 1000
global_step/sec: 28.0177
loss = 1195.0467529296875, steps = 1100, cost time = 3.57s
loss = 1195.0467529296875, steps = 1100
global_step/sec: 27.8416
loss = 1259.039794921875, steps = 1200, cost time = 3.59s
loss = 1259.039794921875, steps = 1200
global_step/sec: 27.8790
loss = 1092.89892578125, steps = 1300, cost time = 3.59s
loss = 1092.89892578125, steps = 1300
global_step/sec: 28.1790
loss = 985.9835205078125, steps = 1400, cost time = 3.55s
loss = 985.9835205078125, steps = 1400
global_step/sec: 28.5571
loss = 1220.029296875, steps = 1500, cost time = 3.50s
loss = 1220.029296875, steps = 1500
global_step/sec: 28.6149
loss = 1245.619873046875, steps = 1600, cost time = 3.49s
loss = 1245.619873046875, steps = 1600
global_step/sec: 28.1210
loss = 1175.039794921875, steps = 1700, cost time = 3.56s
loss = 1175.039794921875, steps = 1700
global_step/sec: 28.0519
loss = 1010.5833740234375, steps = 1800, cost time = 3.56s
loss = 1010.5833740234375, steps = 1800
global_step/sec: 28.2718
loss = 1277.635009765625, steps = 1900, cost time = 3.54s
loss = 1277.635009765625, steps = 1900
global_step/sec: 27.8689
loss = 1155.7073974609375, steps = 2000, cost time = 3.59s
loss = 1155.7073974609375, steps = 2000
global_step/sec: 27.6690
loss = 1322.796630859375, steps = 2100, cost time = 3.61s
loss = 1322.796630859375, steps = 2100
global_step/sec: 28.3331
loss = 1104.788818359375, steps = 2200, cost time = 3.53s
loss = 1104.788818359375, steps = 2200
global_step/sec: 27.9644
loss = 1232.35595703125, steps = 2300, cost time = 3.58s
loss = 1232.35595703125, steps = 2300
global_step/sec: 27.5980
loss = 1258.053955078125, steps = 2400, cost time = 3.62s
loss = 1258.053955078125, steps = 2400
global_step/sec: 28.1334
loss = 1004.0270385742188, steps = 2500, cost time = 3.55s
loss = 1004.0270385742188, steps = 2500
global_step/sec: 28.1699
loss = 1168.2171630859375, steps = 2600, cost time = 3.55s
loss = 1168.2171630859375, steps = 2600
global_step/sec: 28.1375
loss = 1168.190673828125, steps = 2700, cost time = 3.55s
loss = 1168.190673828125, steps = 2700
global_step/sec: 27.7086
loss = 1187.3232421875, steps = 2800, cost time = 3.61s
loss = 1187.3232421875, steps = 2800
global_step/sec: 28.1130
loss = 1123.601318359375, steps = 2900, cost time = 3.56s
loss = 1123.601318359375, steps = 2900
global_step/sec: 28.5500
loss = 1123.585205078125, steps = 3000, cost time = 3.50s
loss = 1123.585205078125, steps = 3000
global_step/sec: 27.8767
loss = 1129.9111328125, steps = 3100, cost time = 3.59s
loss = 1129.9111328125, steps = 3100
global_step/sec: 27.9479
loss = 1117.1922607421875, steps = 3200, cost time = 3.58s
loss = 1117.1922607421875, steps = 3200
global_step/sec: 27.5135
loss = 1117.17724609375, steps = 3300, cost time = 3.63s
loss = 1117.17724609375, steps = 3300
global_step/sec: 28.3433
loss = 1296.550537109375, steps = 3400, cost time = 3.53s
loss = 1296.550537109375, steps = 3400
global_step/sec: 27.9081
loss = 1187.2001953125, steps = 3500, cost time = 3.58s
loss = 1187.2001953125, steps = 3500
global_step/sec: 28.2985
loss = 1174.403076171875, steps = 3600, cost time = 3.53s
loss = 1174.403076171875, steps = 3600
global_step/sec: 28.0550
loss = 1174.39453125, steps = 3700, cost time = 3.56s
loss = 1174.39453125, steps = 3700
global_step/sec: 27.9024
loss = 978.776611328125, steps = 3800, cost time = 3.58s
loss = 978.776611328125, steps = 3800
global_step/sec: 27.9357
loss = 1167.979736328125, steps = 3900, cost time = 3.58s
loss = 1167.979736328125, steps = 3900
global_step/sec: 28.2021
loss = 1244.857421875, steps = 4000, cost time = 3.55s
loss = 1244.857421875, steps = 4000
global_step/sec: 28.3855
loss = 1053.8984375, steps = 4100, cost time = 3.52s
loss = 1053.8984375, steps = 4100
global_step/sec: 27.9910
loss = 1066.4814453125, steps = 4200, cost time = 3.57s
loss = 1066.4814453125, steps = 4200
global_step/sec: 27.8266
loss = 966.272705078125, steps = 4300, cost time = 3.59s
loss = 966.272705078125, steps = 4300
global_step/sec: 28.3849
loss = 1322.3359375, steps = 4400, cost time = 3.52s
loss = 1322.3359375, steps = 4400
global_step/sec: 27.8493
loss = 1328.8095703125, steps = 4500, cost time = 3.59s
loss = 1328.8095703125, steps = 4500
global_step/sec: 27.9831
loss = 1142.468505859375, steps = 4600, cost time = 3.57s
loss = 1142.468505859375, steps = 4600
global_step/sec: 27.9614
loss = 1110.6826171875, steps = 4700, cost time = 3.58s
loss = 1110.6826171875, steps = 4700
global_step/sec: 27.7503
loss = 1072.7396240234375, steps = 4800, cost time = 3.60s
loss = 1072.7396240234375, steps = 4800
global_step/sec: 28.0809
loss = 1167.89501953125, steps = 4900, cost time = 3.56s
loss = 1167.89501953125, steps = 4900
global_step/sec: 28.3387
loss = 972.4485473632812, steps = 5000, cost time = 3.53s
loss = 972.4485473632812, steps = 5000
global_step/sec: 27.9059
loss = 1129.691650390625, steps = 5100, cost time = 3.58s
loss = 1129.691650390625, steps = 5100
global_step/sec: 28.1966
loss = 1148.7578125, steps = 5200, cost time = 3.55s
loss = 1148.7578125, steps = 5200
global_step/sec: 27.9940
loss = 1180.63916015625, steps = 5300, cost time = 3.57s
loss = 1180.63916015625, steps = 5300
global_step/sec: 28.3158
loss = 1219.0516357421875, steps = 5400, cost time = 3.53s
loss = 1219.0516357421875, steps = 5400
global_step/sec: 28.0281
loss = 1315.771484375, steps = 5500, cost time = 3.57s
loss = 1315.771484375, steps = 5500
global_step/sec: 27.8653
loss = 1219.051025390625, steps = 5600, cost time = 3.59s
loss = 1219.051025390625, steps = 5600
global_step/sec: 28.2096
loss = 1028.65283203125, steps = 5700, cost time = 3.54s
loss = 1028.65283203125, steps = 5700
global_step/sec: 28.0127
loss = 1187.0047607421875, steps = 5800, cost time = 3.57s
loss = 1187.0047607421875, steps = 5800
global_step/sec: 28.0416
loss = 1136.002197265625, steps = 5900, cost time = 3.57s
loss = 1136.002197265625, steps = 5900
global_step/sec: 28.2076
loss = 1142.356201171875, steps = 6000, cost time = 3.55s
loss = 1142.356201171875, steps = 6000
global_step/sec: 28.5693
loss = 1199.79248046875, steps = 6100, cost time = 3.50s
loss = 1199.79248046875, steps = 6100
global_step/sec: 28.5271
loss = 1110.6068115234375, steps = 6200, cost time = 3.51s
loss = 1110.6068115234375, steps = 6200
global_step/sec: 28.0377
loss = 1009.8328857421875, steps = 6300, cost time = 3.57s
loss = 1009.8328857421875, steps = 6300
global_step/sec: 28.0551
loss = 1104.2615966796875, steps = 6400, cost time = 3.56s
loss = 1104.2615966796875, steps = 6400
global_step/sec: 27.6387
loss = 1097.927001953125, steps = 6500, cost time = 3.62s
loss = 1097.927001953125, steps = 6500
global_step/sec: 28.0645
loss = 1186.97900390625, steps = 6600, cost time = 3.56s
loss = 1186.97900390625, steps = 6600
global_step/sec: 28.3737
loss = 1283.379150390625, steps = 6700, cost time = 3.52s
loss = 1283.379150390625, steps = 6700
global_step/sec: 27.4734
loss = 1167.8131103515625, steps = 6800, cost time = 3.64s
loss = 1167.8131103515625, steps = 6800
global_step/sec: 27.4278
loss = 1167.8089599609375, steps = 6900, cost time = 3.65s
loss = 1167.8089599609375, steps = 6900
global_step/sec: 27.7502
loss = 1212.5771484375, steps = 7000, cost time = 3.60s
loss = 1212.5771484375, steps = 7000
global_step/sec: 28.1062
loss = 1199.7666015625, steps = 7100, cost time = 3.56s
loss = 1199.7666015625, steps = 7100
global_step/sec: 28.1054
loss = 1129.6016845703125, steps = 7200, cost time = 3.56s
loss = 1129.6016845703125, steps = 7200
global_step/sec: 27.9529
loss = 1091.5797119140625, steps = 7300, cost time = 3.58s
loss = 1091.5797119140625, steps = 7300
global_step/sec: 28.5720
loss = 1129.5997314453125, steps = 7400, cost time = 3.50s
loss = 1129.5997314453125, steps = 7400
global_step/sec: 28.1487
loss = 1016.0609741210938, steps = 7500, cost time = 3.55s
loss = 1016.0609741210938, steps = 7500
global_step/sec: 28.2075
loss = 1135.950927734375, steps = 7600, cost time = 3.55s
loss = 1135.950927734375, steps = 7600
global_step/sec: 27.7033
loss = 1193.350830078125, steps = 7700, cost time = 3.61s
loss = 1193.350830078125, steps = 7700
global_step/sec: 27.9361
loss = 1167.78662109375, steps = 7800, cost time = 3.58s
loss = 1167.78662109375, steps = 7800
global_step/sec: 28.2897
loss = 1085.24072265625, steps = 7900, cost time = 3.53s
loss = 1085.24072265625, steps = 7900
global_step/sec: 28.5064
loss = 1193.337890625, steps = 8000, cost time = 3.51s
loss = 1193.337890625, steps = 8000
global_step/sec: 28.0150
loss = 1041.1363525390625, steps = 8100, cost time = 3.57s
loss = 1041.1363525390625, steps = 8100
global_step/sec: 28.0537
loss = 1206.1417236328125, steps = 8200, cost time = 3.56s
loss = 1206.1417236328125, steps = 8200
global_step/sec: 28.5792
loss = 1354.645751953125, steps = 8300, cost time = 3.50s
loss = 1354.645751953125, steps = 8300
global_step/sec: 28.2342
loss = 997.2747802734375, steps = 8400, cost time = 3.54s
loss = 997.2747802734375, steps = 8400
global_step/sec: 28.6446
loss = 1135.9425048828125, steps = 8500, cost time = 3.49s
loss = 1135.9425048828125, steps = 8500
global_step/sec: 27.9097
loss = 1174.1533203125, steps = 8600, cost time = 3.58s
loss = 1174.1533203125, steps = 8600
global_step/sec: 28.0045
loss = 1218.9554443359375, steps = 8700, cost time = 3.57s
loss = 1218.9554443359375, steps = 8700
global_step/sec: 28.1800
loss = 1218.95458984375, steps = 8800, cost time = 3.55s
loss = 1218.95458984375, steps = 8800
global_step/sec: 27.8677
loss = 1110.53466796875, steps = 8900, cost time = 3.59s
loss = 1110.53466796875, steps = 8900
global_step/sec: 28.1226
loss = 959.8826904296875, steps = 9000, cost time = 3.56s
loss = 959.8826904296875, steps = 9000
global_step/sec: 28.3048
loss = 1206.1240234375, steps = 9100, cost time = 3.53s
loss = 1206.1240234375, steps = 9100
global_step/sec: 27.8540
loss = 1296.25732421875, steps = 9200, cost time = 3.59s
loss = 1296.25732421875, steps = 9200
global_step/sec: 27.9606
loss = 1091.5423583984375, steps = 9300, cost time = 3.58s
loss = 1091.5423583984375, steps = 9300
global_step/sec: 27.8366
loss = 1167.7574462890625, steps = 9400, cost time = 3.59s
loss = 1167.7574462890625, steps = 9400
global_step/sec: 28.2722
loss = 1276.8612060546875, steps = 9500, cost time = 3.54s
loss = 1276.8612060546875, steps = 9500
global_step/sec: 28.2341
loss = 1257.521728515625, steps = 9600, cost time = 3.54s
loss = 1257.521728515625, steps = 9600
global_step/sec: 28.4410
loss = 1296.2528076171875, steps = 9700, cost time = 3.52s
loss = 1296.2528076171875, steps = 9700
global_step/sec: 28.2671
loss = 1072.5863037109375, steps = 9800, cost time = 3.54s
loss = 1072.5863037109375, steps = 9800
global_step/sec: 28.4089
loss = 1110.52001953125, steps = 9900, cost time = 3.52s
loss = 1110.52001953125, steps = 9900
global_step/sec: 27.7405
loss = 1135.91064453125, steps = 10000, cost time = 3.60s
loss = 1135.91064453125, steps = 10000
global_step/sec: 28.1677
loss = 1432.98486328125, steps = 10100, cost time = 3.55s
loss = 1432.98486328125, steps = 10100
global_step/sec: 27.7039
loss = 1123.206298828125, steps = 10200, cost time = 3.61s
loss = 1123.206298828125, steps = 10200
global_step/sec: 27.8428
loss = 1104.189208984375, steps = 10300, cost time = 3.59s
loss = 1104.189208984375, steps = 10300
global_step/sec: 28.0511
loss = 1212.524169921875, steps = 10400, cost time = 3.56s
loss = 1212.524169921875, steps = 10400
global_step/sec: 27.7874
loss = 1034.830810546875, steps = 10500, cost time = 3.60s
loss = 1034.830810546875, steps = 10500
global_step/sec: 27.8059
loss = 1148.630615234375, steps = 10600, cost time = 3.60s
loss = 1148.630615234375, steps = 10600
global_step/sec: 28.1473
loss = 1110.517578125, steps = 10700, cost time = 3.55s
loss = 1110.517578125, steps = 10700
global_step/sec: 27.7003
loss = 1059.9769287109375, steps = 10800, cost time = 3.61s
loss = 1059.9769287109375, steps = 10800
global_step/sec: 28.2231
loss = 1186.90478515625, steps = 10900, cost time = 3.54s
loss = 1186.90478515625, steps = 10900
global_step/sec: 27.7694
loss = 1097.8466796875, steps = 11000, cost time = 3.60s
loss = 1097.8466796875, steps = 11000
global_step/sec: 28.0467
loss = 1034.8145751953125, steps = 11100, cost time = 3.57s
loss = 1034.8145751953125, steps = 11100
global_step/sec: 28.3368
loss = 1148.6221923828125, steps = 11200, cost time = 3.53s
loss = 1148.6221923828125, steps = 11200
global_step/sec: 28.4391
loss = 1078.884765625, steps = 11300, cost time = 3.52s
loss = 1078.884765625, steps = 11300
global_step/sec: 28.8948
loss = 1148.6229248046875, steps = 11400, cost time = 3.46s
loss = 1148.6229248046875, steps = 11400
global_step/sec: 27.9215
loss = 1180.507080078125, steps = 11500, cost time = 3.58s
loss = 1180.507080078125, steps = 11500
global_step/sec: 27.7349
loss = 1193.2958984375, steps = 11600, cost time = 3.61s
loss = 1193.2958984375, steps = 11600
global_step/sec: 28.3898
loss = 1116.849365234375, steps = 11700, cost time = 3.52s
loss = 1116.849365234375, steps = 11700
global_step/sec: 28.0746
loss = 1167.754638671875, steps = 11800, cost time = 3.56s
loss = 1167.754638671875, steps = 11800
global_step/sec: 28.2819
loss = 1154.988525390625, steps = 11900, cost time = 3.54s
loss = 1154.988525390625, steps = 11900
global_step/sec: 28.0981
loss = 1174.1146240234375, steps = 12000, cost time = 3.56s
loss = 1174.1146240234375, steps = 12000
global_step/sec: 28.4612
loss = 1174.115478515625, steps = 12100, cost time = 3.51s
loss = 1174.115478515625, steps = 12100
global_step/sec: 28.2838
loss = 1193.2900390625, steps = 12200, cost time = 3.54s
loss = 1193.2900390625, steps = 12200
global_step/sec: 59740.3060
loss = 24.787700653076172, steps = 12207, cost time = 0.20s
loss = 24.787700653076172, steps = 12207
Evaluation complate:[3/3]
ACC = 0.9466999769210815
AUC = 0.49968186020851135
