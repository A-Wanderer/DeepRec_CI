WARNING:tensorflow:From train.py:14: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

WARNING:tensorflow:From train.py:14: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

WARNING:tensorflow:From train.py:453: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

INFO:tensorflow:Parsing ./data/taobao_train_data
INFO:tensorflow:Parsing ./data/taobao_test_data
WARNING:tensorflow:From train.py:466: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.

WARNING:tensorflow:From train.py:466: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_types(dataset)`.
WARNING:tensorflow:From train.py:467: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(dataset)`.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:347: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_types(iterator)`.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:348: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(iterator)`.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:350: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_classes(iterator)`.
WARNING:tensorflow:From train.py:261: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From train.py:263: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.

WARNING:tensorflow:From train.py:264: The name tf.feature_column.input_layer is deprecated. Please use tf.compat.v1.feature_column.input_layer instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column.py:206: EmbeddingColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:3182: HashedCategoricalColumn._get_sparse_tensors (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column.py:2158: HashedCategoricalColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:3122: HashedCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column.py:207: EmbeddingColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From train.py:239: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.Dense instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From train.py:243: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).
WARNING:tensorflow:From train.py:128: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From train.py:130: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

WARNING:tensorflow:From train.py:302: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
WARNING:tensorflow:From train.py:304: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From train.py:325: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.

WARNING:tensorflow:From train.py:329: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.

WARNING:tensorflow:From train.py:336: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From train.py:340: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

WARNING:tensorflow:From train.py:340: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

WARNING:tensorflow:From train.py:218: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.

WARNING:tensorflow:From train.py:221: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From train.py:493: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From train.py:526: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2022-03-28 07:09:22.404637: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2022-03-28 07:09:22.422798: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3400000000 Hz
2022-03-28 07:09:22.426325: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1bc9830 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-03-28 07:09:22.426371: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From train.py:527: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From train.py:528: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.

WARNING:tensorflow:From train.py:529: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

WARNING:tensorflow:From train.py:530: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From train.py:531: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From train.py:531: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From train.py:533: The name tf.RunOptions is deprecated. Please use tf.compat.v1.RunOptions instead.

WARNING:tensorflow:From train.py:534: The name tf.RunMetadata is deprecated. Please use tf.compat.v1.RunMetadata instead.

Using TensorFlow version 1.15.5
Checking dataset
Numbers of training dataset is 50000
Numbers of test dataset is 10000
Saving model checkpoints to /benchmark_result/checkpoint/2022-03-28-13-34-36/dssm_tf_fp32_
global_step/sec: 50.4266
loss = 1914.4495849609375, steps = 0, cost time = 1.98s
global_step/sec: 22.1923
loss = 1211.9708251953125, steps = 100, cost time = 4.51s
global_step/sec: 22.8870
loss = 1092.87646484375, steps = 200, cost time = 4.37s
global_step/sec: 22.7418
loss = 1215.25634765625, steps = 300, cost time = 4.40s
global_step/sec: 23.1889
loss = 992.3006591796875, steps = 400, cost time = 4.31s
global_step/sec: 23.1108
loss = 1267.085693359375, steps = 500, cost time = 4.33s
global_step/sec: 23.0470
loss = 1117.7918701171875, steps = 600, cost time = 4.34s
global_step/sec: 23.3070
loss = 965.6820068359375, steps = 700, cost time = 4.29s
global_step/sec: 23.0727
loss = 1185.2528076171875, steps = 800, cost time = 4.33s
global_step/sec: 22.9572
loss = 1191.146240234375, steps = 900, cost time = 4.36s
global_step/sec: 23.1380
loss = 1101.383544921875, steps = 1000, cost time = 4.32s
global_step/sec: 22.9492
loss = 1196.332275390625, steps = 1100, cost time = 4.36s
global_step/sec: 23.1793
loss = 1260.178955078125, steps = 1200, cost time = 4.31s
global_step/sec: 23.0864
loss = 1093.917236328125, steps = 1300, cost time = 4.33s
global_step/sec: 23.3168
loss = 986.9234619140625, steps = 1400, cost time = 4.29s
global_step/sec: 23.3708
loss = 1220.8865966796875, steps = 1500, cost time = 4.28s
global_step/sec: 23.1170
loss = 1246.421630859375, steps = 1600, cost time = 4.33s
global_step/sec: 23.2361
loss = 1175.7772216796875, steps = 1700, cost time = 4.30s
global_step/sec: 23.4962
loss = 1011.281982421875, steps = 1800, cost time = 4.26s
global_step/sec: 23.5260
loss = 1278.2694091796875, steps = 1900, cost time = 4.25s
global_step/sec: 23.5441
loss = 1156.318603515625, steps = 2000, cost time = 4.25s
global_step/sec: 23.1787
loss = 1323.377685546875, steps = 2100, cost time = 4.31s
global_step/sec: 23.1130
loss = 1105.34521484375, steps = 2200, cost time = 4.33s
global_step/sec: 23.3044
loss = 1232.8660888671875, steps = 2300, cost time = 4.29s
global_step/sec: 23.3638
loss = 1258.536376953125, steps = 2400, cost time = 4.28s
global_step/sec: 23.2725
loss = 1004.484619140625, steps = 2500, cost time = 4.30s
global_step/sec: 23.3055
loss = 1168.67919921875, steps = 2600, cost time = 4.29s
global_step/sec: 23.4076
loss = 1168.6328125, steps = 2700, cost time = 4.27s
global_step/sec: 23.2443
loss = 1187.749267578125, steps = 2800, cost time = 4.30s
global_step/sec: 23.4267
loss = 1124.0096435546875, steps = 2900, cost time = 4.27s
global_step/sec: 23.1200
loss = 1123.9755859375, steps = 3000, cost time = 4.33s
global_step/sec: 23.1491
loss = 1130.290771484375, steps = 3100, cost time = 4.32s
global_step/sec: 23.2519
loss = 1117.568359375, steps = 3200, cost time = 4.30s
global_step/sec: 23.4968
loss = 1117.541259765625, steps = 3300, cost time = 4.26s
global_step/sec: 23.3916
loss = 1296.88916015625, steps = 3400, cost time = 4.28s
global_step/sec: 23.6139
loss = 1187.5428466796875, steps = 3500, cost time = 4.23s
global_step/sec: 23.3182
loss = 1174.7374267578125, steps = 3600, cost time = 4.29s
global_step/sec: 23.3981
loss = 1174.71484375, steps = 3700, cost time = 4.27s
global_step/sec: 23.1398
loss = 979.10107421875, steps = 3800, cost time = 4.32s
global_step/sec: 23.2247
loss = 1168.2947998046875, steps = 3900, cost time = 4.31s
global_step/sec: 23.1408
loss = 1245.1597900390625, steps = 4000, cost time = 4.32s
global_step/sec: 23.3717
loss = 1054.196044921875, steps = 4100, cost time = 4.28s
global_step/sec: 23.3367
loss = 1066.77587890625, steps = 4200, cost time = 4.29s
global_step/sec: 23.4557
loss = 966.5653686523438, steps = 4300, cost time = 4.26s
global_step/sec: 23.4882
loss = 1322.61669921875, steps = 4400, cost time = 4.26s
global_step/sec: 23.2042
loss = 1329.087890625, steps = 4500, cost time = 4.31s
global_step/sec: 23.3772
loss = 1142.7099609375, steps = 4600, cost time = 4.28s
global_step/sec: 23.4693
loss = 1110.9521484375, steps = 4700, cost time = 4.26s
global_step/sec: 23.2246
loss = 1073.003173828125, steps = 4800, cost time = 4.31s
global_step/sec: 23.5575
loss = 1168.157958984375, steps = 4900, cost time = 4.24s
global_step/sec: 23.5936
loss = 972.7068481445312, steps = 5000, cost time = 4.24s
global_step/sec: 23.5021
loss = 1129.9422607421875, steps = 5100, cost time = 4.25s
global_step/sec: 23.4305
loss = 1149.008544921875, steps = 5200, cost time = 4.27s
global_step/sec: 23.4535
loss = 1180.887939453125, steps = 5300, cost time = 4.26s
global_step/sec: 23.2144
loss = 1219.2958984375, steps = 5400, cost time = 4.31s
global_step/sec: 24.0145
loss = 1316.0155029296875, steps = 5500, cost time = 4.16s
global_step/sec: 25.2804
loss = 1219.2794189453125, steps = 5600, cost time = 3.96s
global_step/sec: 23.3680
loss = 1028.888427734375, steps = 5700, cost time = 4.28s
global_step/sec: 23.4981
loss = 1187.2420654296875, steps = 5800, cost time = 4.26s
global_step/sec: 23.4063
loss = 1136.23486328125, steps = 5900, cost time = 4.27s
global_step/sec: 23.3254
loss = 1142.58447265625, steps = 6000, cost time = 4.29s
global_step/sec: 23.3625
loss = 1200.0174560546875, steps = 6100, cost time = 4.28s
global_step/sec: 23.2216
loss = 1110.82666015625, steps = 6200, cost time = 4.31s
global_step/sec: 23.3150
loss = 1010.0535888671875, steps = 6300, cost time = 4.29s
global_step/sec: 23.1395
loss = 1104.4801025390625, steps = 6400, cost time = 4.32s
global_step/sec: 26.8299
loss = 1098.14306640625, steps = 6500, cost time = 3.73s
global_step/sec: 26.6524
loss = 1187.192626953125, steps = 6600, cost time = 3.75s
global_step/sec: 27.2321
loss = 1283.591064453125, steps = 6700, cost time = 3.67s
global_step/sec: 27.1202
loss = 1168.02197265625, steps = 6800, cost time = 3.69s
global_step/sec: 26.8487
loss = 1168.018310546875, steps = 6900, cost time = 3.72s
global_step/sec: 27.0621
loss = 1212.782958984375, steps = 7000, cost time = 3.70s
global_step/sec: 26.5856
loss = 1199.965087890625, steps = 7100, cost time = 3.76s
global_step/sec: 23.2272
loss = 1129.809814453125, steps = 7200, cost time = 4.31s
global_step/sec: 23.3223
loss = 1091.782470703125, steps = 7300, cost time = 4.29s
global_step/sec: 23.4650
loss = 1129.802001953125, steps = 7400, cost time = 4.26s
global_step/sec: 23.3763
loss = 1016.2577514648438, steps = 7500, cost time = 4.28s
global_step/sec: 23.3439
loss = 1136.1500244140625, steps = 7600, cost time = 4.28s
global_step/sec: 23.5179
loss = 1193.542724609375, steps = 7700, cost time = 4.25s
global_step/sec: 23.5142
loss = 1167.982177734375, steps = 7800, cost time = 4.25s
global_step/sec: 23.6097
loss = 1085.4403076171875, steps = 7900, cost time = 4.24s
global_step/sec: 23.1846
loss = 1193.532470703125, steps = 8000, cost time = 4.31s
global_step/sec: 23.4139
loss = 1041.3310546875, steps = 8100, cost time = 4.27s
global_step/sec: 23.2083
loss = 1206.330078125, steps = 8200, cost time = 4.31s
global_step/sec: 23.4709
loss = 1354.8370361328125, steps = 8300, cost time = 4.26s
global_step/sec: 23.4751
loss = 997.4663696289062, steps = 8400, cost time = 4.26s
global_step/sec: 23.2097
loss = 1136.120849609375, steps = 8500, cost time = 4.31s
global_step/sec: 23.4376
loss = 1174.3411865234375, steps = 8600, cost time = 4.27s
global_step/sec: 23.4578
loss = 1219.14013671875, steps = 8700, cost time = 4.26s
global_step/sec: 23.3275
loss = 1219.1395263671875, steps = 8800, cost time = 4.29s
global_step/sec: 23.3875
loss = 1110.7220458984375, steps = 8900, cost time = 4.28s
global_step/sec: 23.6121
loss = 960.0645751953125, steps = 9000, cost time = 4.24s
global_step/sec: 23.2323
loss = 1206.30859375, steps = 9100, cost time = 4.30s
global_step/sec: 23.2057
loss = 1296.43603515625, steps = 9200, cost time = 4.31s
global_step/sec: 23.5225
loss = 1091.7254638671875, steps = 9300, cost time = 4.25s
global_step/sec: 23.5013
loss = 1167.939453125, steps = 9400, cost time = 4.26s
global_step/sec: 23.5442
loss = 1277.043701171875, steps = 9500, cost time = 4.25s
global_step/sec: 23.4132
loss = 1257.6964111328125, steps = 9600, cost time = 4.27s
global_step/sec: 23.3565
loss = 1296.4276123046875, steps = 9700, cost time = 4.28s
global_step/sec: 23.6991
loss = 1072.767333984375, steps = 9800, cost time = 4.22s
global_step/sec: 23.1788
loss = 1110.702392578125, steps = 9900, cost time = 4.31s
global_step/sec: 23.2798
loss = 1136.087890625, steps = 10000, cost time = 4.30s
global_step/sec: 23.7058
loss = 1433.153564453125, steps = 10100, cost time = 4.22s
global_step/sec: 23.4692
loss = 1123.3822021484375, steps = 10200, cost time = 4.26s
global_step/sec: 23.5867
loss = 1104.3624267578125, steps = 10300, cost time = 4.24s
global_step/sec: 23.5115
loss = 1212.6964111328125, steps = 10400, cost time = 4.25s
global_step/sec: 23.5855
loss = 1034.9981689453125, steps = 10500, cost time = 4.24s
global_step/sec: 23.5111
loss = 1148.8017578125, steps = 10600, cost time = 4.25s
global_step/sec: 23.4850
loss = 1110.68994140625, steps = 10700, cost time = 4.26s
global_step/sec: 23.2105
loss = 1060.14501953125, steps = 10800, cost time = 4.31s
global_step/sec: 23.4894
loss = 1187.0771484375, steps = 10900, cost time = 4.26s
global_step/sec: 23.5605
loss = 1098.02197265625, steps = 11000, cost time = 4.24s
global_step/sec: 23.3719
loss = 1034.9901123046875, steps = 11100, cost time = 4.28s
global_step/sec: 23.3550
loss = 1148.794677734375, steps = 11200, cost time = 4.28s
global_step/sec: 23.5131
loss = 1079.056640625, steps = 11300, cost time = 4.25s
global_step/sec: 23.4175
loss = 1148.792236328125, steps = 11400, cost time = 4.27s
global_step/sec: 23.4905
loss = 1180.6767578125, steps = 11500, cost time = 4.26s
global_step/sec: 23.3736
loss = 1193.464599609375, steps = 11600, cost time = 4.28s
global_step/sec: 23.3717
loss = 1117.0179443359375, steps = 11700, cost time = 4.28s
global_step/sec: 23.4818
loss = 1167.90576171875, steps = 11800, cost time = 4.26s
global_step/sec: 23.5643
loss = 1155.155029296875, steps = 11900, cost time = 4.24s
global_step/sec: 23.8742
loss = 1174.2855224609375, steps = 12000, cost time = 4.19s
global_step/sec: 23.3802
loss = 1174.28564453125, steps = 12100, cost time = 4.28s
global_step/sec: 23.6466
loss = 1193.45751953125, steps = 12200, cost time = 4.23s
global_step/sec: 45841.1934
loss = 23.04129409790039, steps = 12207, cost time = 0.27s
Evaluation complate:[3/3]
ACC = 0.9096999764442444
AUC = 0.485866904258728
